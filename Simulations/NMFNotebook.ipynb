{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GammaSimulations import GammaSimulations\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "nr_components=25\n",
    "nr_timepoints=50\n",
    "nr_neurons=50\n",
    "X=GammaSimulations().simulate_data(nr_components,nr_timepoints,nr_neurons)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "U=np.zeros((nr_neurons,nr_components))\n",
    "U=torch.tensor(U,requires_grad=True)\n",
    "V=np.zeros((nr_components,nr_timepoints))\n",
    "V=torch.tensor(V,requires_grad=True)\n",
    "def forward(U,V):\n",
    "    pred=U@V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.5317, -0.8789, -0.3044,  ..., -0.8769, -1.7898, -1.5760],\n",
      "        [ 0.7948,  0.3355,  0.9260,  ...,  0.3442,  0.9874,  0.1262],\n",
      "        [ 0.8318, -1.6527,  0.0230,  ...,  1.5588, -1.7002,  1.8052],\n",
      "        ...,\n",
      "        [ 0.1139, -0.5214, -0.6159,  ..., -0.0650,  0.0774, -2.7786],\n",
      "        [-0.1600,  0.3919,  1.1426,  ..., -1.7806, -0.6753, -0.5046],\n",
      "        [-0.6630,  1.9471,  1.2255,  ...,  1.5098,  0.3425, -0.1440]],\n",
      "       requires_grad=True)\n",
      "tensor([[ 1.6846,  0.2410,  1.2868,  ..., -0.0880, -0.0597, -1.3190],\n",
      "        [-1.6590, -1.4059,  0.0248,  ..., -0.4636,  0.6457,  1.6751],\n",
      "        [-0.6774,  1.6490, -1.0414,  ...,  0.3609, -2.2637,  0.6661],\n",
      "        ...,\n",
      "        [ 0.0445,  1.1002, -0.1459,  ...,  0.0930, -1.2909,  1.9094],\n",
      "        [ 0.6625, -0.1309,  0.2460,  ...,  0.5638,  0.5563, -0.0400],\n",
      "        [-1.3606,  0.2419,  0.3053,  ...,  1.0757,  0.0797,  1.7173]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "U=torch.randn((nr_neurons,nr_components),requires_grad=True)\n",
    "V=torch.randn((nr_components,nr_timepoints),requires_grad=True)\n",
    "print(V)\n",
    "print(U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 50])\n",
      "(50, 50)\n",
      "torch.Size([50, 50])\n",
      "tensor([[ 1.6846,  0.2410,  1.2868,  ..., -0.0880, -0.0597, -1.3190],\n",
      "        [-1.6590, -1.4059,  0.0248,  ..., -0.4636,  0.6457,  1.6751],\n",
      "        [-0.6774,  1.6490, -1.0414,  ...,  0.3609, -2.2637,  0.6661],\n",
      "        ...,\n",
      "        [ 0.0445,  1.1002, -0.1459,  ...,  0.0930, -1.2909,  1.9094],\n",
      "        [ 0.6625, -0.1309,  0.2460,  ...,  0.5638,  0.5563, -0.0400],\n",
      "        [-1.3606,  0.2419,  0.3053,  ...,  1.0757,  0.0797,  1.7173]],\n",
      "       requires_grad=True)\n",
      "tensor([[ 1.5317, -0.8789, -0.3044,  ..., -0.8769, -1.7898, -1.5760],\n",
      "        [ 0.7948,  0.3355,  0.9260,  ...,  0.3442,  0.9874,  0.1262],\n",
      "        [ 0.8318, -1.6527,  0.0230,  ...,  1.5588, -1.7002,  1.8052],\n",
      "        ...,\n",
      "        [ 0.1139, -0.5214, -0.6159,  ..., -0.0650,  0.0774, -2.7786],\n",
      "        [-0.1600,  0.3919,  1.1426,  ..., -1.7806, -0.6753, -0.5046],\n",
      "        [-0.6630,  1.9471,  1.2255,  ...,  1.5098,  0.3425, -0.1440]],\n",
      "       requires_grad=True)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of scalar type Float but got scalar type Double for argument #2 'target'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-68bca52d29d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mpreds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_torch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m#loss.backward()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    441\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2255\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2256\u001b[0m         \u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2257\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2258\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected object of scalar type Float but got scalar type Double for argument #2 'target'"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "def model(U,V):\n",
    "    UV=U@V\n",
    "    UV=Variable(UV,requires_grad=True)\n",
    "    return UV\n",
    "print((U@V).shape)\n",
    "print(X.shape)\n",
    "X_torch=torch.tensor(X,dtype=torch.double)\n",
    "print(X_torch.shape)\n",
    "def mse(t1,t2):\n",
    "    diff=t1-t2\n",
    "    print(diff)\n",
    "    return torch.sum(diff*diff)/diff.numel()\n",
    "\n",
    "loss_func = torch.nn.MSELoss()\n",
    "U=Variable(U,requires_grad=True)\n",
    "V=Variable(V,requires_grad=True)\n",
    "X_torch=Variable(X_torch)\n",
    "print(U)\n",
    "print(V)\n",
    "optimizer = torch.optim.SGD([U,V], \n",
    "                            lr=1e-6)\n",
    "for i in range(0,10):\n",
    "    preds=model(U,V)\n",
    "    loss=loss_func(preds,X_torch)\n",
    "    print(loss)\n",
    "    #loss.backward()\n",
    "    loss.backward()\n",
    "    #print('bom',loss.backward())\n",
    "    print('LOZZ',loss)\n",
    "    print(U.grad)\n",
    "    optimizer.step()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(92157.4375, grad_fn=<MseLossBackward>)\n",
      "U Parameter containing:\n",
      "tensor([[0.9023, 0.8210, 0.5492,  ..., 0.1021, 0.9532, 0.0926],\n",
      "        [0.5375, 0.5167, 0.5029,  ..., 0.6863, 0.4303, 0.3703],\n",
      "        [0.6259, 0.8489, 0.6209,  ..., 0.8950, 0.1018, 0.4842],\n",
      "        ...,\n",
      "        [0.9646, 0.8485, 0.5476,  ..., 0.4643, 0.9418, 0.7044],\n",
      "        [0.3126, 0.6723, 0.7195,  ..., 0.1253, 0.0625, 0.9489],\n",
      "        [0.1216, 0.4618, 0.0874,  ..., 0.0692, 0.1514, 0.7704]],\n",
      "       requires_grad=True)\n",
      "U Parameter containing:\n",
      "tensor([[0.8993, 0.8179, 0.5461,  ..., 0.0989, 0.9498, 0.0893],\n",
      "        [0.5346, 0.5138, 0.5001,  ..., 0.6832, 0.4272, 0.3670],\n",
      "        [0.6230, 0.8460, 0.6179,  ..., 0.8919, 0.0986, 0.4809],\n",
      "        ...,\n",
      "        [0.9613, 0.8452, 0.5442,  ..., 0.4609, 0.9382, 0.7007],\n",
      "        [0.3101, 0.6698, 0.7170,  ..., 0.1227, 0.0598, 0.9461],\n",
      "        [0.1190, 0.4592, 0.0848,  ..., 0.0665, 0.1486, 0.7674]],\n",
      "       requires_grad=True)\n",
      "U Parameter containing:\n",
      "tensor([[0.8962, 0.8150, 0.5430,  ..., 0.0958, 0.9465, 0.0860],\n",
      "        [0.5318, 0.5110, 0.4973,  ..., 0.6802, 0.4242, 0.3638],\n",
      "        [0.6201, 0.8431, 0.6149,  ..., 0.8889, 0.0955, 0.4777],\n",
      "        ...,\n",
      "        [0.9581, 0.8420, 0.5409,  ..., 0.4575, 0.9347, 0.6971],\n",
      "        [0.3076, 0.6673, 0.7144,  ..., 0.1202, 0.0572, 0.9433],\n",
      "        [0.1164, 0.4566, 0.0822,  ..., 0.0638, 0.1458, 0.7645]],\n",
      "       requires_grad=True)\n",
      "U Parameter containing:\n",
      "tensor([[0.8932, 0.8121, 0.5400,  ..., 0.0927, 0.9433, 0.0827],\n",
      "        [0.5291, 0.5083, 0.4946,  ..., 0.6772, 0.4213, 0.3607],\n",
      "        [0.6173, 0.8402, 0.6120,  ..., 0.8859, 0.0925, 0.4746],\n",
      "        ...,\n",
      "        [0.9550, 0.8389, 0.5377,  ..., 0.4542, 0.9312, 0.6936],\n",
      "        [0.3052, 0.6649, 0.7119,  ..., 0.1177, 0.0546, 0.9407],\n",
      "        [0.1138, 0.4540, 0.0796,  ..., 0.0612, 0.1430, 0.7616]],\n",
      "       requires_grad=True)\n",
      "U Parameter containing:\n",
      "tensor([[0.8903, 0.8092, 0.5371,  ..., 0.0897, 0.9401, 0.0796],\n",
      "        [0.5264, 0.5056, 0.4919,  ..., 0.6742, 0.4184, 0.3576],\n",
      "        [0.6145, 0.8374, 0.6091,  ..., 0.8830, 0.0895, 0.4715],\n",
      "        ...,\n",
      "        [0.9519, 0.8358, 0.5346,  ..., 0.4510, 0.9279, 0.6902],\n",
      "        [0.3029, 0.6625, 0.7095,  ..., 0.1153, 0.0521, 0.9380],\n",
      "        [0.1114, 0.4516, 0.0771,  ..., 0.0586, 0.1403, 0.7588]],\n",
      "       requires_grad=True)\n",
      "U Parameter containing:\n",
      "tensor([[0.8874, 0.8064, 0.5342,  ..., 0.0868, 0.9370, 0.0764],\n",
      "        [0.5237, 0.5029, 0.4893,  ..., 0.6713, 0.4156, 0.3546],\n",
      "        [0.6118, 0.8347, 0.6063,  ..., 0.8801, 0.0865, 0.4685],\n",
      "        ...,\n",
      "        [0.9488, 0.8327, 0.5314,  ..., 0.4478, 0.9245, 0.6868],\n",
      "        [0.3006, 0.6602, 0.7071,  ..., 0.1129, 0.0496, 0.9354],\n",
      "        [0.1089, 0.4491, 0.0746,  ..., 0.0560, 0.1376, 0.7561]],\n",
      "       requires_grad=True)\n",
      "U Parameter containing:\n",
      "tensor([[0.8846, 0.8036, 0.5313,  ..., 0.0838, 0.9339, 0.0734],\n",
      "        [0.5211, 0.5003, 0.4867,  ..., 0.6685, 0.4128, 0.3516],\n",
      "        [0.6091, 0.8320, 0.6035,  ..., 0.8772, 0.0836, 0.4655],\n",
      "        ...,\n",
      "        [0.9458, 0.8298, 0.5284,  ..., 0.4446, 0.9213, 0.6834],\n",
      "        [0.2983, 0.6579, 0.7047,  ..., 0.1106, 0.0472, 0.9329],\n",
      "        [0.1065, 0.4467, 0.0722,  ..., 0.0535, 0.1350, 0.7533]],\n",
      "       requires_grad=True)\n",
      "U Parameter containing:\n",
      "tensor([[0.8818, 0.8009, 0.5285,  ..., 0.0810, 0.9308, 0.0703],\n",
      "        [0.5186, 0.4977, 0.4842,  ..., 0.6657, 0.4101, 0.3486],\n",
      "        [0.6065, 0.8294, 0.6007,  ..., 0.8744, 0.0808, 0.4625],\n",
      "        ...,\n",
      "        [0.9429, 0.8268, 0.5254,  ..., 0.4415, 0.9181, 0.6801],\n",
      "        [0.2961, 0.6557, 0.7024,  ..., 0.1083, 0.0448, 0.9304],\n",
      "        [0.1042, 0.4444, 0.0698,  ..., 0.0511, 0.1324, 0.7507]],\n",
      "       requires_grad=True)\n",
      "U Parameter containing:\n",
      "tensor([[0.8791, 0.7982, 0.5257,  ..., 0.0782, 0.9279, 0.0674],\n",
      "        [0.5160, 0.4952, 0.4817,  ..., 0.6629, 0.4074, 0.3457],\n",
      "        [0.6039, 0.8268, 0.5981,  ..., 0.8717, 0.0780, 0.4597],\n",
      "        ...,\n",
      "        [0.9400, 0.8239, 0.5224,  ..., 0.4384, 0.9149, 0.6769],\n",
      "        [0.2939, 0.6534, 0.7001,  ..., 0.1060, 0.0424, 0.9279],\n",
      "        [0.1019, 0.4421, 0.0674,  ..., 0.0486, 0.1299, 0.7480]],\n",
      "       requires_grad=True)\n",
      "U Parameter containing:\n",
      "tensor([[0.8764, 0.7956, 0.5230,  ..., 0.0754, 0.9249, 0.0644],\n",
      "        [0.5136, 0.4927, 0.4793,  ..., 0.6602, 0.4047, 0.3429],\n",
      "        [0.6014, 0.8242, 0.5954,  ..., 0.8690, 0.0753, 0.4568],\n",
      "        ...,\n",
      "        [0.9371, 0.8211, 0.5195,  ..., 0.4354, 0.9118, 0.6737],\n",
      "        [0.2917, 0.6513, 0.6978,  ..., 0.1038, 0.0401, 0.9255],\n",
      "        [0.0996, 0.4398, 0.0651,  ..., 0.0463, 0.1274, 0.7454]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class NMF(nn.Module):\n",
    "    def __init__(self, nr_neurons, nr_timepoints, nr_components):\n",
    "        super(NMF, self).__init__()\n",
    "        self.U = nn.Parameter(torch.rand(nr_neurons, nr_components, requires_grad=True))\n",
    "        self.V = nn.Parameter(torch.rand(nr_components, nr_timepoints, requires_grad=True))\n",
    "\n",
    "    def forward(self):\n",
    "        return torch.matmul(self.U, self.V)\n",
    "\n",
    "# some data cube Y: B x N and we want to factor it into K components\n",
    "nr_components=25\n",
    "nr_timepoints=50\n",
    "nr_neurons=50\n",
    "#Y = torch.rand(B,N) \n",
    "X_torch=torch.tensor(X,dtype=torch.float32)\n",
    "Y=X_torch\n",
    "nmf = NMF(nr_neurons, nr_timepoints, nr_components)\n",
    "Y_ = nmf()\n",
    "loss_fn = nn.MSELoss(reduction='sum')\n",
    "loss = loss_fn(Y_, Y)\n",
    "loss.backward()\n",
    "print(loss)\n",
    "n_epoch=10\n",
    "for epoch in range(n_epoch):\n",
    "    Y_ = nmf()\n",
    "    loss = loss_fn(Y_, Y)\n",
    "    nmf.zero_grad() # need to clear the old gradients\n",
    "    loss.backward()\n",
    "\n",
    "    for param in nmf.parameters():\n",
    "        param.data = param.data - 1e-5 * param.grad\n",
    "    print('U',nmf.U)\n",
    "    nmf.U.data=torch.clamp(nmf.U.data,min=0)\n",
    "    #print(loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
