{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GammaSimulations import GammaSimulations\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "nr_components=25\n",
    "nr_timepoints=50\n",
    "nr_neurons=50\n",
    "X=GammaSimulations().simulate_data(nr_components,nr_timepoints,nr_neurons)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "U=np.zeros((nr_neurons,nr_components))\n",
    "U=torch.tensor(U,requires_grad=True)\n",
    "V=np.zeros((nr_components,nr_timepoints))\n",
    "V=torch.tensor(V,requires_grad=True)\n",
    "def forward(U,V):\n",
    "    pred=U@V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.5317, -0.8789, -0.3044,  ..., -0.8769, -1.7898, -1.5760],\n",
      "        [ 0.7948,  0.3355,  0.9260,  ...,  0.3442,  0.9874,  0.1262],\n",
      "        [ 0.8318, -1.6527,  0.0230,  ...,  1.5588, -1.7002,  1.8052],\n",
      "        ...,\n",
      "        [ 0.1139, -0.5214, -0.6159,  ..., -0.0650,  0.0774, -2.7786],\n",
      "        [-0.1600,  0.3919,  1.1426,  ..., -1.7806, -0.6753, -0.5046],\n",
      "        [-0.6630,  1.9471,  1.2255,  ...,  1.5098,  0.3425, -0.1440]],\n",
      "       requires_grad=True)\n",
      "tensor([[ 1.6846,  0.2410,  1.2868,  ..., -0.0880, -0.0597, -1.3190],\n",
      "        [-1.6590, -1.4059,  0.0248,  ..., -0.4636,  0.6457,  1.6751],\n",
      "        [-0.6774,  1.6490, -1.0414,  ...,  0.3609, -2.2637,  0.6661],\n",
      "        ...,\n",
      "        [ 0.0445,  1.1002, -0.1459,  ...,  0.0930, -1.2909,  1.9094],\n",
      "        [ 0.6625, -0.1309,  0.2460,  ...,  0.5638,  0.5563, -0.0400],\n",
      "        [-1.3606,  0.2419,  0.3053,  ...,  1.0757,  0.0797,  1.7173]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "U=torch.randn((nr_neurons,nr_components),requires_grad=True)\n",
    "V=torch.randn((nr_components,nr_timepoints),requires_grad=True)\n",
    "print(V)\n",
    "print(U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 50])\n",
      "(50, 50)\n",
      "torch.Size([50, 50])\n",
      "tensor([[ 1.6846,  0.2410,  1.2868,  ..., -0.0880, -0.0597, -1.3190],\n",
      "        [-1.6590, -1.4059,  0.0248,  ..., -0.4636,  0.6457,  1.6751],\n",
      "        [-0.6774,  1.6490, -1.0414,  ...,  0.3609, -2.2637,  0.6661],\n",
      "        ...,\n",
      "        [ 0.0445,  1.1002, -0.1459,  ...,  0.0930, -1.2909,  1.9094],\n",
      "        [ 0.6625, -0.1309,  0.2460,  ...,  0.5638,  0.5563, -0.0400],\n",
      "        [-1.3606,  0.2419,  0.3053,  ...,  1.0757,  0.0797,  1.7173]],\n",
      "       requires_grad=True)\n",
      "tensor([[ 1.5317, -0.8789, -0.3044,  ..., -0.8769, -1.7898, -1.5760],\n",
      "        [ 0.7948,  0.3355,  0.9260,  ...,  0.3442,  0.9874,  0.1262],\n",
      "        [ 0.8318, -1.6527,  0.0230,  ...,  1.5588, -1.7002,  1.8052],\n",
      "        ...,\n",
      "        [ 0.1139, -0.5214, -0.6159,  ..., -0.0650,  0.0774, -2.7786],\n",
      "        [-0.1600,  0.3919,  1.1426,  ..., -1.7806, -0.6753, -0.5046],\n",
      "        [-0.6630,  1.9471,  1.2255,  ...,  1.5098,  0.3425, -0.1440]],\n",
      "       requires_grad=True)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of scalar type Float but got scalar type Double for argument #2 'target'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-68bca52d29d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mpreds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_torch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m#loss.backward()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    441\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2255\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2256\u001b[0m         \u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2257\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2258\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected object of scalar type Float but got scalar type Double for argument #2 'target'"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "def model(U,V):\n",
    "    UV=U@V\n",
    "    UV=Variable(UV,requires_grad=True)\n",
    "    return UV\n",
    "print((U@V).shape)\n",
    "print(X.shape)\n",
    "X_torch=torch.tensor(X,dtype=torch.double)\n",
    "print(X_torch.shape)\n",
    "def mse(t1,t2):\n",
    "    diff=t1-t2\n",
    "    print(diff)\n",
    "    return torch.sum(diff*diff)/diff.numel()\n",
    "\n",
    "loss_func = torch.nn.MSELoss()\n",
    "U=Variable(U,requires_grad=True)\n",
    "V=Variable(V,requires_grad=True)\n",
    "X_torch=Variable(X_torch)\n",
    "print(U)\n",
    "print(V)\n",
    "optimizer = torch.optim.SGD([U,V], \n",
    "                            lr=1e-6)\n",
    "for i in range(0,10):\n",
    "    preds=model(U,V)\n",
    "    loss=loss_func(preds,X_torch)\n",
    "    print(loss)\n",
    "    #loss.backward()\n",
    "    loss.backward()\n",
    "    #print('bom',loss.backward())\n",
    "    print('LOZZ',loss)\n",
    "    print(U.grad)\n",
    "    optimizer.step()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(102768.4141, grad_fn=<MseLossBackward>)\n",
      "U Parameter containing:\n",
      "tensor([[0.3251, 0.0162, 0.6591,  ..., 0.6739, 0.8408, 0.1427],\n",
      "        [0.5809, 0.2888, 0.9564,  ..., 0.9315, 0.9006, 0.7768],\n",
      "        [0.8891, 0.4586, 0.3555,  ..., 0.2674, 0.8074, 0.4048],\n",
      "        ...,\n",
      "        [0.0412, 0.1695, 0.0783,  ..., 0.9525, 0.0890, 0.2297],\n",
      "        [0.6075, 0.1704, 0.4531,  ..., 0.1960, 0.9614, 0.5429],\n",
      "        [0.4992, 0.1459, 0.9565,  ..., 0.5575, 0.6843, 0.6881]],\n",
      "       requires_grad=True)\n",
      "tensor(102768.4141, grad_fn=<MseLossBackward>)\n",
      "U Parameter containing:\n",
      "tensor([[0.3220, 0.0135, 0.6561,  ..., 0.6712, 0.8379, 0.1400],\n",
      "        [0.5770, 0.2854, 0.9527,  ..., 0.9280, 0.8970, 0.7735],\n",
      "        [0.8854, 0.4553, 0.3520,  ..., 0.2642, 0.8040, 0.4017],\n",
      "        ...,\n",
      "        [0.0385, 0.1671, 0.0757,  ..., 0.9500, 0.0865, 0.2273],\n",
      "        [0.6044, 0.1676, 0.4501,  ..., 0.1933, 0.9585, 0.5403],\n",
      "        [0.4958, 0.1429, 0.9532,  ..., 0.5545, 0.6811, 0.6852]],\n",
      "       requires_grad=True)\n",
      "tensor(100166.3359, grad_fn=<MseLossBackward>)\n",
      "U Parameter containing:\n",
      "tensor([[0.3190, 0.0108, 0.6532,  ..., 0.6685, 0.8351, 0.1375],\n",
      "        [0.5733, 0.2820, 0.9491,  ..., 0.9246, 0.8934, 0.7702],\n",
      "        [0.8818, 0.4521, 0.3486,  ..., 0.2611, 0.8007, 0.3987],\n",
      "        ...,\n",
      "        [0.0359, 0.1647, 0.0731,  ..., 0.9476, 0.0841, 0.2250],\n",
      "        [0.6013, 0.1649, 0.4472,  ..., 0.1907, 0.9557, 0.5376],\n",
      "        [0.4924, 0.1399, 0.9500,  ..., 0.5516, 0.6781, 0.6823]],\n",
      "       requires_grad=True)\n",
      "tensor(97665.5547, grad_fn=<MseLossBackward>)\n",
      "U Parameter containing:\n",
      "tensor([[0.3161, 0.0082, 0.6504,  ..., 0.6659, 0.8323, 0.1350],\n",
      "        [0.5697, 0.2787, 0.9455,  ..., 0.9213, 0.8899, 0.7671],\n",
      "        [0.8783, 0.4490, 0.3453,  ..., 0.2580, 0.7974, 0.3957],\n",
      "        ...,\n",
      "        [0.0332, 0.1623, 0.0706,  ..., 0.9452, 0.0816, 0.2228],\n",
      "        [0.5983, 0.1623, 0.4444,  ..., 0.1881, 0.9529, 0.5351],\n",
      "        [0.4891, 0.1370, 0.9468,  ..., 0.5487, 0.6751, 0.6794]],\n",
      "       requires_grad=True)\n",
      "tensor(95260.6953, grad_fn=<MseLossBackward>)\n",
      "U Parameter containing:\n",
      "tensor([[0.3132, 0.0056, 0.6475,  ..., 0.6633, 0.8296, 0.1325],\n",
      "        [0.5661, 0.2754, 0.9420,  ..., 0.9181, 0.8865, 0.7639],\n",
      "        [0.8748, 0.4459, 0.3420,  ..., 0.2550, 0.7942, 0.3927],\n",
      "        ...,\n",
      "        [0.0307, 0.1600, 0.0682,  ..., 0.9429, 0.0793, 0.2205],\n",
      "        [0.5954, 0.1597, 0.4416,  ..., 0.1856, 0.9502, 0.5326],\n",
      "        [0.4859, 0.1342, 0.9437,  ..., 0.5458, 0.6721, 0.6766]],\n",
      "       requires_grad=True)\n",
      "tensor(92946.9844, grad_fn=<MseLossBackward>)\n",
      "U Parameter containing:\n",
      "tensor([[0.3104, 0.0031, 0.6448,  ..., 0.6608, 0.8269, 0.1301],\n",
      "        [0.5625, 0.2722, 0.9386,  ..., 0.9149, 0.8831, 0.7609],\n",
      "        [0.8714, 0.4429, 0.3387,  ..., 0.2521, 0.7911, 0.3898],\n",
      "        ...,\n",
      "        [0.0281, 0.1577, 0.0658,  ..., 0.9406, 0.0769, 0.2184],\n",
      "        [0.5925, 0.1572, 0.4388,  ..., 0.1831, 0.9476, 0.5301],\n",
      "        [0.4827, 0.1314, 0.9406,  ..., 0.5431, 0.6692, 0.6739]],\n",
      "       requires_grad=True)\n",
      "tensor(90718.8594, grad_fn=<MseLossBackward>)\n",
      "U Parameter containing:\n",
      "tensor([[3.0756e-01, 6.3861e-04, 6.4208e-01,  ..., 6.5833e-01, 8.2432e-01,\n",
      "         1.2770e-01],\n",
      "        [5.5906e-01, 2.6908e-01, 9.3523e-01,  ..., 9.1172e-01, 8.7975e-01,\n",
      "         7.5785e-01],\n",
      "        [8.6804e-01, 4.3989e-01, 3.3557e-01,  ..., 2.4918e-01, 7.8804e-01,\n",
      "         3.8700e-01],\n",
      "        ...,\n",
      "        [2.5670e-02, 1.5543e-01, 6.3400e-02,  ..., 9.3839e-01, 7.4652e-02,\n",
      "         2.1625e-01],\n",
      "        [5.8965e-01, 1.5468e-01, 4.3614e-01,  ..., 1.8067e-01, 9.4494e-01,\n",
      "         5.2771e-01],\n",
      "        [4.7959e-01, 1.2860e-01, 9.3759e-01,  ..., 5.4035e-01, 6.6639e-01,\n",
      "         6.7123e-01]], requires_grad=True)\n",
      "tensor(88572.7891, grad_fn=<MseLossBackward>)\n",
      "U Parameter containing:\n",
      "tensor([[ 0.3048, -0.0018,  0.6394,  ...,  0.6559,  0.8217,  0.1254],\n",
      "        [ 0.5556,  0.2660,  0.9319,  ...,  0.9086,  0.8765,  0.7549],\n",
      "        [ 0.8647,  0.4370,  0.3324,  ...,  0.2463,  0.7850,  0.3842],\n",
      "        ...,\n",
      "        [ 0.0232,  0.1532,  0.0611,  ...,  0.9362,  0.0724,  0.2142],\n",
      "        [ 0.5869,  0.1522,  0.4335,  ...,  0.1783,  0.9424,  0.5253],\n",
      "        [ 0.4765,  0.1259,  0.9346,  ...,  0.5377,  0.6636,  0.6686]],\n",
      "       requires_grad=True)\n",
      "tensor(86503.3984, grad_fn=<MseLossBackward>)\n",
      "U Parameter containing:\n",
      "tensor([[ 0.3021, -0.0024,  0.6368,  ...,  0.6535,  0.8192,  0.1231],\n",
      "        [ 0.5523,  0.2630,  0.9287,  ...,  0.9056,  0.8733,  0.7520],\n",
      "        [ 0.8615,  0.4341,  0.3294,  ...,  0.2436,  0.7821,  0.3815],\n",
      "        ...,\n",
      "        [ 0.0208,  0.1511,  0.0588,  ...,  0.9340,  0.0702,  0.2121],\n",
      "        [ 0.5841,  0.1498,  0.4309,  ...,  0.1759,  0.9398,  0.5230],\n",
      "        [ 0.4735,  0.1232,  0.9317,  ...,  0.5351,  0.6609,  0.6660]],\n",
      "       requires_grad=True)\n",
      "tensor(84508.8594, grad_fn=<MseLossBackward>)\n",
      "U Parameter containing:\n",
      "tensor([[ 0.2995, -0.0024,  0.6342,  ...,  0.6512,  0.8167,  0.1208],\n",
      "        [ 0.5490,  0.2600,  0.9255,  ...,  0.9027,  0.8701,  0.7491],\n",
      "        [ 0.8583,  0.4313,  0.3264,  ...,  0.2408,  0.7792,  0.3788],\n",
      "        ...,\n",
      "        [ 0.0185,  0.1489,  0.0565,  ...,  0.9319,  0.0680,  0.2101],\n",
      "        [ 0.5814,  0.1475,  0.4283,  ...,  0.1736,  0.9374,  0.5207],\n",
      "        [ 0.4705,  0.1206,  0.9288,  ...,  0.5325,  0.6582,  0.6635]],\n",
      "       requires_grad=True)\n",
      "tensor(82584.0078, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class NMF(nn.Module):\n",
    "    def __init__(self, nr_neurons, nr_timepoints, nr_components):\n",
    "        super(NMF, self).__init__()\n",
    "        self.U = nn.Parameter(torch.rand(nr_neurons, nr_components, requires_grad=True))\n",
    "        self.V = nn.Parameter(torch.rand(nr_components, nr_timepoints, requires_grad=True))\n",
    "\n",
    "    def forward(self):\n",
    "        return torch.matmul(self.U, self.V)\n",
    "\n",
    "# some data cube Y: B x N and we want to factor it into K components\n",
    "nr_components=25\n",
    "nr_timepoints=50\n",
    "nr_neurons=50\n",
    "#Y = torch.rand(B,N) \n",
    "X_torch=torch.tensor(X,dtype=torch.float32)\n",
    "Y=X_torch\n",
    "nmf = NMF(nr_neurons, nr_timepoints, nr_components)\n",
    "Y_ = nmf()\n",
    "loss_fn = nn.MSELoss(reduction='sum')\n",
    "loss = loss_fn(Y_, Y)\n",
    "loss.backward()\n",
    "print(loss)\n",
    "n_epoch=10\n",
    "for epoch in range(n_epoch):\n",
    "    Y_ = nmf()\n",
    "    loss = loss_fn(Y_, Y)\n",
    "    nmf.zero_grad() # need to clear the old gradients\n",
    "    loss.backward()\n",
    "\n",
    "    for param in nmf.parameters():\n",
    "        param.data = param.data - 1e-5 * param.grad\n",
    "    print('U',nmf.U)\n",
    "    nmf.U.data=torch.clamp(nmf.U.data,min=0)\n",
    "    print(loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
