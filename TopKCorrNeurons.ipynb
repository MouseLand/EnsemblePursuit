{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import os\n",
    "import time\n",
    "from scipy import stats\n",
    "\n",
    "import gc\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnsemblePursuitPyTorch():\n",
    "    \n",
    "    def calculate_cost_delta(self):\n",
    "        cost_delta=torch.clamp(torch.matmul(self.current_v,self.X),min=0,max=None)**2/torch.matmul(self.current_v,self.current_v)-self.lambd\n",
    "        #print('mean cost_delta',torch.mean(cost_delta))\n",
    "        return cost_delta\n",
    "    \n",
    "    def fit_one_assembly(self):\n",
    "        with torch.cuda.device(0) as device:\n",
    "            top_corr_neuron=self.select_top_k_corr_neuron()\n",
    "            #print('corr',top_corr_neuron)\n",
    "            #print('chosen neuron',top_corr_neuron)\n",
    "            #choose_neuron_idx=np.random.randint(0,self.sz[1],1)[0]\n",
    "            choose_neuron_idx=top_corr_neuron\n",
    "            #print(choose_neuron_idx)\n",
    "            self.selected_neurons=torch.zeros([self.sz[1]]).cuda()\n",
    "            self.selected_neurons[choose_neuron_idx]=1\n",
    "            self.current_v=self.X[:,choose_neuron_idx]\n",
    "            max_delta_cost=1000\n",
    "            self.i=0\n",
    "            while max_delta_cost>0:\n",
    "                cost_delta=self.calculate_cost_delta()\n",
    "                #print(cost_delta.size())\n",
    "                #print(self.current_u.size())\n",
    "                mask=self.selected_neurons.clone()\n",
    "                mask[self.selected_neurons==0]=1\n",
    "                mask[self.selected_neurons!=0]=0\n",
    "                masked_cost_delta=mask*cost_delta\n",
    "                #print(masked_cost_delta.type())\n",
    "                #print(masked_cost_delta)\n",
    "                values,sorted_neurons=masked_cost_delta.sort()\n",
    "                max_delta_neuron=sorted_neurons[-1]\n",
    "                #print(max_delta_neuron.item())\n",
    "                #print(values)\n",
    "                max_delta_cost=values[-1]\n",
    "                #print('max delta',max_delta_cost)\n",
    "                self.current_u=torch.clamp(torch.matmul(self.current_v,self.X),min=0,max=None)/torch.matmul(self.current_v,self.current_v)\n",
    "                #print(self.current_u[max_delta_neuron])\n",
    "                if max_delta_cost>0:\n",
    "                    self.current_v=(self.current_v+self.X[:,max_delta_neuron.item()])/2\n",
    "                    self.selected_neurons[max_delta_neuron.item()]=1\n",
    "                self.i+=1\n",
    "            #print(i)\n",
    "            self.current_u=torch.clamp(torch.matmul(self.current_v,self.X),min=0,max=None)/torch.matmul(self.current_v,self.current_v)\n",
    "            self.U=torch.cat((self.U,self.current_u.view(self.X.size(1),1)),1)\n",
    "            self.V=torch.cat((self.V,self.current_v.view(1,self.X.size(0))),0)\n",
    "    \n",
    "    def corrcoef(self,x):\n",
    "        \"\"\"\n",
    "        Mimics `np.corrcoef`\n",
    "\n",
    "        Arguments\n",
    "        ---------\n",
    "        x : 2D torch.Tensor\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        c : torch.Tensor\n",
    "            if x.size() = (5, 100), then return val will be of size (5,5)\n",
    "\n",
    "        Numpy docs ref:\n",
    "            https://docs.scipy.org/doc/numpy/reference/generated/numpy.corrcoef.html\n",
    "        Numpy code ref: \n",
    "            https://github.com/numpy/numpy/blob/v1.12.0/numpy/lib/function_base.py#L2933-L3013\n",
    "\n",
    "        Example:\n",
    "            >>> x = np.random.randn(5,120)\n",
    "            # result is a (5,5) matrix of correlations between rows\n",
    "            >>> np_corr = np.corrcoef(x)\n",
    "            >>> th_corr = corrcoef(torch.from_numpy(x))\n",
    "            >>> np.allclose(np_corr, th_corr.numpy())\n",
    "            # [out]: True\n",
    "        \"\"\"\n",
    "        # calculate covariance matrix of rows\n",
    "        mean_x = torch.mean(x,0)\n",
    "        #print(mean_x.size())\n",
    "        #print(mean_x.expand_as(x))\n",
    "        xm = torch.sub(x,mean_x)\n",
    "        c = xm.mm(xm.t())\n",
    "        c = c / (x.size(1) - 1)\n",
    "\n",
    "        # normalize covariance matrix\n",
    "        d = torch.diag(c)\n",
    "        stddev = torch.pow(d, 0.5)\n",
    "        c = c.div(stddev.expand_as(c))\n",
    "        c = c.div(stddev.expand_as(c).t())\n",
    "\n",
    "        # clamp between -1 and 1\n",
    "        # probably not necessary but numpy does it\n",
    "        c = torch.clamp(c, -1.0, 1.0)\n",
    "\n",
    "        return c\n",
    "    \n",
    "    def select_top_k_corr_neuron(self):\n",
    "        corr=self.corrcoef(self.X.t())\n",
    "        vals,ix=corr.sort(dim=1)\n",
    "        top_vals=vals[:,:-1][:,self.sz[1]-6:]\n",
    "        #print(top_vals)\n",
    "        av=torch.mean(top_vals,dim=1)\n",
    "        vals,top_neurons=torch.sort(av)\n",
    "        top_neuron=top_neurons[self.sz[1]-101:]\n",
    "        top_val=vals[self.sz[1]-101:]\n",
    "        idx=torch.randint(0,100,size=(1,))\n",
    "        print(idx)\n",
    "        print('top n', top_neuron[idx[0]], top_val[idx[0]])\n",
    "        return top_neuron[idx[0]].item()\n",
    "    \n",
    "    \n",
    "    def fit_transform(self,X,lambd,n_ensembles=None):\n",
    "        with torch.cuda.device(0) as device:\n",
    "            self.lambd=lambd\n",
    "            print(X)\n",
    "            self.X=stats.zscore(X,axis=0)\n",
    "            self.X=np.nan_to_num(self.X)\n",
    "            print(np.mean(self.X,axis=0))\n",
    "            self.X=torch.cuda.FloatTensor(self.X) \n",
    "            print(self.X)\n",
    "            self.sz=self.X.size()\n",
    "            print(self.sz[0],self.sz[1])\n",
    "            self.U=torch.zeros((self.X.size(1),1)).cuda()\n",
    "            self.V=torch.zeros([1,self.X.size(0)]).cuda()\n",
    "            self.nr_of_neurons=[]\n",
    "            #self.current_u=torch.zeros([self.X.size(1)]).cuda()\n",
    "            cost_lst=[]\n",
    "            for iteration in range(0,n_ensembles):\n",
    "                self.fit_one_assembly()\n",
    "                self.nr_of_neurons.append(self.i)\n",
    "                U_V=torch.mm(self.current_u.view(self.sz[1],1),self.current_v.view(1,self.sz[0]))\n",
    "                #print(U_V.size())\n",
    "                res=(self.X-U_V.t())\n",
    "                self.X=res\n",
    "                #print('norm',torch.norm(self.X))\n",
    "                self.cost=torch.mean(torch.mul(res,res))\n",
    "                #print('cost',self.cost)\n",
    "                cost_lst.append(self.cost.item())\n",
    "                #Reset u for new iteration\n",
    "            self.U=self.U[:,1:]\n",
    "            self.V=self.V[1:,:]\n",
    "            print(self.X.size())\n",
    "            print(self.U.size())\n",
    "            print(self.V.size())\n",
    "            return torch.matmul(self.U,self.V).t().cpu(), self.nr_of_neurons, self.U.cpu(), self.V.cpu(), cost_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5880, 10103)\n"
     ]
    }
   ],
   "source": [
    "X=sio.loadmat('/home/maria/Documents/EnsemblePursuit/data/natimg2800_M170717_MP034_2017-09-11.mat')['stim']['resp'][0][0]\n",
    "X[X<0]=0\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[31.466291   11.154725    0.         ... 35.939972    0.\n",
      "   0.        ]\n",
      " [41.705284    0.          0.         ...  0.         44.25718\n",
      "  34.889084  ]\n",
      " [ 0.          0.          0.         ... 92.24999    22.162407\n",
      "  21.241     ]\n",
      " ...\n",
      " [12.287675   18.75502     0.         ... 15.54476    55.489014\n",
      "  21.571573  ]\n",
      " [14.505278   27.549797    0.         ...  3.5592616   0.\n",
      "  26.330444  ]\n",
      " [ 0.65212256 31.231289    0.         ...  0.         14.375819\n",
      "  14.927368  ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maria/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:138: RuntimeWarning: invalid value encountered in sqrt\n",
      "  ret = um.sqrt(ret, out=ret)\n",
      "/home/maria/anaconda3/lib/python3.6/site-packages/scipy/stats/stats.py:2253: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  return (a - mns) / sstd\n",
      "/home/maria/anaconda3/lib/python3.6/site-packages/scipy/stats/stats.py:2253: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return (a - mns) / sstd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.46528060e-08 -7.78509630e-08 -5.44956755e-08 ...  1.29751605e-08\n",
      " -1.94627403e-09  5.19006438e-09]\n",
      "tensor([[ 1.1550, -0.1022, -0.5535,  ...,  0.5873, -0.8588, -0.7753],\n",
      "        [ 1.7695, -0.8956, -0.5535,  ..., -0.8096,  0.8385,  0.5909],\n",
      "        [-0.7333, -0.8956, -0.5535,  ...,  2.7760, -0.0089,  0.0565],\n",
      "        ...,\n",
      "        [ 0.0041,  0.4383, -0.5535,  ..., -0.2054,  1.2692,  0.0694],\n",
      "        [ 0.1372,  1.0639, -0.5535,  ..., -0.6713, -0.8588,  0.2557],\n",
      "        [-0.6942,  1.3257, -0.5535,  ..., -0.8096, -0.3075, -0.1908]],\n",
      "       device='cuda:0')\n",
      "5880 10103\n",
      "tensor([66])\n",
      "top n tensor(2398, device='cuda:0') tensor(0.4354, device='cuda:0')\n",
      "tensor([93])\n",
      "top n tensor(3183, device='cuda:0') tensor(0.4809, device='cuda:0')\n",
      "tensor([33])\n",
      "top n tensor(1458, device='cuda:0') tensor(0.4139, device='cuda:0')\n",
      "tensor([93])\n",
      "top n tensor(3183, device='cuda:0') tensor(0.4805, device='cuda:0')\n",
      "tensor([61])\n",
      "top n tensor(3214, device='cuda:0') tensor(0.4313, device='cuda:0')\n",
      "tensor([80])\n",
      "top n tensor(7728, device='cuda:0') tensor(0.4493, device='cuda:0')\n",
      "tensor([75])\n",
      "top n tensor(1747, device='cuda:0') tensor(0.4449, device='cuda:0')\n",
      "tensor([8])\n",
      "top n tensor(5078, device='cuda:0') tensor(0.3937, device='cuda:0')\n",
      "tensor([10])\n",
      "top n tensor(4080, device='cuda:0') tensor(0.3929, device='cuda:0')\n",
      "tensor([98])\n",
      "top n tensor(7766, device='cuda:0') tensor(0.4827, device='cuda:0')\n",
      "tensor([30])\n",
      "top n tensor(1506, device='cuda:0') tensor(0.4056, device='cuda:0')\n",
      "tensor([21])\n",
      "top n tensor(4096, device='cuda:0') tensor(0.3968, device='cuda:0')\n",
      "tensor([28])\n",
      "top n tensor(3838, device='cuda:0') tensor(0.4017, device='cuda:0')\n",
      "tensor([30])\n",
      "top n tensor(833, device='cuda:0') tensor(0.4041, device='cuda:0')\n",
      "tensor([46])\n",
      "top n tensor(1458, device='cuda:0') tensor(0.4135, device='cuda:0')\n",
      "tensor([15])\n",
      "top n tensor(2575, device='cuda:0') tensor(0.3933, device='cuda:0')\n",
      "tensor([54])\n",
      "top n tensor(9391, device='cuda:0') tensor(0.4217, device='cuda:0')\n",
      "tensor([18])\n",
      "top n tensor(1041, device='cuda:0') tensor(0.3945, device='cuda:0')\n",
      "tensor([66])\n",
      "top n tensor(2854, device='cuda:0') tensor(0.4249, device='cuda:0')\n",
      "tensor([55])\n",
      "top n tensor(9391, device='cuda:0') tensor(0.4194, device='cuda:0')\n",
      "tensor([90])\n",
      "top n tensor(1408, device='cuda:0') tensor(0.4495, device='cuda:0')\n",
      "tensor([58])\n",
      "top n tensor(8217, device='cuda:0') tensor(0.4210, device='cuda:0')\n",
      "tensor([46])\n",
      "top n tensor(1458, device='cuda:0') tensor(0.4101, device='cuda:0')\n",
      "tensor([79])\n",
      "top n tensor(223, device='cuda:0') tensor(0.4382, device='cuda:0')\n",
      "tensor([84])\n",
      "top n tensor(7728, device='cuda:0') tensor(0.4417, device='cuda:0')\n",
      "tensor([8])\n",
      "top n tensor(6451, device='cuda:0') tensor(0.3887, device='cuda:0')\n",
      "tensor([6])\n",
      "top n tensor(3606, device='cuda:0') tensor(0.3864, device='cuda:0')\n",
      "tensor([11])\n",
      "top n tensor(4080, device='cuda:0') tensor(0.3882, device='cuda:0')\n",
      "tensor([44])\n",
      "top n tensor(3810, device='cuda:0') tensor(0.4048, device='cuda:0')\n",
      "tensor([88])\n",
      "top n tensor(1763, device='cuda:0') tensor(0.4478, device='cuda:0')\n",
      "tensor([76])\n",
      "top n tensor(3522, device='cuda:0') tensor(0.4292, device='cuda:0')\n",
      "tensor([77])\n",
      "top n tensor(1842, device='cuda:0') tensor(0.4340, device='cuda:0')\n",
      "tensor([84])\n",
      "top n tensor(1616, device='cuda:0') tensor(0.4412, device='cuda:0')\n",
      "tensor([82])\n",
      "top n tensor(223, device='cuda:0') tensor(0.4376, device='cuda:0')\n",
      "tensor([98])\n",
      "top n tensor(36, device='cuda:0') tensor(0.4736, device='cuda:0')\n",
      "tensor([21])\n",
      "top n tensor(3179, device='cuda:0') tensor(0.3903, device='cuda:0')\n",
      "tensor([30])\n",
      "top n tensor(2096, device='cuda:0') tensor(0.3941, device='cuda:0')\n",
      "tensor([5])\n",
      "top n tensor(6451, device='cuda:0') tensor(0.3825, device='cuda:0')\n",
      "tensor([59])\n",
      "top n tensor(5379, device='cuda:0') tensor(0.4161, device='cuda:0')\n",
      "tensor([40])\n",
      "top n tensor(4097, device='cuda:0') tensor(0.3985, device='cuda:0')\n",
      "tensor([86])\n",
      "top n tensor(325, device='cuda:0') tensor(0.4411, device='cuda:0')\n",
      "tensor([36])\n",
      "top n tensor(1458, device='cuda:0') tensor(0.3966, device='cuda:0')\n",
      "tensor([88])\n",
      "top n tensor(1747, device='cuda:0') tensor(0.4423, device='cuda:0')\n",
      "tensor([60])\n",
      "top n tensor(2316, device='cuda:0') tensor(0.4141, device='cuda:0')\n",
      "tensor([51])\n",
      "top n tensor(7234, device='cuda:0') tensor(0.4021, device='cuda:0')\n",
      "tensor([55])\n",
      "top n tensor(2479, device='cuda:0') tensor(0.4080, device='cuda:0')\n",
      "tensor([8])\n",
      "top n tensor(3488, device='cuda:0') tensor(0.3775, device='cuda:0')\n",
      "tensor([11])\n",
      "top n tensor(2192, device='cuda:0') tensor(0.3786, device='cuda:0')\n",
      "tensor([79])\n",
      "top n tensor(984, device='cuda:0') tensor(0.4270, device='cuda:0')\n",
      "tensor([48])\n",
      "top n tensor(1774, device='cuda:0') tensor(0.3990, device='cuda:0')\n",
      "tensor([34])\n",
      "top n tensor(2907, device='cuda:0') tensor(0.3866, device='cuda:0')\n",
      "tensor([2])\n",
      "top n tensor(2341, device='cuda:0') tensor(0.3727, device='cuda:0')\n",
      "tensor([79])\n",
      "top n tensor(984, device='cuda:0') tensor(0.4266, device='cuda:0')\n",
      "tensor([58])\n",
      "top n tensor(833, device='cuda:0') tensor(0.4044, device='cuda:0')\n",
      "tensor([12])\n",
      "top n tensor(9642, device='cuda:0') tensor(0.3752, device='cuda:0')\n",
      "tensor([71])\n",
      "top n tensor(7709, device='cuda:0') tensor(0.4177, device='cuda:0')\n",
      "tensor([72])\n",
      "top n tensor(2470, device='cuda:0') tensor(0.4171, device='cuda:0')\n",
      "tensor([6])\n",
      "top n tensor(1366, device='cuda:0') tensor(0.3710, device='cuda:0')\n",
      "tensor([14])\n",
      "top n tensor(5374, device='cuda:0') tensor(0.3740, device='cuda:0')\n",
      "tensor([61])\n",
      "top n tensor(6415, device='cuda:0') tensor(0.4044, device='cuda:0')\n",
      "tensor([48])\n",
      "top n tensor(9367, device='cuda:0') tensor(0.3934, device='cuda:0')\n",
      "tensor([16])\n",
      "top n tensor(2771, device='cuda:0') tensor(0.3717, device='cuda:0')\n",
      "tensor([56])\n",
      "top n tensor(1055, device='cuda:0') tensor(0.3952, device='cuda:0')\n",
      "tensor([68])\n",
      "top n tensor(9391, device='cuda:0') tensor(0.4090, device='cuda:0')\n",
      "tensor([45])\n",
      "top n tensor(3175, device='cuda:0') tensor(0.3849, device='cuda:0')\n",
      "tensor([27])\n",
      "top n tensor(3106, device='cuda:0') tensor(0.3742, device='cuda:0')\n",
      "tensor([7])\n",
      "top n tensor(4403, device='cuda:0') tensor(0.3658, device='cuda:0')\n",
      "tensor([71])\n",
      "top n tensor(788, device='cuda:0') tensor(0.4088, device='cuda:0')\n",
      "tensor([44])\n",
      "top n tensor(7234, device='cuda:0') tensor(0.3855, device='cuda:0')\n",
      "tensor([61])\n",
      "top n tensor(6415, device='cuda:0') tensor(0.3971, device='cuda:0')\n",
      "tensor([1])\n",
      "top n tensor(9642, device='cuda:0') tensor(0.3641, device='cuda:0')\n",
      "tensor([41])\n",
      "top n tensor(4978, device='cuda:0') tensor(0.3814, device='cuda:0')\n",
      "tensor([55])\n",
      "top n tensor(905, device='cuda:0') tensor(0.3914, device='cuda:0')\n",
      "tensor([84])\n",
      "top n tensor(2422, device='cuda:0') tensor(0.4204, device='cuda:0')\n",
      "tensor([3])\n",
      "top n tensor(4320, device='cuda:0') tensor(0.3619, device='cuda:0')\n",
      "tensor([2])\n",
      "top n tensor(3309, device='cuda:0') tensor(0.3612, device='cuda:0')\n",
      "tensor([86])\n",
      "top n tensor(2854, device='cuda:0') tensor(0.4208, device='cuda:0')\n",
      "tensor([43])\n",
      "top n tensor(6954, device='cuda:0') tensor(0.3804, device='cuda:0')\n",
      "tensor([60])\n",
      "top n tensor(905, device='cuda:0') tensor(0.3914, device='cuda:0')\n",
      "tensor([61])\n",
      "top n tensor(905, device='cuda:0') tensor(0.3917, device='cuda:0')\n",
      "tensor([87])\n",
      "top n tensor(7728, device='cuda:0') tensor(0.4220, device='cuda:0')\n",
      "tensor([82])\n",
      "top n tensor(1297, device='cuda:0') tensor(0.4164, device='cuda:0')\n",
      "tensor([57])\n",
      "top n tensor(83, device='cuda:0') tensor(0.3879, device='cuda:0')\n",
      "tensor([27])\n",
      "top n tensor(9849, device='cuda:0') tensor(0.3656, device='cuda:0')\n",
      "tensor([71])\n",
      "top n tensor(36, device='cuda:0') tensor(0.3978, device='cuda:0')\n",
      "tensor([38])\n",
      "top n tensor(3488, device='cuda:0') tensor(0.3708, device='cuda:0')\n",
      "tensor([17])\n",
      "top n tensor(9849, device='cuda:0') tensor(0.3593, device='cuda:0')\n",
      "tensor([89])\n",
      "top n tensor(7766, device='cuda:0') tensor(0.4251, device='cuda:0')\n",
      "tensor([73])\n",
      "top n tensor(2470, device='cuda:0') tensor(0.4001, device='cuda:0')\n",
      "tensor([21])\n",
      "top n tensor(3238, device='cuda:0') tensor(0.3598, device='cuda:0')\n",
      "tensor([2])\n",
      "top n tensor(7430, device='cuda:0') tensor(0.3543, device='cuda:0')\n",
      "tensor([21])\n",
      "top n tensor(6686, device='cuda:0') tensor(0.3589, device='cuda:0')\n",
      "tensor([24])\n",
      "top n tensor(6686, device='cuda:0') tensor(0.3590, device='cuda:0')\n",
      "tensor([20])\n",
      "top n tensor(9849, device='cuda:0') tensor(0.3585, device='cuda:0')\n",
      "tensor([79])\n",
      "top n tensor(2628, device='cuda:0') tensor(0.4062, device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([80])\n",
      "top n tensor(9391, device='cuda:0') tensor(0.4048, device='cuda:0')\n",
      "tensor([12])\n",
      "top n tensor(5209, device='cuda:0') tensor(0.3558, device='cuda:0')\n",
      "tensor([93])\n",
      "top n tensor(1616, device='cuda:0') tensor(0.4252, device='cuda:0')\n",
      "tensor([60])\n",
      "top n tensor(325, device='cuda:0') tensor(0.3858, device='cuda:0')\n",
      "tensor([45])\n",
      "top n tensor(7003, device='cuda:0') tensor(0.3675, device='cuda:0')\n",
      "torch.Size([5880, 10103])\n",
      "torch.Size([10103, 100])\n",
      "torch.Size([100, 5880])\n",
      "194.77644181251526\n",
      "[249, 230, 491, 792, 269, 355, 81, 272, 109, 187, 175, 442, 324, 420, 480, 195, 428, 6, 227, 52, 355, 190, 80, 471, 184, 101, 4, 396, 178, 235, 315, 91, 262, 154, 243, 82, 262, 202, 247, 315, 143, 35, 228, 216, 221, 310, 209, 44, 223, 6, 91, 327, 248, 186, 364, 324, 395, 172, 192, 66, 124, 6, 4, 249, 152, 147, 86, 171, 40, 76, 92, 56, 114, 84, 85, 26, 159, 110, 206, 105, 157, 238, 152, 143, 209, 168, 72, 80, 124, 72, 117, 84, 98, 197, 7, 121, 161, 92, 7, 168]\n",
      "[0.998864471912384, 0.9972290396690369, 0.9963499307632446, 0.9946427941322327, 0.9934293031692505, 0.9921253323554993, 0.9904618263244629, 0.9890836477279663, 0.9882087707519531, 0.9870206117630005, 0.9861653447151184, 0.9852532148361206, 0.9835926294326782, 0.9822540879249573, 0.9812512993812561, 0.9804809093475342, 0.9790009260177612, 0.9774717688560486, 0.9765321612358093, 0.9753092527389526, 0.9744247198104858, 0.9734537601470947, 0.9722913503646851, 0.971342921257019, 0.9703667759895325, 0.9692730903625488, 0.96826171875, 0.9672154784202576, 0.9664567112922668, 0.9655676484107971, 0.9648376703262329, 0.963239848613739, 0.9622204303741455, 0.9615182280540466, 0.9606093764305115, 0.9595557451248169, 0.9588412046432495, 0.957773745059967, 0.9569281339645386, 0.955778181552887, 0.9548957347869873, 0.9542043209075928, 0.9533138275146484, 0.9525948762893677, 0.9517455697059631, 0.9509803056716919, 0.9503065347671509, 0.9495933651924133, 0.9486487507820129, 0.9479770660400391, 0.9471003413200378, 0.9463921189308167, 0.9455006718635559, 0.9447224140167236, 0.9438800811767578, 0.9429555535316467, 0.9420807957649231, 0.9414268136024475, 0.9407252669334412, 0.9397386312484741, 0.9388433694839478, 0.9384127855300903, 0.9378838539123535, 0.9374168515205383, 0.9367682933807373, 0.9359323978424072, 0.9351742267608643, 0.9343414306640625, 0.9336891174316406, 0.9331207871437073, 0.9325428009033203, 0.9315682053565979, 0.9308915138244629, 0.9300960302352905, 0.9293873906135559, 0.9287859797477722, 0.9281631708145142, 0.9273993372917175, 0.9267094135284424, 0.9259655475616455, 0.9252399206161499, 0.9247592687606812, 0.9241911768913269, 0.9233885407447815, 0.9226994514465332, 0.921862006187439, 0.9213008284568787, 0.9205814003944397, 0.92012619972229, 0.9194568395614624, 0.9186646938323975, 0.9177857041358948, 0.9172533750534058, 0.9167389273643494, 0.9162352085113525, 0.9157565236091614, 0.9153292775154114, 0.9147036671638489, 0.9142689108848572, 0.9137124419212341]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(7)\n",
    "ep=EnsemblePursuitPyTorch()\n",
    "s=time.time()\n",
    "U_V,nr_of_neurons,U,V, cost_lst=ep.fit_transform(X,300,100)\n",
    "e=time.time()\n",
    "print(e-s)\n",
    "print(nr_of_neurons)\n",
    "print(cost_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05964285714285714\n"
     ]
    }
   ],
   "source": [
    "def test_train_split(data,stim):\n",
    "    unique, counts = np.unique(stim.flatten(), return_counts=True)\n",
    "    count_dict=dict(zip(unique, counts))\n",
    "\n",
    "    keys_with_enough_data=[]\n",
    "    for key in count_dict.keys():\n",
    "        if count_dict[key]==2:\n",
    "            keys_with_enough_data.append(key)\n",
    "\n",
    "    filtered_stims=np.isin(stim.flatten(),keys_with_enough_data)\n",
    "\n",
    "    #Arrange data so that responses with the same stimulus are adjacent\n",
    "    z=stim.flatten()[np.where(filtered_stims)[0]]\n",
    "    sortd=np.argsort(z)\n",
    "    istim=np.sort(z)\n",
    "    X=data[filtered_stims,:]\n",
    "    out=X[sortd,:].copy()\n",
    "\n",
    "    x_train=out[::2,:]\n",
    "    y_train=istim[::2]\n",
    "    x_test=out[1::2,:]\n",
    "    y_test=istim[1::2]\n",
    "    \n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "def evaluate_model(x_train,x_test):\n",
    "    corr_mat=np.zeros((x_train.shape[0],x_train.shape[0]))\n",
    "    for j in range(0,x_train.shape[0]):\n",
    "        for i in range(0,x_test.shape[0]):\n",
    "            corr_mat[j,i]=np.corrcoef(x_train[j,:],x_test[i,:])[0,1]\n",
    "    print(np.mean(np.argmax(corr_mat, axis=0) == np.arange(0,x_train.shape[0],1,int)))\n",
    "    \n",
    "stim=sio.loadmat('/home/maria/Documents/EnsemblePursuit/data/natimg2800_M170717_MP034_2017-09-11.mat')['stim']['istim'][0][0]\n",
    "x_train, x_test, y_train, y_test=test_train_split(np.array(V.t()),stim)\n",
    "evaluate_model(x_train,x_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
