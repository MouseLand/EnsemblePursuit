{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()\n",
    "t=torch.cuda.FloatTensor([2,3])\n",
    "\n",
    "import gc\n",
    "\n",
    "g=gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnsemblePursuitPyTorch():\n",
    "    \n",
    "    def calculate_cost_delta(self):\n",
    "        #print(np.dot(self.current_v.T,self.current_v))\n",
    "        #cost_delta=np.clip(self.current_v.T@self.X,0,None)/np.dot(self.current_v.T,self.current_v)[0]-self.lambd\n",
    "        #print(torch.matmul(self.current_v,self.X).size())\n",
    "        cost_delta=torch.clamp(torch.matmul(self.current_v,self.X),min=0,max=None)/torch.matmul(self.current_v,self.current_v)-self.lambd\n",
    "        return cost_delta\n",
    "    \n",
    "    def fit_one_assembly(self):\n",
    "        with torch.cuda.device(0) as device:\n",
    "            choose_neuron_idx=np.random.randint(0,self.X.size()[1],1)[0]\n",
    "            self.current_u=torch.zeros([self.X.size(1)]).cuda()\n",
    "            self.current_u[choose_neuron_idx]=1\n",
    "            self.current_v=self.X[:,choose_neuron_idx]\n",
    "            #print(self.current_v.size())\n",
    "            max_delta_cost=1000\n",
    "            self.i=0\n",
    "            while max_delta_cost>0:\n",
    "                cost_delta=self.calculate_cost_delta()\n",
    "                #print(cost_delta.size())\n",
    "                #print(self.current_u.size())\n",
    "                mask=self.current_u.clone()\n",
    "                mask[self.current_u==0]=1\n",
    "                mask[self.current_u!=0]=0\n",
    "                masked_cost_delta=mask*cost_delta\n",
    "                #print(masked_cost_delta.type())\n",
    "                #print(masked_cost_delta)\n",
    "                values,sorted_neurons=masked_cost_delta.sort()\n",
    "                max_delta_neuron=sorted_neurons[-1]\n",
    "                #print(max_delta_neuron.item())\n",
    "                #print(values)\n",
    "                max_delta_cost=values[-1]\n",
    "                if max_delta_cost>0:\n",
    "                    self.current_v=(self.current_v+self.X[:,max_delta_neuron.item()])/2\n",
    "                    self.current_u[max_delta_neuron.item()]=1\n",
    "                self.i+=1\n",
    "            #print(i)\n",
    "            self.U=torch.cat((self.U,self.current_u.view(self.X.size(1),1)),1)\n",
    "            self.V=torch.cat((self.V,self.current_v.view(1,self.X.size(0))),0)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def fit_transform(self,X,lambd,n_ensembles=None):\n",
    "        with torch.cuda.device(0) as device:\n",
    "            self.lambd=lambd\n",
    "            self.X=torch.cuda.FloatTensor(X)\n",
    "            self.U=torch.zeros((self.X.size(1),1)).cuda()\n",
    "            self.V=torch.zeros([1,self.X.size(0)]).cuda()\n",
    "            self.nr_of_neurons=[]\n",
    "            #self.current_u=torch.zeros([self.X.size(1)]).cuda()\n",
    "            for iteration in range(0,n_ensembles):\n",
    "                self.fit_one_assembly()\n",
    "                self.nr_of_neurons.append(self.i)\n",
    "                U_V=torch.mm(self.current_u.view(self.X.size(1),1),self.current_v.view(1,self.X.size(0)))\n",
    "                #print(U_V.size())\n",
    "                self.X=(self.X.t()-U_V).t()\n",
    "                self.X[self.X<0]=0\n",
    "                #Reset u for new iteration\n",
    "            self.U=self.U[:,1:]\n",
    "            self.V=self.V[1:,:]\n",
    "            print(self.X.size())\n",
    "            print(self.U.size())\n",
    "            print(self.V.size())\n",
    "            return torch.matmul(self.U,self.V).t().cpu(), self.nr_of_neurons, self.U.cpu(), self.V.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5880, 10103)\n"
     ]
    }
   ],
   "source": [
    "X=sio.loadmat('/home/maria/Documents/EnsemblePursuit/data/natimg2800_M170717_MP034_2017-09-11.mat')['stim']['resp'][0][0]\n",
    "X[X<0]=0\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(7)\n",
    "ep=EnsemblePursuitPyTorch()\n",
    "s=time.time()\n",
    "U_V,nr_of_neurons,U,V=ep.fit_transform(X,0.35,1000)\n",
    "e=time.time()\n",
    "print(e-s)\n",
    "print(nr_of_neurons)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
