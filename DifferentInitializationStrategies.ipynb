{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import os\n",
    "import time\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnsemblePursuitPyTorch():\n",
    "    \n",
    "    def zscore(self):\n",
    "        mean_stimuli=self.X.mean(dim=0)\n",
    "        std_stimuli=self.X.std(dim=0)+0.0000000001\n",
    "        \n",
    "        self.X=torch.sub(self.X,mean_stimuli)\n",
    "        self.X=self.X.div(std_stimuli)\n",
    "    \n",
    "    def calculate_cost_delta(self):\n",
    "        cost_delta=(torch.clamp(torch.matmul(self.current_v,self.X),min=0,max=None)**2)/(self.sz[0]*torch.matmul(self.current_v,self.current_v))-self.lambd\n",
    "        #print('cost delta',cost_delta.mean())\n",
    "        return cost_delta\n",
    "    \n",
    "    def fit_one_assembly(self):\n",
    "        '''\n",
    "        Function for fitting one cell assembly and computing u and v of the currrent assembly (self.current_u,\n",
    "        self.current_v).\n",
    "        One neuron cell assemblies are excluded. \n",
    "        '''\n",
    "        with torch.cuda.device(0) as device:\n",
    "            #Fake i for initiating while loop. self.i stores the number of neurons in assemblies.\n",
    "            self.i=1\n",
    "            #If i is 1, e.g. only one neuron in fit cell assembly, will run fitting the assembly again. \n",
    "            #safety it to avoid infinite loops.\n",
    "            safety_it=0\n",
    "            n_of_neurons=self.neuron_init_dict['parameters']['n_of_neurons']\n",
    "            #a variable to switch to random initialization after finding first assembly if the method is\n",
    "            #selecting neurons from a time point\n",
    "            self.first_assembly=True\n",
    "            while self.i==1:\n",
    "                if self.first_assembly==True:\n",
    "                    top_neurons=self.select_top_neurons()\n",
    "                    self.first_assembly=False\n",
    "                elif self.first_assembly==False and self.neuron_init_dict['method']=='from_time_point':\n",
    "                    self.self.neuron_init_dict['method']='top_k_corr'\n",
    "                    top_neurons=self.select_top_neurons()\n",
    "                elif self.first_assembly==False:\n",
    "                    top_neurons=self.select_top_neurons()\n",
    "                #Array of keeping track of neurons in the cell assembly\n",
    "                self.selected_neurons=torch.zeros([self.sz[1]]).cuda()\n",
    "                for j in range(0,len(top_neurons)):\n",
    "                    self.selected_neurons[top_neurons[j]]=1\n",
    "                #Seed current_v\n",
    "                self.current_v=self.X[:,top_neurons].mean(1).flatten()\n",
    "                #print('shp',self.current_v)\n",
    "                #Fake cost to initiate while loop\n",
    "                max_delta_cost=1000\n",
    "                #reset i\n",
    "                self.i=1\n",
    "                #while max_delta_cost>0 and self.i<=1000:\n",
    "                while max_delta_cost>0:\n",
    "                    cost_delta=self.calculate_cost_delta()\n",
    "                    #invert the 0's and 1's in the array which stores which neurons have already \n",
    "                    #been selected into the assembly to use it as a mask\n",
    "                    mask=self.selected_neurons.clone()\n",
    "                    mask[self.selected_neurons==0]=1\n",
    "                    mask[self.selected_neurons!=0]=0\n",
    "                    masked_cost_delta=mask*cost_delta\n",
    "                    values,sorted_neurons=masked_cost_delta.sort()\n",
    "                    max_delta_neuron=sorted_neurons[-1]\n",
    "                    max_delta_cost=values[-1]\n",
    "                    if max_delta_cost>0:\n",
    "                        self.selected_neurons[max_delta_neuron.item()]=1\n",
    "                        self.current_v= self.X[:, (self.selected_neurons == 1)].mean(dim=1)\n",
    "                        #print('sel neurons', self.X[:, (self.selected_neurons == 1)].size())\n",
    "                    self.i+=1\n",
    "                safety_it+=1\n",
    "                #Increase number of neurons to sample from if while loop hasn't been finding any assemblies.\n",
    "                if safety_it>100:\n",
    "                    self.neuron_init_dict['parameters']['n_of_neurons']=500\n",
    "                if safety_it>600:\n",
    "                    self.neuron_init_dict['parameters']['n_of_neurons']=1000\n",
    "                if safety_it>1600:\n",
    "                    raise ValueError('Assembly capacity too big, can\\'t fit model')\n",
    "            #Add final seed neuron to seed_neurons.        \n",
    "            self.seed_neurons=self.seed_neurons+top_neurons          \n",
    "            #Calculate u based on final v fit for a cell assembly. \n",
    "            self.current_u=torch.clamp(torch.matmul(self.current_v,self.X),min=0,max=None)/torch.matmul(self.current_v,self.current_v)\n",
    "            self.U=torch.cat((self.U,self.current_u.view(self.X.size(1),1)),1)\n",
    "            self.V=torch.cat((self.V,self.current_v.view(1,self.X.size(0))),0)\n",
    "            \n",
    "    def select_top_neurons(self):\n",
    "        if self.neuron_init_dict['method']=='top_k_corr':\n",
    "            n_of_neurons=self.neuron_init_dict['parameters']['n_of_neurons']\n",
    "            top_neurons,_=self.corr_top_k(n_neurons=n_of_neurons)\n",
    "            top_neurons=self.select_top_k_corr_neuron(top_neurons,_,n_of_neurons)\n",
    "        if self.neuron_init_dict['method']=='random':\n",
    "            top_neurons=[np.random.randint(0,self.sz[1],1)[0]]\n",
    "        if self.neuron_init_dict['method']=='from_time_point':\n",
    "            top_neurons=self.select_from_time_point()\n",
    "        return top_neurons\n",
    "    \n",
    "    def select_from_time_point(self):\n",
    "        threshold=self.neuron_init_dict['parameters']['T']\n",
    "        threshold_array=(self.original_X>=threshold).sum(dim=1)\n",
    "        #print('thr_array',threshold_array)\n",
    "        values,sorted_timepoints=threshold_array.sort()\n",
    "        timepoint=sorted_timepoints[-1]\n",
    "        #print('t',timepoint)\n",
    "        neurons=(self.original_X[timepoint,:]>=threshold).nonzero()\n",
    "        #print('neurons',neurons)\n",
    "        return neurons.tolist()\n",
    "    \n",
    "    def corrcoef(self,x):\n",
    "        '''\n",
    "        Torch implementation of the full correlation matrix.\n",
    "        '''\n",
    "        # calculate covariance matrix of columns\n",
    "        mean_x = torch.mean(x,0)\n",
    "        xm = torch.sub(x,mean_x)\n",
    "        c = x.mm(x.t())\n",
    "        c = c / (x.size(1))\n",
    "\n",
    "        # normalize covariance matrix\n",
    "        d = torch.diag(c)\n",
    "        stddev = torch.pow(d, 0.5)\n",
    "        c = c.div(stddev.expand_as(c))\n",
    "        c = c.div(stddev.expand_as(c).t())\n",
    "        #print((c!=c).nonzero())\n",
    "        # clamp between -1 and 1\n",
    "        c = torch.clamp(c, -1.0, 1.0)\n",
    "\n",
    "        return c\n",
    "    \n",
    "    def corr_top_k(self,n_neurons=100):\n",
    "        '''\n",
    "        Finds n_neurons neurons that are on average most correlated to their \n",
    "        5 closest neighbors.\n",
    "        '''\n",
    "        #Compute full correlation matrix (works with one neuron per column,\n",
    "        #so have to transpose.)\n",
    "        corr=self.corrcoef(self.X.t())\n",
    "        #Sorts each row of correlation matrix\n",
    "        vals,ix=corr.sort(dim=1)\n",
    "        #Discards the last entry corresponding to the diagonal 1 and then\n",
    "        #selects 5 of the largest entries from sorted array.\n",
    "        top_vals=vals[:,:-1][:,self.sz[1]-6:]\n",
    "        #Averages the 5 top correlations.\n",
    "        av=torch.mean(top_vals,dim=1)\n",
    "        #Sorts the averages\n",
    "        vals,top_neurons=torch.sort(av)\n",
    "        #Selects top neurons\n",
    "        top_neuron=top_neurons[self.sz[1]-(n_neurons+1):]\n",
    "        top_val=vals[self.sz[1]-(n_neurons+1):]\n",
    "        return top_neuron,top_val\n",
    "          \n",
    "    \n",
    "    def select_top_k_corr_neuron(self,top_neuron,top_val,n_neurons=100):\n",
    "        '''\n",
    "        Randomly samples from k top correlated urons.\n",
    "        '''\n",
    "        #Randomly samples a neuron from the n_of_neurons top correlated.\n",
    "        idx=torch.randint(0,n_neurons,size=(1,))\n",
    "        print('top n', top_neuron[idx[0]].item(), top_val[idx[0]].item())\n",
    "        return [top_neuron[idx[0]].item()]\n",
    "    \n",
    "    \n",
    "    def fit_transform(self,X,lambd,n_ensembles,neuron_init_dict):\n",
    "        torch.manual_seed(7)\n",
    "        with torch.cuda.device(0) as device:\n",
    "            self.neuron_init_dict=neuron_init_dict\n",
    "            self.lambd=lambd\n",
    "            #Creates cuda tensor from data\n",
    "            self.X=torch.cuda.FloatTensor(X)\n",
    "            #z-score data.\n",
    "            self.zscore()\n",
    "            #Keep original data for one type of initialization\n",
    "            if self.neuron_init_dict['method']=='from_time_point':\n",
    "                self.original_X=self.X.clone()\n",
    "            #Store dimensionality of X for later use.\n",
    "            self.sz=self.X.size()\n",
    "            print('sz',self.sz)\n",
    "            #Initializes U and V with zeros, later these will be discarded.\n",
    "            self.U=torch.zeros((self.X.size(1),1)).cuda()\n",
    "            self.V=torch.zeros([1,self.X.size(0)]).cuda()\n",
    "            #List for storing the number of neurons in each fit assembly.\n",
    "            self.nr_of_neurons=[]\n",
    "            #List for storing the seed neurons for each assembly.\n",
    "            self.seed_neurons=[]\n",
    "            cost_lst=[]\n",
    "            for iteration in range(0,n_ensembles):\n",
    "                self.fit_one_assembly()\n",
    "                self.nr_of_neurons.append(self.i)\n",
    "                U_V=torch.mm(self.current_u.view(self.sz[1],1),self.current_v.view(1,self.sz[0]))\n",
    "                U_V[U_V != U_V] = 0\n",
    "                res=(self.X-U_V.t())\n",
    "                self.X=res\n",
    "                if iteration==441:\n",
    "                    print('res',res)\n",
    "                    print((res!=res).nonzero())\n",
    "                print('ensemble nr', iteration)\n",
    "                #print('u',self.current_u)\n",
    "                #print('v',self.current_v)\n",
    "                #print('length v', torch.matmul(self.current_v,self.current_v))\n",
    "                #print('norm',torch.norm(self.X))\n",
    "                self.cost=torch.mean(torch.mul(res,res))\n",
    "                print('cost',self.cost)\n",
    "                cost_lst.append(self.cost.item())\n",
    "            #After fitting arrays discard the zero initialization rows and columns from U and V.\n",
    "            self.U=self.U[:,1:]\n",
    "            self.V=self.V[1:,:]\n",
    "            print(self.X.size())\n",
    "            print(self.U.size())\n",
    "            print(self.V.size())\n",
    "            return torch.matmul(self.U,self.V).t().cpu(), self.nr_of_neurons, self.U.cpu(), self.V.cpu(), cost_lst, self.seed_neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5880, 10103)\n"
     ]
    }
   ],
   "source": [
    "X=sio.loadmat('/home/maria/Documents/EnsemblePursuit/data/natimg2800_M170717_MP034_2017-09-11.mat')['stim']['resp'][0][0]\n",
    "X[X<0]=0\n",
    "print(X.shape)\n",
    "#print(X[0,2])\n",
    "#X=stats.zscore(X+0.0000001,axis=0)\n",
    "#print(X[2940,638])\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#plt.hist(X.flatten(),range=(-1.2,1.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sz torch.Size([5880, 10103])\n",
      "top n 1608 0.5516875386238098\n",
      "ensemble nr 0\n",
      "cost tensor(0.9790, device='cuda:0')\n",
      "top n 5168 0.6076483726501465\n",
      "ensemble nr 1\n",
      "cost tensor(0.9756, device='cuda:0')\n",
      "top n 7728 0.5407932996749878\n",
      "ensemble nr 2\n",
      "cost tensor(0.9716, device='cuda:0')\n",
      "top n 3100 0.58343905210495\n",
      "ensemble nr 3\n",
      "cost tensor(0.9686, device='cuda:0')\n",
      "top n 1489 0.5739583373069763\n",
      "ensemble nr 4\n",
      "cost tensor(0.9648, device='cuda:0')\n",
      "top n 1605 0.532871663570404\n",
      "ensemble nr 5\n",
      "cost tensor(0.9619, device='cuda:0')\n",
      "top n 36 0.5808411240577698\n",
      "ensemble nr 6\n",
      "cost tensor(0.9587, device='cuda:0')\n",
      "top n 2470 0.559316098690033\n",
      "ensemble nr 7\n",
      "cost tensor(0.9553, device='cuda:0')\n",
      "top n 984 0.5784658789634705\n",
      "ensemble nr 8\n",
      "cost tensor(0.9526, device='cuda:0')\n",
      "top n 6422 0.5333208441734314\n",
      "ensemble nr 9\n",
      "cost tensor(0.9501, device='cuda:0')\n",
      "top n 4978 0.5298789739608765\n",
      "ensemble nr 10\n",
      "cost tensor(0.9480, device='cuda:0')\n",
      "top n 3183 0.5145644545555115\n",
      "ensemble nr 11\n",
      "cost tensor(0.9450, device='cuda:0')\n",
      "top n 3230 0.5032902359962463\n",
      "ensemble nr 12\n",
      "cost tensor(0.9424, device='cuda:0')\n",
      "top n 8101 0.5056964159011841\n",
      "ensemble nr 13\n",
      "cost tensor(0.9405, device='cuda:0')\n",
      "top n 1490 0.5232211947441101\n",
      "ensemble nr 14\n",
      "cost tensor(0.9387, device='cuda:0')\n",
      "top n 2470 0.5080247521400452\n",
      "ensemble nr 15\n",
      "cost tensor(0.9368, device='cuda:0')\n",
      "top n 2398 0.5285517573356628\n",
      "ensemble nr 16\n",
      "cost tensor(0.9348, device='cuda:0')\n",
      "top n 3522 0.535610020160675\n",
      "ensemble nr 17\n",
      "cost tensor(0.9327, device='cuda:0')\n",
      "top n 689 0.5553615689277649\n",
      "ensemble nr 18\n",
      "cost tensor(0.9314, device='cuda:0')\n",
      "top n 2329 0.4949810206890106\n",
      "ensemble nr 19\n",
      "cost tensor(0.9299, device='cuda:0')\n",
      "top n 1925 0.6169247627258301\n",
      "ensemble nr 20\n",
      "cost tensor(0.9285, device='cuda:0')\n",
      "top n 3938 0.5056683421134949\n",
      "ensemble nr 21\n",
      "cost tensor(0.9266, device='cuda:0')\n",
      "top n 3100 0.5808704495429993\n",
      "ensemble nr 22\n",
      "cost tensor(0.9251, device='cuda:0')\n",
      "top n 2703 0.5097880959510803\n",
      "ensemble nr 23\n",
      "cost tensor(0.9239, device='cuda:0')\n",
      "top n 833 0.4832151532173157\n",
      "ensemble nr 24\n",
      "cost tensor(0.9226, device='cuda:0')\n",
      "top n 1774 0.5174908638000488\n",
      "ensemble nr 25\n",
      "cost tensor(0.9211, device='cuda:0')\n",
      "top n 4610 0.5008663535118103\n",
      "ensemble nr 26\n",
      "cost tensor(0.9207, device='cuda:0')\n",
      "top n 7335 0.489046186208725\n",
      "ensemble nr 27\n",
      "cost tensor(0.9191, device='cuda:0')\n",
      "top n 6150 0.4904380440711975\n",
      "ensemble nr 28\n",
      "cost tensor(0.9176, device='cuda:0')\n",
      "top n 2650 0.5223018527030945\n",
      "ensemble nr 29\n",
      "cost tensor(0.9172, device='cuda:0')\n",
      "top n 3183 0.5039364695549011\n",
      "ensemble nr 30\n",
      "cost tensor(0.9156, device='cuda:0')\n",
      "top n 4863 0.491630882024765\n",
      "ensemble nr 31\n",
      "cost tensor(0.9152, device='cuda:0')\n",
      "top n 2687 0.48143893480300903\n",
      "ensemble nr 32\n",
      "cost tensor(0.9136, device='cuda:0')\n",
      "top n 3033 0.5092794299125671\n",
      "ensemble nr 33\n",
      "cost tensor(0.9128, device='cuda:0')\n",
      "top n 97 0.472374826669693\n",
      "ensemble nr 34\n",
      "cost tensor(0.9114, device='cuda:0')\n",
      "top n 574 0.5201254487037659\n",
      "ensemble nr 35\n",
      "cost tensor(0.9103, device='cuda:0')\n",
      "top n 4185 0.47534728050231934\n",
      "ensemble nr 36\n",
      "cost tensor(0.9088, device='cuda:0')\n",
      "top n 2331 0.4811226427555084\n",
      "ensemble nr 37\n",
      "cost tensor(0.9070, device='cuda:0')\n",
      "top n 2316 0.5067722797393799\n",
      "ensemble nr 38\n",
      "cost tensor(0.9061, device='cuda:0')\n",
      "top n 3183 0.4992285668849945\n",
      "ensemble nr 39\n",
      "cost tensor(0.9052, device='cuda:0')\n",
      "top n 202 0.5201194882392883\n",
      "ensemble nr 40\n",
      "cost tensor(0.9042, device='cuda:0')\n",
      "top n 519 0.5002273917198181\n",
      "ensemble nr 41\n",
      "cost tensor(0.9030, device='cuda:0')\n",
      "top n 6248 0.4649599492549896\n",
      "ensemble nr 42\n",
      "cost tensor(0.9019, device='cuda:0')\n",
      "top n 1568 0.4642360806465149\n",
      "ensemble nr 43\n",
      "cost tensor(0.9012, device='cuda:0')\n",
      "top n 519 0.4928646981716156\n",
      "ensemble nr 44\n",
      "cost tensor(0.9000, device='cuda:0')\n",
      "top n 529 0.47115325927734375\n",
      "ensemble nr 45\n",
      "cost tensor(0.8989, device='cuda:0')\n",
      "top n 2069 0.4931502044200897\n",
      "ensemble nr 46\n",
      "cost tensor(0.8985, device='cuda:0')\n",
      "top n 2774 0.627129852771759\n",
      "ensemble nr 47\n",
      "cost tensor(0.8974, device='cuda:0')\n",
      "top n 2651 0.4643653929233551\n",
      "ensemble nr 48\n",
      "cost tensor(0.8961, device='cuda:0')\n",
      "top n 735 0.4804610311985016\n",
      "ensemble nr 49\n",
      "cost tensor(0.8957, device='cuda:0')\n",
      "top n 149 0.4610055088996887\n",
      "ensemble nr 50\n",
      "cost tensor(0.8945, device='cuda:0')\n",
      "top n 6422 0.46426820755004883\n",
      "ensemble nr 51\n",
      "cost tensor(0.8933, device='cuda:0')\n",
      "top n 4484 0.4594619870185852\n",
      "ensemble nr 52\n",
      "cost tensor(0.8923, device='cuda:0')\n",
      "top n 223 0.5239571928977966\n",
      "ensemble nr 53\n",
      "cost tensor(0.8913, device='cuda:0')\n",
      "top n 4320 0.455829918384552\n",
      "ensemble nr 54\n",
      "cost tensor(0.8902, device='cuda:0')\n",
      "top n 2716 0.49702736735343933\n",
      "ensemble nr 55\n",
      "cost tensor(0.8895, device='cuda:0')\n",
      "top n 529 0.4554477334022522\n",
      "ensemble nr 56\n",
      "cost tensor(0.8888, device='cuda:0')\n",
      "top n 5890 0.49636659026145935\n",
      "ensemble nr 57\n",
      "cost tensor(0.8880, device='cuda:0')\n",
      "top n 7766 0.4690399169921875\n",
      "ensemble nr 58\n",
      "cost tensor(0.8871, device='cuda:0')\n",
      "top n 196 0.46720343828201294\n",
      "ensemble nr 59\n",
      "cost tensor(0.8862, device='cuda:0')\n",
      "top n 8101 0.482711523771286\n",
      "ensemble nr 60\n",
      "cost tensor(0.8857, device='cuda:0')\n",
      "top n 3962 0.4622185230255127\n",
      "ensemble nr 61\n",
      "cost tensor(0.8846, device='cuda:0')\n",
      "top n 2398 0.47982168197631836\n",
      "ensemble nr 62\n",
      "cost tensor(0.8840, device='cuda:0')\n",
      "top n 196 0.4629283547401428\n",
      "ensemble nr 63\n",
      "cost tensor(0.8834, device='cuda:0')\n",
      "top n 5168 0.48633676767349243\n",
      "ensemble nr 64\n",
      "cost tensor(0.8826, device='cuda:0')\n",
      "top n 3971 0.46709948778152466\n",
      "ensemble nr 65\n",
      "cost tensor(0.8822, device='cuda:0')\n",
      "top n 3917 0.4693187177181244\n",
      "ensemble nr 66\n",
      "cost tensor(0.8819, device='cuda:0')\n",
      "top n 3057 0.46329376101493835\n",
      "ensemble nr 67\n",
      "cost tensor(0.8811, device='cuda:0')\n",
      "top n 2030 0.46411868929862976\n",
      "ensemble nr 68\n",
      "cost tensor(0.8802, device='cuda:0')\n",
      "top n 5168 0.44900599122047424\n",
      "ensemble nr 69\n",
      "cost tensor(0.8794, device='cuda:0')\n",
      "top n 574 0.49459704756736755\n",
      "ensemble nr 70\n",
      "cost tensor(0.8788, device='cuda:0')\n",
      "top n 1747 0.5363368988037109\n",
      "ensemble nr 71\n",
      "cost tensor(0.8781, device='cuda:0')\n",
      "top n 105 0.442922443151474\n",
      "ensemble nr 72\n",
      "cost tensor(0.8770, device='cuda:0')\n",
      "top n 3982 0.45750418305397034\n",
      "ensemble nr 73\n",
      "cost tensor(0.8763, device='cuda:0')\n",
      "top n 3522 0.5133135914802551\n",
      "ensemble nr 74\n",
      "cost tensor(0.8754, device='cuda:0')\n",
      "top n 2233 0.5291087031364441\n",
      "ensemble nr 75\n",
      "cost tensor(0.8747, device='cuda:0')\n",
      "top n 2657 0.5705506801605225\n",
      "ensemble nr 76\n",
      "cost tensor(0.8738, device='cuda:0')\n",
      "top n 833 0.47003450989723206\n",
      "ensemble nr 77\n",
      "cost tensor(0.8731, device='cuda:0')\n",
      "top n 1408 0.4632391631603241\n",
      "ensemble nr 78\n",
      "cost tensor(0.8724, device='cuda:0')\n",
      "top n 3698 0.45952972769737244\n",
      "ensemble nr 79\n",
      "cost tensor(0.8716, device='cuda:0')\n",
      "top n 4097 0.484982967376709\n",
      "ensemble nr 80\n",
      "cost tensor(0.8710, device='cuda:0')\n",
      "top n 2703 0.4727517068386078\n",
      "ensemble nr 81\n",
      "cost tensor(0.8703, device='cuda:0')\n",
      "top n 1283 0.44960346817970276\n",
      "ensemble nr 82\n",
      "cost tensor(0.8699, device='cuda:0')\n",
      "top n 1797 0.4600595533847809\n",
      "ensemble nr 83\n",
      "cost tensor(0.8693, device='cuda:0')\n",
      "top n 149 0.43814513087272644\n",
      "ensemble nr 84\n",
      "cost tensor(0.8686, device='cuda:0')\n",
      "top n 3033 0.4780520498752594\n",
      "ensemble nr 85\n",
      "cost tensor(0.8679, device='cuda:0')\n",
      "top n 2907 0.4936716556549072\n",
      "ensemble nr 86\n",
      "cost tensor(0.8672, device='cuda:0')\n",
      "top n 1408 0.4535268247127533\n",
      "ensemble nr 87\n",
      "cost tensor(0.8668, device='cuda:0')\n",
      "top n 2398 0.43862390518188477\n",
      "ensemble nr 88\n",
      "cost tensor(0.8662, device='cuda:0')\n",
      "top n 803 0.4399094581604004\n",
      "ensemble nr 89\n",
      "cost tensor(0.8655, device='cuda:0')\n",
      "top n 56 0.47186699509620667\n",
      "ensemble nr 90\n",
      "cost tensor(0.8651, device='cuda:0')\n",
      "top n 1988 0.431514710187912\n",
      "ensemble nr 91\n",
      "cost tensor(0.8641, device='cuda:0')\n",
      "top n 3866 0.6165822148323059\n",
      "ensemble nr 92\n",
      "cost tensor(0.8638, device='cuda:0')\n",
      "top n 4822 0.4523603916168213\n",
      "ensemble nr 93\n",
      "cost tensor(0.8634, device='cuda:0')\n",
      "top n 7439 0.47360849380493164\n",
      "ensemble nr 94\n",
      "cost tensor(0.8627, device='cuda:0')\n",
      "top n 1763 0.4995468258857727\n",
      "ensemble nr 95\n",
      "cost tensor(0.8621, device='cuda:0')\n",
      "top n 4204 0.43368640542030334\n",
      "ensemble nr 96\n",
      "cost tensor(0.8615, device='cuda:0')\n",
      "top n 202 0.46781644225120544\n",
      "ensemble nr 97\n",
      "cost tensor(0.8611, device='cuda:0')\n",
      "top n 1481 0.44216805696487427\n",
      "ensemble nr 98\n",
      "cost tensor(0.8604, device='cuda:0')\n",
      "top n 689 0.43348222970962524\n",
      "ensemble nr 99\n",
      "cost tensor(0.8600, device='cuda:0')\n",
      "torch.Size([5880, 10103])\n",
      "torch.Size([10103, 100])\n",
      "torch.Size([100, 5880])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262.2090358734131\n",
      "[7706, 781, 917, 802, 1044, 739, 955, 813, 754, 591, 475, 730, 688, 402, 435, 491, 488, 513, 151, 268, 291, 438, 289, 133, 253, 321, 8, 317, 319, 8, 329, 4, 351, 151, 253, 176, 283, 365, 144, 141, 179, 214, 192, 58, 280, 192, 7, 197, 277, 5, 239, 234, 138, 158, 185, 103, 79, 140, 117, 156, 12, 202, 55, 49, 112, 4, 6, 118, 134, 93, 73, 71, 142, 87, 125, 85, 172, 70, 113, 109, 38, 93, 7, 73, 73, 80, 88, 13, 99, 65, 29, 119, 5, 6, 77, 59, 45, 22, 79, 26]\n",
      "[0.9790144562721252, 0.9756215810775757, 0.9716017246246338, 0.968632698059082, 0.9648038744926453, 0.9618967771530151, 0.9586775898933411, 0.9552889466285706, 0.9525600671768188, 0.9501284956932068, 0.947966992855072, 0.9450409412384033, 0.9423522353172302, 0.9405446648597717, 0.9386520981788635, 0.9368120431900024, 0.9348150491714478, 0.9326952695846558, 0.9314060807228088, 0.929879367351532, 0.9285059571266174, 0.9265608787536621, 0.9250596761703491, 0.9239290952682495, 0.9225829839706421, 0.9211192727088928, 0.9207102060317993, 0.9190828800201416, 0.9175682067871094, 0.9171537160873413, 0.9155669212341309, 0.9152184128761292, 0.9136278629302979, 0.9127662181854248, 0.9113785624504089, 0.9103230834007263, 0.9087911248207092, 0.9070044755935669, 0.9060673117637634, 0.9051806926727295, 0.9042313098907471, 0.9029610753059387, 0.9018661379814148, 0.9012445211410522, 0.8999693393707275, 0.8989130258560181, 0.8985365033149719, 0.8973880410194397, 0.8961026668548584, 0.8957459330558777, 0.8945220708847046, 0.893264651298523, 0.8922935724258423, 0.8912535309791565, 0.8902393579483032, 0.8894827961921692, 0.8888168931007385, 0.8879624605178833, 0.8870832324028015, 0.8861544132232666, 0.8857335448265076, 0.8845995664596558, 0.8839730024337769, 0.8833990693092346, 0.8825709819793701, 0.8822452425956726, 0.8818624019622803, 0.8810924291610718, 0.8802103996276855, 0.8794185519218445, 0.8787707090377808, 0.8780537247657776, 0.8770390748977661, 0.8763218522071838, 0.8754445314407349, 0.8747484683990479, 0.873789370059967, 0.873136043548584, 0.8723610639572144, 0.8715620636940002, 0.8710007071495056, 0.8702623248100281, 0.869924783706665, 0.8693124055862427, 0.8685520887374878, 0.8678799271583557, 0.8671588897705078, 0.8668255805969238, 0.8661666512489319, 0.8654858469963074, 0.8650701642036438, 0.8641476035118103, 0.8637505769729614, 0.8633716106414795, 0.8627256155014038, 0.8621434569358826, 0.8615188598632812, 0.8610686659812927, 0.8603726625442505, 0.8599993586540222]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(7)\n",
    "ep=EnsemblePursuitPyTorch()\n",
    "s=time.time()\n",
    "neuron_init_dict={'method':'top_k_corr','parameters':{'T':10,'n_of_neurons':100}}\n",
    "U_V,nr_of_neurons,U,V, cost_lst,seed_neurons=ep.fit_transform(X,0.01,100,neuron_init_dict)\n",
    "e=time.time()\n",
    "print(e-s)\n",
    "print(nr_of_neurons)\n",
    "print(cost_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2800, 100)\n",
      "torch.Size([5880, 100])\n",
      "torch.Size([100, 2800])\n",
      "mean torch.Size([2800])\n",
      "torch.Size([100, 2800])\n",
      "real torch.Size([2800, 2800])\n",
      "std torch.Size([2800, 2800])\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "(2800, 2800)\n",
      "[[ 0.48389277  0.13106228 -0.01481764 ... -0.0306722   0.24949397\n",
      "   0.01670054]\n",
      " [-0.03882445  0.6263196  -0.15681359 ... -0.0850101   0.41936255\n",
      "  -0.12335168]\n",
      " [ 0.12175509  0.04216132  0.16484174 ... -0.13321646  0.14176479\n",
      "   0.03313031]\n",
      " ...\n",
      " [-0.01193806 -0.1131935  -0.29540166 ...  0.01895166 -0.26015824\n",
      "  -0.09928895]\n",
      " [-0.12130365 -0.13640052  0.2367122  ...  0.03883941 -0.00586061\n",
      "   0.14155532]\n",
      " [-0.06314491 -0.37712082  0.16995601 ...  0.04508706  0.01002807\n",
      "   0.14924286]]\n",
      "0.11321428571428571\n"
     ]
    }
   ],
   "source": [
    "def test_train_split(data,stim):\n",
    "    unique, counts = np.unique(stim.flatten(), return_counts=True)\n",
    "    count_dict=dict(zip(unique, counts))\n",
    "\n",
    "    keys_with_enough_data=[]\n",
    "    for key in count_dict.keys():\n",
    "        if count_dict[key]==2:\n",
    "            keys_with_enough_data.append(key)\n",
    "\n",
    "    filtered_stims=np.isin(stim.flatten(),keys_with_enough_data)\n",
    "\n",
    "    #Arrange data so that responses with the same stimulus are adjacent\n",
    "    z=stim.flatten()[np.where(filtered_stims)[0]]\n",
    "    sortd=np.argsort(z)\n",
    "    istim=np.sort(z)\n",
    "    X=data[filtered_stims,:]\n",
    "    out=X[sortd,:].copy()\n",
    "\n",
    "    x_train=out[::2,:]\n",
    "    y_train=istim[::2]\n",
    "    x_test=out[1::2,:]\n",
    "    y_test=istim[1::2]\n",
    "    \n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "def pearsonr(x, y):\n",
    "    \"\"\"\n",
    "    Mimics `scipy.stats.pearsonr`\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    x : 1D torch.Tensor\n",
    "    y : 1D torch.Tensor\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    r_val : float\n",
    "        pearsonr correlation coefficient between x and y\n",
    "    \n",
    "    Scipy docs ref:\n",
    "        https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.pearsonr.html\n",
    "    \n",
    "    Scipy code ref:\n",
    "        https://github.com/scipy/scipy/blob/v0.19.0/scipy/stats/stats.py#L2975-L3033\n",
    "    Example:\n",
    "        >>> x = np.random.randn(100)\n",
    "        >>> y = np.random.randn(100)\n",
    "        >>> sp_corr = scipy.stats.pearsonr(x, y)[0]\n",
    "        >>> th_corr = pearsonr(torch.from_numpy(x), torch.from_numpy(y))\n",
    "        >>> np.allclose(sp_corr, th_corr)\n",
    "    \"\"\"\n",
    "    mean_x = torch.mean(x)\n",
    "    mean_y = torch.mean(y)\n",
    "    xm = x.sub(mean_x)\n",
    "    ym = y.sub(mean_y)\n",
    "    r_num = xm.dot(ym)\n",
    "    r_den = torch.norm(xm, 2) * torch.norm(ym, 2)\n",
    "    r_val = r_num / r_den\n",
    "    return r_val\n",
    "\n",
    "def corrcoef(x,y):\n",
    "        '''\n",
    "        Torch implementation of the full correlation matrix.\n",
    "        '''\n",
    "        # calculate covariance matrix of columns\n",
    "        mean_x = torch.mean(x,0)\n",
    "        xm = torch.sub(x,mean_x)\n",
    "        mean_y=torch.mean(y,0)\n",
    "        ym=torch.sub(y,mean_y)\n",
    "        c = torch.matmul(x.t(),y)\n",
    "        c = c / (x.size(0))\n",
    "\n",
    "        # normalize covariance matrix\n",
    "        std_x=torch.std(x,0)\n",
    "        std_y=torch.std(y,0)\n",
    "        std=torch.matmul(std_x.view(std_x.size()[0],1),std_y.view(1,std_y.size()[0]))\n",
    "        c = c.div(std)\n",
    "        return c\n",
    "    \n",
    "def evaluate_model(x_train,x_test):\n",
    "    corr_mat=np.zeros((x_train.shape[0],x_train.shape[0]))\n",
    "    for j in range(0,x_train.shape[0]):\n",
    "        for i in range(0,x_test.shape[0]):\n",
    "            corr_mat[j,i]=np.corrcoef(x_train[j,:],x_test[i,:])[0,1]\n",
    "    print(np.mean(np.argmax(corr_mat, axis=0) == np.arange(0,x_train.shape[0],1,int)))\n",
    "    \n",
    "def evaluate_model_torch(x_train,x_test):\n",
    "    x_train=torch.cuda.FloatTensor(x_train).t()\n",
    "    x_test=torch.cuda.FloatTensor(x_test).t()\n",
    "    corr_mat=np.array(corrcoef(x_train,x_test).cpu())\n",
    "    #print(corr_mat.size())\n",
    "    print(corr_mat.shape)\n",
    "    print(corr_mat)\n",
    "    print(np.mean(np.argmax(corr_mat, axis=0) == np.arange(0,x_train.size()[1],1,int)))\n",
    "    \n",
    "stim=sio.loadmat('/home/maria/Documents/EnsemblePursuit/data/natimg2800_M170717_MP034_2017-09-11.mat')['stim']['istim'][0][0]\n",
    "x_train, x_test, y_train, y_test=test_train_split(np.array(V.t()),stim)\n",
    "print(x_train.shape)\n",
    "print(V.t().size())\n",
    "evaluate_model_torch(x_train,x_test)\n",
    "#evaluate_model(x_train,x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "        19.60094   ,  2.7848775 ],\n",
      "       [ 4.320244  ,  4.52501   ,  9.780368  , ...,  0.        ,\n",
      "        70.08017   ,  7.3250747 ],\n",
      "       [17.024296  , 26.734932  , 16.11348   , ..., 24.66158   ,\n",
      "         0.        ,  3.7951417 ],\n",
      "       ...,\n",
      "       [ 0.        ,  0.        ,  0.        , ..., 29.551828  ,\n",
      "        21.59899   ,  0.        ],\n",
      "       [ 0.        , 10.944789  ,  9.216457  , ..., 14.365367  ,\n",
      "         0.        ,  3.9756985 ],\n",
      "       [ 4.130911  , 13.328591  , 12.285298  , ..., 12.446973  ,\n",
      "         0.        ,  0.19337654]], dtype=float32)]]\n"
     ]
    }
   ],
   "source": [
    "spont=sio.loadmat('/home/maria/Documents/EnsemblePursuit/data/natimg2800_M170717_MP034_2017-09-11.mat')['stim']['spont']\n",
    "print(spont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff4c2fba8d0>]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(range(0,100),cost_lst)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
