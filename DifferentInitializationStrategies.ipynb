{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import os\n",
    "import time\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnsemblePursuitPyTorch():\n",
    "    \n",
    "    def zscore(self):\n",
    "        mean_stimuli=self.X.mean(dim=0)\n",
    "        std_stimuli=self.X.std(dim=0)+0.0000000001\n",
    "        \n",
    "        self.X=torch.sub(self.X,mean_stimuli)\n",
    "        self.X=self.X.div(std_stimuli)\n",
    "    \n",
    "    def calculate_cost_delta(self):\n",
    "        cost_delta=torch.clamp(torch.matmul(self.current_v,self.X),min=0,max=None)**2/torch.matmul(self.current_v,self.current_v)-self.lambd\n",
    "        return cost_delta\n",
    "    \n",
    "    def fit_one_assembly(self):\n",
    "        '''\n",
    "        Function for fitting one cell assembly and computing u and v of the currrent assembly (self.current_u,\n",
    "        self.current_v).\n",
    "        One neuron cell assemblies are excluded. \n",
    "        '''\n",
    "        with torch.cuda.device(0) as device:\n",
    "            #Fake i for initiating while loop. self.i stores the number of neurons in assemblies.\n",
    "            self.i=1\n",
    "            #If i is 1, e.g. only one neuron in fit cell assembly, will run fitting the assembly again. \n",
    "            #safety it to avoid infinite loops.\n",
    "            safety_it=0\n",
    "            n_of_neurons=self.neuron_init_dict['parameters']['n_of_neurons']\n",
    "            #a variable to switch to random initialization after finding first assembly if the method is\n",
    "            #selecting neurons from a time point\n",
    "            self.first_assembly=True\n",
    "            while self.i==1:\n",
    "                if self.first_assembly==True:\n",
    "                    top_neurons=self.select_top_neurons()\n",
    "                    self.first_assembly=False\n",
    "                elif self.first_assembly==False and self.neuron_init_dict['method']=='from_time_point':\n",
    "                    self.self.neuron_init_dict['method']='top_k_corr'\n",
    "                    top_neurons=self.select_top_neurons()\n",
    "                elif self.first_assembly==False:\n",
    "                    top_neurons=self.select_top_neurons()\n",
    "                #Array of keeping track of neurons in the cell assembly\n",
    "                self.selected_neurons=torch.zeros([self.sz[1]]).cuda()\n",
    "                for j in range(0,len(top_neurons)):\n",
    "                    self.selected_neurons[top_neurons[j]]=1\n",
    "                #Seed current_v\n",
    "                self.current_v=self.X[:,top_neurons].mean(1).flatten()\n",
    "                #print('shp',self.current_v)\n",
    "                #Fake cost to initiate while loop\n",
    "                max_delta_cost=1000\n",
    "                #reset i\n",
    "                self.i=1\n",
    "                while max_delta_cost>0:\n",
    "                    cost_delta=self.calculate_cost_delta()\n",
    "                    #invert the 0's and 1's in the array which stores which neurons have already \n",
    "                    #been selected into the assembly to use it as a mask\n",
    "                    mask=self.selected_neurons.clone()\n",
    "                    mask[self.selected_neurons==0]=1\n",
    "                    mask[self.selected_neurons!=0]=0\n",
    "                    masked_cost_delta=mask*cost_delta\n",
    "                    values,sorted_neurons=masked_cost_delta.sort()\n",
    "                    max_delta_neuron=sorted_neurons[-1]\n",
    "                    max_delta_cost=values[-1]\n",
    "                    if max_delta_cost>0:\n",
    "                        self.current_v=(self.current_v+self.X[:,max_delta_neuron.item()])/2\n",
    "                        self.selected_neurons[max_delta_neuron.item()]=1\n",
    "                    self.i+=1\n",
    "                safety_it+=1\n",
    "                #Increase number of neurons to sample from if while loop hasn't been finding any assemblies.\n",
    "                if safety_it>100:\n",
    "                    self.neuron_init_dict['parameters']['n_of_neurons']=500\n",
    "                if safety_it>600:\n",
    "                    self.neuron_init_dict['parameters']['n_of_neurons']=1000\n",
    "                if safety_it>1600:\n",
    "                    raise ValueError('Assembly capacity too big, can\\'t fit model')\n",
    "            #Add final seed neuron to seed_neurons.        \n",
    "            self.seed_neurons=self.seed_neurons+top_neurons          \n",
    "            #Calculate u based on final v fit for a cell assembly. \n",
    "            self.current_u=torch.clamp(torch.matmul(self.current_v,self.X),min=0,max=None)/torch.matmul(self.current_v,self.current_v)\n",
    "            self.U=torch.cat((self.U,self.current_u.view(self.X.size(1),1)),1)\n",
    "            self.V=torch.cat((self.V,self.current_v.view(1,self.X.size(0))),0)\n",
    "            \n",
    "    def select_top_neurons(self):\n",
    "        if self.neuron_init_dict['method']=='top_k_corr':\n",
    "            n_of_neurons=self.neuron_init_dict['parameters']['n_of_neurons']\n",
    "            top_neurons,_=self.corr_top_k(n_neurons=n_of_neurons)\n",
    "            top_neurons=self.select_top_k_corr_neuron(top_neurons,_,n_of_neurons)\n",
    "        if self.neuron_init_dict['method']=='random':\n",
    "            top_neurons=[np.random.randint(0,self.sz[1],1)[0]]\n",
    "        if self.neuron_init_dict['method']=='from_time_point':\n",
    "            top_neurons=self.select_from_time_point()\n",
    "        return top_neurons\n",
    "    \n",
    "    def select_from_time_point(self):\n",
    "        threshold=self.neuron_init_dict['parameters']['T']\n",
    "        threshold_array=(self.original_X>=threshold).sum(dim=1)\n",
    "        #print('thr_array',threshold_array)\n",
    "        values,sorted_timepoints=threshold_array.sort()\n",
    "        timepoint=sorted_timepoints[-1]\n",
    "        #print('t',timepoint)\n",
    "        neurons=(self.original_X[timepoint,:]>=threshold).nonzero()\n",
    "        #print('neurons',neurons)\n",
    "        return neurons.tolist()\n",
    "    \n",
    "    def corrcoef(self,x):\n",
    "        '''\n",
    "        Torch implementation of the full correlation matrix.\n",
    "        '''\n",
    "        # calculate covariance matrix of columns\n",
    "        mean_x = torch.mean(x,0)\n",
    "        xm = torch.sub(x,mean_x)\n",
    "        c = x.mm(x.t())\n",
    "        c = c / (x.size(1) - 1)\n",
    "\n",
    "        # normalize covariance matrix\n",
    "        d = torch.diag(c)\n",
    "        stddev = torch.pow(d, 0.5)\n",
    "        c = c.div(stddev.expand_as(c))\n",
    "        c = c.div(stddev.expand_as(c).t())\n",
    "\n",
    "        # clamp between -1 and 1\n",
    "        c = torch.clamp(c, -1.0, 1.0)\n",
    "\n",
    "        return c\n",
    "    \n",
    "    def corr_top_k(self,n_neurons=100):\n",
    "        '''\n",
    "        Finds n_neurons neurons that are on average most correlated to their \n",
    "        5 closest neighbors.\n",
    "        '''\n",
    "        #Compute full correlation matrix (works with one neuron per column,\n",
    "        #so have to transpose.)\n",
    "        corr=self.corrcoef(self.X.t())\n",
    "        #Sorts each row of correlation matrix\n",
    "        vals,ix=corr.sort(dim=1)\n",
    "        #Discards the last entry corresponding to the diagonal 1 and then\n",
    "        #selects 5 of the largest entries from sorted array.\n",
    "        top_vals=vals[:,:-1][:,self.sz[1]-6:]\n",
    "        #Averages the 5 top correlations.\n",
    "        av=torch.mean(top_vals,dim=1)\n",
    "        #Sorts the averages\n",
    "        vals,top_neurons=torch.sort(av)\n",
    "        #Selects top neurons\n",
    "        top_neuron=top_neurons[self.sz[1]-(n_neurons+1):]\n",
    "        top_val=vals[self.sz[1]-(n_neurons+1):]\n",
    "        return top_neuron,top_val\n",
    "          \n",
    "    \n",
    "    def select_top_k_corr_neuron(self,top_neuron,top_val,n_neurons=100):\n",
    "        '''\n",
    "        Randomly samples from k top correlated urons.\n",
    "        '''\n",
    "        #Randomly samples a neuron from the n_of_neurons top correlated.\n",
    "        idx=torch.randint(0,n_neurons,size=(1,))\n",
    "        print('top n', top_neuron[idx[0]].item(), top_val[idx[0]].item())\n",
    "        return [top_neuron[idx[0]].item()]\n",
    "    \n",
    "    \n",
    "    def fit_transform(self,X,lambd,n_ensembles,neuron_init_dict):\n",
    "        torch.manual_seed(7)\n",
    "        with torch.cuda.device(0) as device:\n",
    "            self.neuron_init_dict=neuron_init_dict\n",
    "            self.lambd=lambd\n",
    "            #Creates cuda tensor from data\n",
    "            self.X=torch.cuda.FloatTensor(X)\n",
    "            #z-score data.\n",
    "            self.zscore()\n",
    "            #Keep original data for one type of initialization\n",
    "            if self.neuron_init_dict['method']=='from_time_point':\n",
    "                self.original_X=self.X.clone()\n",
    "            #Store dimensionality of X for later use.\n",
    "            self.sz=self.X.size()\n",
    "            print('sz',self.sz)\n",
    "            #Initializes U and V with zeros, later these will be discarded.\n",
    "            self.U=torch.zeros((self.X.size(1),1)).cuda()\n",
    "            self.V=torch.zeros([1,self.X.size(0)]).cuda()\n",
    "            #List for storing the number of neurons in each fit assembly.\n",
    "            self.nr_of_neurons=[]\n",
    "            #List for storing the seed neurons for each assembly.\n",
    "            self.seed_neurons=[]\n",
    "            cost_lst=[]\n",
    "            for iteration in range(0,n_ensembles):\n",
    "                self.fit_one_assembly()\n",
    "                self.nr_of_neurons.append(self.i)\n",
    "                U_V=torch.mm(self.current_u.view(self.sz[1],1),self.current_v.view(1,self.sz[0]))\n",
    "                U_V[U_V != U_V] = 0\n",
    "                res=(self.X-U_V.t())\n",
    "                self.X=res\n",
    "                if iteration==441:\n",
    "                    print('res',res)\n",
    "                    print((res!=res).nonzero())\n",
    "                print('ensemble nr', iteration)\n",
    "                #print('u',self.current_u)\n",
    "                #print('v',self.current_v)\n",
    "                #print('length v', torch.matmul(self.current_v,self.current_v))\n",
    "                #print('norm',torch.norm(self.X))\n",
    "                self.cost=torch.mean(torch.mul(res,res))\n",
    "                print('cost',self.cost)\n",
    "                cost_lst.append(self.cost.item())\n",
    "            #After fitting arrays discard the zero initialization rows and columns from U and V.\n",
    "            self.U=self.U[:,1:]\n",
    "            self.V=self.V[1:,:]\n",
    "            print(self.X.size())\n",
    "            print(self.U.size())\n",
    "            print(self.V.size())\n",
    "            return torch.matmul(self.U,self.V).t().cpu(), self.nr_of_neurons, self.U.cpu(), self.V.cpu(), cost_lst, self.seed_neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5880, 10103)\n"
     ]
    }
   ],
   "source": [
    "X=sio.loadmat('/home/maria/Documents/EnsemblePursuit/data/natimg2800_M170717_MP034_2017-09-11.mat')['stim']['resp'][0][0]\n",
    "X[X<0]=0\n",
    "print(X.shape)\n",
    "#print(X[0,2])\n",
    "#X=stats.zscore(X+0.0000001,axis=0)\n",
    "#print(X[2940,638])\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#plt.hist(X.flatten(),range=(-1.2,1.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sz torch.Size([5880, 10103])\n",
      "top n 1608 0.5516875386238098\n",
      "ensemble nr 0\n",
      "cost tensor(0.9983, device='cuda:0')\n",
      "top n 7766 0.6151697039604187\n",
      "ensemble nr 1\n",
      "cost tensor(0.9972, device='cuda:0')\n",
      "top n 4978 0.5523561835289001\n",
      "ensemble nr 2\n",
      "cost tensor(0.9962, device='cuda:0')\n",
      "top n 2831 0.6011964082717896\n",
      "ensemble nr 3\n",
      "cost tensor(0.9947, device='cuda:0')\n",
      "top n 3522 0.5949273109436035\n",
      "ensemble nr 4\n",
      "cost tensor(0.9932, device='cuda:0')\n",
      "top n 2205 0.5659705996513367\n",
      "ensemble nr 5\n",
      "cost tensor(0.9924, device='cuda:0')\n",
      "top n 1747 0.6020787358283997\n",
      "ensemble nr 6\n",
      "cost tensor(0.9911, device='cuda:0')\n",
      "top n 788 0.5871729254722595\n",
      "ensemble nr 7\n",
      "cost tensor(0.9898, device='cuda:0')\n",
      "top n 1747 0.602094829082489\n",
      "ensemble nr 8\n",
      "cost tensor(0.9890, device='cuda:0')\n",
      "top n 3433 0.5721320509910583\n",
      "ensemble nr 9\n",
      "cost tensor(0.9879, device='cuda:0')\n",
      "top n 2907 0.5692064166069031\n",
      "ensemble nr 10\n",
      "cost tensor(0.9863, device='cuda:0')\n",
      "top n 6415 0.5507308840751648\n",
      "ensemble nr 11\n",
      "cost tensor(0.9847, device='cuda:0')\n",
      "top n 699 0.5392265319824219\n",
      "ensemble nr 12\n",
      "cost tensor(0.9833, device='cuda:0')\n",
      "top n 6450 0.5424861311912537\n",
      "ensemble nr 13\n",
      "cost tensor(0.9817, device='cuda:0')\n",
      "top n 7685 0.5676639676094055\n",
      "ensemble nr 14\n",
      "cost tensor(0.9804, device='cuda:0')\n",
      "top n 6415 0.5448682904243469\n",
      "ensemble nr 15\n",
      "cost tensor(0.9791, device='cuda:0')\n",
      "top n 2907 0.5672569274902344\n",
      "ensemble nr 16\n",
      "cost tensor(0.9779, device='cuda:0')\n",
      "top n 2628 0.5690738558769226\n",
      "ensemble nr 17\n",
      "cost tensor(0.9767, device='cuda:0')\n",
      "top n 2422 0.5827426314353943\n",
      "ensemble nr 18\n",
      "cost tensor(0.9757, device='cuda:0')\n",
      "top n 3106 0.5374171137809753\n",
      "ensemble nr 19\n",
      "cost tensor(0.9746, device='cuda:0')\n",
      "top n 1747 0.602055013179779\n",
      "ensemble nr 20\n",
      "cost tensor(0.9739, device='cuda:0')\n",
      "top n 9367 0.5448437929153442\n",
      "ensemble nr 21\n",
      "cost tensor(0.9724, device='cuda:0')\n",
      "top n 2831 0.5979399085044861\n",
      "ensemble nr 22\n",
      "cost tensor(0.9712, device='cuda:0')\n",
      "top n 2342 0.5505902171134949\n",
      "ensemble nr 23\n",
      "cost tensor(0.9700, device='cuda:0')\n",
      "top n 6161 0.5260971188545227\n",
      "ensemble nr 24\n",
      "cost tensor(0.9689, device='cuda:0')\n",
      "top n 9391 0.5589247345924377\n",
      "ensemble nr 25\n",
      "cost tensor(0.9680, device='cuda:0')\n",
      "top n 6415 0.5417442917823792\n",
      "ensemble nr 26\n",
      "cost tensor(0.9670, device='cuda:0')\n",
      "top n 3570 0.5329250693321228\n",
      "ensemble nr 27\n",
      "cost tensor(0.9664, device='cuda:0')\n",
      "top n 9777 0.5344419479370117\n",
      "ensemble nr 28\n",
      "cost tensor(0.9655, device='cuda:0')\n",
      "top n 2628 0.5682411193847656\n",
      "ensemble nr 29\n",
      "cost tensor(0.9647, device='cuda:0')\n",
      "top n 2479 0.5460273027420044\n",
      "ensemble nr 30\n",
      "cost tensor(0.9637, device='cuda:0')\n",
      "top n 1830 0.5362727046012878\n",
      "ensemble nr 31\n",
      "cost tensor(0.9629, device='cuda:0')\n",
      "top n 3838 0.5240196585655212\n",
      "ensemble nr 32\n",
      "cost tensor(0.9620, device='cuda:0')\n",
      "top n 2295 0.5516299605369568\n",
      "ensemble nr 33\n",
      "cost tensor(0.9613, device='cuda:0')\n",
      "top n 2192 0.5215362310409546\n",
      "ensemble nr 34\n",
      "cost tensor(0.9603, device='cuda:0')\n",
      "top n 833 0.5637120008468628\n",
      "ensemble nr 35\n",
      "cost tensor(0.9596, device='cuda:0')\n",
      "top n 89 0.52334064245224\n",
      "ensemble nr 36\n",
      "cost tensor(0.9590, device='cuda:0')\n",
      "top n 6954 0.5261133313179016\n",
      "ensemble nr 37\n",
      "cost tensor(0.9583, device='cuda:0')\n",
      "top n 905 0.5509058833122253\n",
      "ensemble nr 38\n",
      "cost tensor(0.9578, device='cuda:0')\n",
      "top n 7728 0.5468804240226746\n",
      "ensemble nr 39\n",
      "cost tensor(0.9570, device='cuda:0')\n",
      "top n 2628 0.5655251145362854\n",
      "ensemble nr 40\n",
      "cost tensor(0.9557, device='cuda:0')\n",
      "top n 905 0.5467689037322998\n",
      "ensemble nr 41\n",
      "cost tensor(0.9551, device='cuda:0')\n",
      "top n 2619 0.5170339941978455\n",
      "ensemble nr 42\n",
      "cost tensor(0.9544, device='cuda:0')\n",
      "top n 3442 0.5152128338813782\n",
      "ensemble nr 43\n",
      "cost tensor(0.9537, device='cuda:0')\n",
      "top n 1041 0.5378713011741638\n",
      "ensemble nr 44\n",
      "cost tensor(0.9528, device='cuda:0')\n",
      "top n 4680 0.5216113328933716\n",
      "ensemble nr 45\n",
      "cost tensor(0.9522, device='cuda:0')\n",
      "top n 149 0.5403587222099304\n",
      "ensemble nr 46\n",
      "cost tensor(0.9514, device='cuda:0')\n",
      "top n 1763 0.6042097210884094\n",
      "ensemble nr 47\n",
      "cost tensor(0.9505, device='cuda:0')\n",
      "top n 923 0.5157985687255859\n",
      "ensemble nr 48\n",
      "cost tensor(0.9493, device='cuda:0')\n",
      "top n 3505 0.5289757251739502\n",
      "ensemble nr 49\n",
      "cost tensor(0.9486, device='cuda:0')\n",
      "top n 788 0.5144066214561462\n",
      "ensemble nr 50\n",
      "cost tensor(0.9477, device='cuda:0')\n",
      "top n 6451 0.5191890001296997\n",
      "ensemble nr 51\n",
      "cost tensor(0.9469, device='cuda:0')\n",
      "top n 4403 0.5131217241287231\n",
      "ensemble nr 52\n",
      "cost tensor(0.9464, device='cuda:0')\n",
      "top n 3522 0.5660856366157532\n",
      "ensemble nr 53\n",
      "cost tensor(0.9458, device='cuda:0')\n",
      "top n 9849 0.5101889967918396\n",
      "ensemble nr 54\n",
      "cost tensor(0.9449, device='cuda:0')\n",
      "top n 4097 0.5463826656341553\n",
      "ensemble nr 55\n",
      "cost tensor(0.9442, device='cuda:0')\n",
      "top n 3681 0.5100330710411072\n",
      "ensemble nr 56\n",
      "cost tensor(0.9438, device='cuda:0')\n",
      "top n 2398 0.5451080203056335\n",
      "ensemble nr 57\n",
      "cost tensor(0.9431, device='cuda:0')\n",
      "top n 7234 0.52277672290802\n",
      "ensemble nr 58\n",
      "cost tensor(0.9424, device='cuda:0')\n",
      "top n 7234 0.5228166580200195\n",
      "ensemble nr 59\n",
      "cost tensor(0.9414, device='cuda:0')\n",
      "top n 1672 0.5285670757293701\n",
      "ensemble nr 60\n",
      "cost tensor(0.9405, device='cuda:0')\n",
      "top n 8946 0.5169894695281982\n",
      "ensemble nr 61\n",
      "cost tensor(0.9399, device='cuda:0')\n",
      "top n 1616 0.53034508228302\n",
      "ensemble nr 62\n",
      "cost tensor(0.9393, device='cuda:0')\n",
      "top n 574 0.5197151303291321\n",
      "ensemble nr 63\n",
      "cost tensor(0.9386, device='cuda:0')\n",
      "top n 149 0.5397207140922546\n",
      "ensemble nr 64\n",
      "cost tensor(0.9380, device='cuda:0')\n",
      "top n 519 0.5223322510719299\n",
      "ensemble nr 65\n",
      "cost tensor(0.9374, device='cuda:0')\n",
      "top n 3505 0.5226914286613464\n",
      "ensemble nr 66\n",
      "cost tensor(0.9369, device='cuda:0')\n",
      "top n 3962 0.5203584432601929\n",
      "ensemble nr 67\n",
      "cost tensor(0.9362, device='cuda:0')\n",
      "top n 3838 0.5222129225730896\n",
      "ensemble nr 68\n",
      "cost tensor(0.9352, device='cuda:0')\n",
      "top n 7439 0.5076047778129578\n",
      "ensemble nr 69\n",
      "cost tensor(0.9344, device='cuda:0')\n",
      "top n 3230 0.5496949553489685\n",
      "ensemble nr 70\n",
      "cost tensor(0.9339, device='cuda:0')\n",
      "top n 2657 0.5780618786811829\n",
      "ensemble nr 71\n",
      "cost tensor(0.9334, device='cuda:0')\n",
      "top n 3106 0.5038057565689087\n",
      "ensemble nr 72\n",
      "cost tensor(0.9326, device='cuda:0')\n",
      "top n 8946 0.5175408720970154\n",
      "ensemble nr 73\n",
      "cost tensor(0.9320, device='cuda:0')\n",
      "top n 223 0.568017303943634\n",
      "ensemble nr 74\n",
      "cost tensor(0.9308, device='cuda:0')\n",
      "top n 984 0.5744115710258484\n",
      "ensemble nr 75\n",
      "cost tensor(0.9302, device='cuda:0')\n",
      "top n 1763 0.5792221426963806\n",
      "ensemble nr 76\n",
      "cost tensor(0.9297, device='cuda:0')\n",
      "top n 1506 0.5247929096221924\n",
      "ensemble nr 77\n",
      "cost tensor(0.9293, device='cuda:0')\n",
      "top n 1490 0.5243352651596069\n",
      "ensemble nr 78\n",
      "cost tensor(0.9285, device='cuda:0')\n",
      "top n 2295 0.5212069749832153\n",
      "ensemble nr 79\n",
      "cost tensor(0.9279, device='cuda:0')\n",
      "top n 149 0.5414451956748962\n",
      "ensemble nr 80\n",
      "cost tensor(0.9273, device='cuda:0')\n",
      "top n 2479 0.5315736532211304\n",
      "ensemble nr 81\n",
      "cost tensor(0.9265, device='cuda:0')\n",
      "top n 4132 0.5121439695358276\n",
      "ensemble nr 82\n",
      "cost tensor(0.9261, device='cuda:0')\n",
      "top n 1506 0.5237946510314941\n",
      "ensemble nr 83\n",
      "cost tensor(0.9256, device='cuda:0')\n",
      "top n 3340 0.5011118650436401\n",
      "ensemble nr 84\n",
      "cost tensor(0.9250, device='cuda:0')\n",
      "top n 5168 0.5360309481620789\n",
      "ensemble nr 85\n",
      "cost tensor(0.9243, device='cuda:0')\n",
      "top n 2422 0.5488371253013611\n",
      "ensemble nr 86\n",
      "cost tensor(0.9234, device='cuda:0')\n",
      "top n 2192 0.5164100527763367\n",
      "ensemble nr 87\n",
      "cost tensor(0.9225, device='cuda:0')\n",
      "top n 4096 0.4999265670776367\n",
      "ensemble nr 88\n",
      "cost tensor(0.9219, device='cuda:0')\n",
      "top n 2192 0.5016220808029175\n",
      "ensemble nr 89\n",
      "cost tensor(0.9210, device='cuda:0')\n",
      "top n 4978 0.5305209159851074\n",
      "ensemble nr 90\n",
      "cost tensor(0.9204, device='cuda:0')\n",
      "top n 3238 0.49750813841819763\n",
      "ensemble nr 91\n",
      "cost tensor(0.9199, device='cuda:0')\n",
      "top n 1747 0.5842310190200806\n",
      "ensemble nr 92\n",
      "cost tensor(0.9192, device='cuda:0')\n",
      "top n 5379 0.5173530578613281\n",
      "ensemble nr 93\n",
      "cost tensor(0.9184, device='cuda:0')\n",
      "top n 149 0.5397331118583679\n",
      "ensemble nr 94\n",
      "cost tensor(0.9176, device='cuda:0')\n",
      "top n 7766 0.5726880431175232\n",
      "ensemble nr 95\n",
      "cost tensor(0.9169, device='cuda:0')\n",
      "top n 2192 0.5010207295417786\n",
      "ensemble nr 96\n",
      "cost tensor(0.9164, device='cuda:0')\n",
      "top n 3033 0.5397018790245056\n",
      "ensemble nr 97\n",
      "cost tensor(0.9156, device='cuda:0')\n",
      "top n 231 0.5089727640151978\n",
      "ensemble nr 98\n",
      "cost tensor(0.9148, device='cuda:0')\n",
      "top n 7234 0.5023193359375\n",
      "ensemble nr 99\n",
      "cost tensor(0.9139, device='cuda:0')\n",
      "torch.Size([5880, 10103])\n",
      "torch.Size([10103, 100])\n",
      "torch.Size([100, 5880])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166.15873456001282\n",
      "[489, 280, 378, 286, 162, 342, 423, 528, 879, 538, 182, 444, 5, 203, 325, 469, 489, 253, 185, 142, 338, 253, 339, 60, 66, 358, 26, 7, 430, 337, 232, 7, 59, 153, 331, 269, 56, 223, 260, 252, 177, 312, 4, 41, 7, 247, 130, 156, 205, 219, 25, 116, 192, 202, 54, 125, 7, 149, 192, 259, 201, 61, 166, 24, 117, 67, 7, 125, 79, 101, 166, 5, 70, 145, 252, 198, 92, 106, 10, 47, 43, 80, 54, 46, 163, 58, 119, 14, 165, 66, 24, 81, 91, 148, 54, 123, 25, 88, 36, 127]\n",
      "[0.9982699155807495, 0.9972298741340637, 0.9962355494499207, 0.9946871995925903, 0.9931973814964294, 0.992392361164093, 0.9910662770271301, 0.9898481965065002, 0.9889543652534485, 0.9878562688827515, 0.9863051772117615, 0.9846845865249634, 0.9832974672317505, 0.9817129373550415, 0.980440616607666, 0.9791320562362671, 0.9779412746429443, 0.9766851663589478, 0.9756861925125122, 0.9745945930480957, 0.9739111661911011, 0.972445011138916, 0.971204400062561, 0.9699748158454895, 0.968870997428894, 0.968004584312439, 0.9670141339302063, 0.9663633108139038, 0.9654893279075623, 0.964656412601471, 0.9637121558189392, 0.962875247001648, 0.9620419144630432, 0.9613052010536194, 0.9602946639060974, 0.9595942497253418, 0.9589893817901611, 0.9582918882369995, 0.9577569961547852, 0.9569785594940186, 0.955724835395813, 0.9550521373748779, 0.9543524384498596, 0.9536553025245667, 0.9527695775032043, 0.9521917700767517, 0.9513628482818604, 0.9504985809326172, 0.9493281841278076, 0.9485715627670288, 0.9476619362831116, 0.9469154477119446, 0.9464151859283447, 0.9457827806472778, 0.9449388384819031, 0.9441905617713928, 0.9437673687934875, 0.9430772662162781, 0.9424024820327759, 0.9413625597953796, 0.9405327439308167, 0.9399145841598511, 0.939319908618927, 0.9386358261108398, 0.9380379915237427, 0.9374371767044067, 0.9368695616722107, 0.9361802339553833, 0.935210108757019, 0.9344368577003479, 0.9339141249656677, 0.9333575367927551, 0.9325553178787231, 0.9319507479667664, 0.9308387637138367, 0.9302005767822266, 0.9296768307685852, 0.9292508959770203, 0.9285387992858887, 0.9278790354728699, 0.9272559285163879, 0.9265424013137817, 0.9260576963424683, 0.9255521297454834, 0.9249817728996277, 0.9242794513702393, 0.9233875274658203, 0.9224651455879211, 0.9218770861625671, 0.9210491180419922, 0.920420229434967, 0.9198722243309021, 0.9192013144493103, 0.9183910489082336, 0.9176360964775085, 0.9169484972953796, 0.9163537621498108, 0.9155795574188232, 0.9147900938987732, 0.9138810038566589]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(7)\n",
    "ep=EnsemblePursuitPyTorch()\n",
    "s=time.time()\n",
    "neuron_init_dict={'method':'top_k_corr','parameters':{'T':10,'n_of_neurons':100}}\n",
    "U_V,nr_of_neurons,U,V, cost_lst,seed_neurons=ep.fit_transform(X,300,100,neuron_init_dict)\n",
    "e=time.time()\n",
    "print(e-s)\n",
    "print(nr_of_neurons)\n",
    "print(cost_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_train_split(data,stim):\n",
    "    unique, counts = np.unique(stim.flatten(), return_counts=True)\n",
    "    count_dict=dict(zip(unique, counts))\n",
    "\n",
    "    keys_with_enough_data=[]\n",
    "    for key in count_dict.keys():\n",
    "        if count_dict[key]==2:\n",
    "            keys_with_enough_data.append(key)\n",
    "\n",
    "    filtered_stims=np.isin(stim.flatten(),keys_with_enough_data)\n",
    "\n",
    "    #Arrange data so that responses with the same stimulus are adjacent\n",
    "    z=stim.flatten()[np.where(filtered_stims)[0]]\n",
    "    sortd=np.argsort(z)\n",
    "    istim=np.sort(z)\n",
    "    X=data[filtered_stims,:]\n",
    "    out=X[sortd,:].copy()\n",
    "\n",
    "    x_train=out[::2,:]\n",
    "    y_train=istim[::2]\n",
    "    x_test=out[1::2,:]\n",
    "    y_test=istim[1::2]\n",
    "    \n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "def evaluate_model(x_train,x_test):\n",
    "    corr_mat=np.zeros((x_train.shape[0],x_train.shape[0]))\n",
    "    for j in range(0,x_train.shape[0]):\n",
    "        for i in range(0,x_test.shape[0]):\n",
    "            corr_mat[j,i]=np.corrcoef(x_train[j,:],x_test[i,:])[0,1]\n",
    "    print(np.mean(np.argmax(corr_mat, axis=0) == np.arange(0,x_train.shape[0],1,int)))\n",
    "    \n",
    "stim=sio.loadmat('/home/maria/Documents/EnsemblePursuit/data/natimg2800_M170717_MP034_2017-09-11.mat')['stim']['istim'][0][0]\n",
    "x_train, x_test, y_train, y_test=test_train_split(np.array(V.t()),stim)\n",
    "evaluate_model(x_train,x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fef06d32b38>]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(range(0,100),cost_lst)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
