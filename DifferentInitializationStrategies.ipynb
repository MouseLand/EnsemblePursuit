{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import os\n",
    "import time\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnsemblePursuitPyTorch():\n",
    "    \n",
    "    def zscore(self):\n",
    "        mean_stimuli=self.X.mean(dim=0)\n",
    "        std_stimuli=self.X.std(dim=0)+0.0000000001\n",
    "        \n",
    "        self.X=torch.sub(self.X,mean_stimuli)\n",
    "        self.X=self.X.div(std_stimuli)\n",
    "    \n",
    "    def calculate_cost_delta(self):\n",
    "        cost_delta=(torch.clamp(torch.matmul(self.current_v,self.X),min=0,max=None)**2)/(self.sz[0]*torch.matmul(self.current_v,self.current_v))-self.lambd\n",
    "        #print('cost delta',cost_delta.mean())\n",
    "        return cost_delta\n",
    "    \n",
    "    def fit_one_assembly(self):\n",
    "        '''\n",
    "        Function for fitting one cell assembly and computing u and v of the currrent assembly (self.current_u,\n",
    "        self.current_v).\n",
    "        One neuron cell assemblies are excluded. \n",
    "        '''\n",
    "        with torch.cuda.device(0) as device:\n",
    "            #Fake i for initiating while loop. self.i stores the number of neurons in assemblies.\n",
    "            self.i=7\n",
    "            #If i is 1, e.g. only one neuron in fit cell assembly, will run fitting the assembly again. \n",
    "            #safety it to avoid infinite loops.\n",
    "            safety_it=0\n",
    "            n_of_neurons=self.neuron_init_dict['parameters']['n_of_neurons']\n",
    "            min_assembly_size=self.neuron_init_dict['parameters']['min_assembly_size']\n",
    "            #Correlate correlation matrix if top_k_corr method of assembly initialization, because\n",
    "            #then sampling will be better\n",
    "            if self.neuron_init_dict['method']=='top_k_corr':\n",
    "                self.for_sampling,self.vals=self.corr_top_k(n_neurons=n_of_neurons)\n",
    "            #Reject assemblies with less than 8 neurons\n",
    "            while self.i<min_assembly_size:\n",
    "                if self.first_assembly==True:\n",
    "                    top_neurons=self.select_top_neurons()\n",
    "                elif self.first_assembly==False and self.neuron_init_dict['method']=='from_time_point':\n",
    "                    self.neuron_init_dict['method']='top_k_corr'\n",
    "                    top_neurons=self.select_top_neurons()\n",
    "                elif self.first_assembly==False:\n",
    "                    top_neurons=self.select_top_neurons()\n",
    "                #Array of keeping track of neurons in the cell assembly\n",
    "                self.selected_neurons=torch.zeros([self.sz[1]]).cuda()\n",
    "                for j in range(0,len(top_neurons)):\n",
    "                    self.selected_neurons[top_neurons[j]]=1\n",
    "                #Seed current_v\n",
    "                self.current_v=self.X[:,top_neurons].mean(1).flatten()\n",
    "                #Fake cost to initiate while loop\n",
    "                max_delta_cost=1000\n",
    "                #reset i\n",
    "                self.i=1\n",
    "                #while max_delta_cost>0 and self.i<=1000:\n",
    "                while max_delta_cost>0:\n",
    "                    cost_delta=self.calculate_cost_delta()\n",
    "                    #invert the 0's and 1's in the array which stores which neurons have already \n",
    "                    #been selected into the assembly to use it as a mask\n",
    "                    mask=self.selected_neurons.clone()\n",
    "                    mask[self.selected_neurons==0]=1\n",
    "                    mask[self.selected_neurons!=0]=0\n",
    "                    masked_cost_delta=mask*cost_delta\n",
    "                    values,sorted_neurons=masked_cost_delta.sort()\n",
    "                    max_delta_neuron=sorted_neurons[-1]\n",
    "                    max_delta_cost=values[-1]\n",
    "                    if max_delta_cost>0:\n",
    "                        self.selected_neurons[max_delta_neuron.item()]=1\n",
    "                        self.current_v= self.X[:, (self.selected_neurons == 1)].mean(dim=1)\n",
    "                        #print('sel neurons', self.X[:, (self.selected_neurons == 1)].size())\n",
    "                    self.i+=1\n",
    "                safety_it+=1\n",
    "                #Increase number of neurons to sample from if while loop hasn't been finding any assemblies.\n",
    "                if safety_it>100:\n",
    "                    self.neuron_init_dict['parameters']['n_of_neurons']=500\n",
    "                    if self.neuron_init_dict['method']=='top_k_corr':\n",
    "                        self.for_sampling,self.vals=self.corr_top_k(n_neurons=500)\n",
    "                if safety_it>600:\n",
    "                    self.neuron_init_dict['parameters']['n_of_neurons']=1000\n",
    "                    if self.neuron_init_dict['method']=='top_k_corr':\n",
    "                        self.for_sampling,self.vals=self.corr_top_k(n_neurons=1000)\n",
    "                if safety_it>1600:\n",
    "                    raise ValueError('Assembly capacity too big, can\\'t fit model')\n",
    "            #Once one assembly has been found, set the variable to false\n",
    "            self.first_assembly=False\n",
    "            #Add final seed neuron to seed_neurons.        \n",
    "            self.seed_neurons=self.seed_neurons+top_neurons          \n",
    "            #Calculate u based on final v fit for a cell assembly. \n",
    "            self.current_u=torch.clamp(torch.matmul(self.current_v,self.X),min=0,max=None)/torch.matmul(self.current_v,self.current_v)\n",
    "            self.U=torch.cat((self.U,self.current_u.view(self.X.size(1),1)),1)\n",
    "            self.V=torch.cat((self.V,self.current_v.view(1,self.X.size(0))),0)\n",
    "            \n",
    "    def select_top_neurons(self):\n",
    "        if self.neuron_init_dict['method']=='top_k_corr':\n",
    "            n_of_neurons=self.neuron_init_dict['parameters']['n_of_neurons']\n",
    "            top_neurons=self.select_top_k_corr_neuron(self.for_sampling,self.vals,n_of_neurons)\n",
    "        if self.neuron_init_dict['method']=='random':\n",
    "            top_neurons=[np.random.randint(0,self.sz[1],1)[0]]\n",
    "        if self.neuron_init_dict['method']=='from_time_point':\n",
    "            top_neurons=self.select_from_time_point()\n",
    "        return top_neurons\n",
    "    \n",
    "    def select_from_time_point(self):\n",
    "        threshold=self.neuron_init_dict['parameters']['T']\n",
    "        threshold_array=(self.original_X>=threshold).sum(dim=1)\n",
    "        #print('thr_array',threshold_array)\n",
    "        values,sorted_timepoints=threshold_array.sort()\n",
    "        timepoint=sorted_timepoints[-1]\n",
    "        #print('t',timepoint)\n",
    "        neurons=(self.original_X[timepoint,:]>=threshold).nonzero()\n",
    "        #print('neurons',neurons)\n",
    "        return neurons.tolist()\n",
    "    \n",
    "    def corrcoef(self,x):\n",
    "        '''\n",
    "        Torch implementation of the full correlation matrix.\n",
    "        '''\n",
    "        # calculate covariance matrix of columns\n",
    "        mean_x = torch.mean(x,0)\n",
    "        xm = torch.sub(x,mean_x)\n",
    "        c = x.mm(x.t())\n",
    "        c = c / (x.size(1))\n",
    "\n",
    "        # normalize covariance matrix\n",
    "        d = torch.diag(c)\n",
    "        stddev = torch.pow(d, 0.5)\n",
    "        c = c.div(stddev.expand_as(c))\n",
    "        c = c.div(stddev.expand_as(c).t())\n",
    "        #print((c!=c).nonzero())\n",
    "        # clamp between -1 and 1\n",
    "        c = torch.clamp(c, -1.0, 1.0)\n",
    "\n",
    "        return c\n",
    "    \n",
    "    def corr_top_k(self,n_neurons=100):\n",
    "        '''\n",
    "        Finds n_neurons neurons that are on average most correlated to their \n",
    "        5 closest neighbors.\n",
    "        '''\n",
    "        #Compute full correlation matrix (works with one neuron per column,\n",
    "        #so have to transpose.)\n",
    "        corr=self.corrcoef(self.X.t())\n",
    "        #Sorts each row of correlation matrix\n",
    "        vals,ix=corr.sort(dim=1)\n",
    "        #Discards the last entry corresponding to the diagonal 1 and then\n",
    "        #selects 5 of the largest entries from sorted array.\n",
    "        top_vals=vals[:,:-1][:,self.sz[1]-6:]\n",
    "        #Averages the 5 top correlations.\n",
    "        av=torch.mean(top_vals,dim=1)\n",
    "        #Sorts the averages\n",
    "        vals,top_neurons=torch.sort(av)\n",
    "        #Selects top neurons\n",
    "        top_neuron=top_neurons[self.sz[1]-(n_neurons+1):]\n",
    "        top_val=vals[self.sz[1]-(n_neurons+1):]\n",
    "        return top_neuron,top_val\n",
    "          \n",
    "    \n",
    "    def select_top_k_corr_neuron(self,top_neuron,top_val,n_neurons=100):\n",
    "        '''\n",
    "        Randomly samples from k top correlated urons.\n",
    "        '''\n",
    "        #Randomly samples a neuron from the n_of_neurons top correlated.\n",
    "        idx=torch.randint(0,n_neurons,size=(1,))\n",
    "        print('top n', top_neuron[idx[0]].item(), top_val[idx[0]].item())\n",
    "        return [top_neuron[idx[0]].item()]\n",
    "    \n",
    "    \n",
    "    def fit_transform(self,X,lambd,n_ensembles,neuron_init_dict):\n",
    "        torch.manual_seed(7)\n",
    "        with torch.cuda.device(0) as device:\n",
    "            self.neuron_init_dict=neuron_init_dict\n",
    "            self.lambd=lambd\n",
    "            #Creates cuda tensor from data\n",
    "            self.X=torch.cuda.FloatTensor(X)\n",
    "            #z-score data.\n",
    "            self.zscore()\n",
    "            #Keep original data for one type of initialization\n",
    "            if self.neuron_init_dict['method']=='from_time_point':\n",
    "                self.original_X=self.X.clone()\n",
    "            #Store dimensionality of X for later use.\n",
    "            self.sz=self.X.size()\n",
    "            print('sz',self.sz)\n",
    "            #Initializes U and V with zeros, later these will be discarded.\n",
    "            self.U=torch.zeros((self.X.size(1),1)).cuda()\n",
    "            self.V=torch.zeros([1,self.X.size(0)]).cuda()\n",
    "            #List for storing the number of neurons in each fit assembly.\n",
    "            self.nr_of_neurons=[]\n",
    "            #List for storing the seed neurons for each assembly.\n",
    "            self.seed_neurons=[]\n",
    "            cost_lst=[]\n",
    "            #a variable to switch to random initialization after finding first assembly if the method is\n",
    "            #selecting neurons from a time point\n",
    "            self.first_assembly=True\n",
    "            for iteration in range(0,n_ensembles):\n",
    "                self.fit_one_assembly()\n",
    "                self.nr_of_neurons.append(self.i)\n",
    "                U_V=torch.mm(self.current_u.view(self.sz[1],1),self.current_v.view(1,self.sz[0]))\n",
    "                U_V[U_V != U_V] = 0\n",
    "                self.X=(self.X-U_V.t())\n",
    "                print('ensemble nr', iteration)\n",
    "                #print('u',self.current_u)\n",
    "                #print('v',self.current_v)\n",
    "                #print('length v', torch.matmul(self.current_v,self.current_v))\n",
    "                #print('norm',torch.norm(self.X))\n",
    "                self.cost=torch.mean(torch.mul(self.X,self.X))\n",
    "                print('cost',self.cost)\n",
    "                cost_lst.append(self.cost.item())\n",
    "            #After fitting arrays discard the zero initialization rows and columns from U and V.\n",
    "            self.U=self.U[:,1:]\n",
    "            self.V=self.V[1:,:]\n",
    "            print(self.X.size())\n",
    "            print(self.U.size())\n",
    "            print(self.V.size())\n",
    "            return torch.matmul(self.U,self.V).t().cpu(), self.nr_of_neurons, self.U.cpu(), self.V.cpu(), cost_lst, self.seed_neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5880, 10103)\n",
      "[[31.466291   11.154725    0.         ... 35.939972    0.\n",
      "   0.        ]\n",
      " [41.705284    0.          0.         ...  0.         44.25718\n",
      "  34.889084  ]\n",
      " [ 0.          0.          0.         ... 92.24999    22.162407\n",
      "  21.241     ]\n",
      " ...\n",
      " [12.287675   18.75502     0.         ... 15.54476    55.489014\n",
      "  21.571573  ]\n",
      " [14.505278   27.549797    0.         ...  3.5592616   0.\n",
      "  26.330444  ]\n",
      " [ 0.65212256 31.231289    0.         ...  0.         14.375819\n",
      "  14.927368  ]]\n"
     ]
    }
   ],
   "source": [
    "X=sio.loadmat('/home/maria/Documents/EnsemblePursuit/data/natimg2800_M170717_MP034_2017-09-11.mat')['stim']['resp'][0][0]\n",
    "X[X<0]=0\n",
    "print(X.shape)\n",
    "#print(X[0,2])\n",
    "#X=stats.zscore(X+0.0000001,axis=0)\n",
    "#print(X[2940,638])\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#plt.hist(X.flatten(),range=(-1.2,1.2))\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(280, 10103)\n"
     ]
    }
   ],
   "source": [
    "spont=sio.loadmat('/home/maria/Documents/EnsemblePursuit/data/natimg2800_M170717_MP034_2017-09-11.mat')['stim']['spont'][0][0]\n",
    "print(spont.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-406.6489      74.33246    -24.037865  ...    2.2557046    2.8091228\n",
      "    21.018682 ]\n",
      " [-407.63913     15.983221   -51.209404  ...    7.382367     1.6047179\n",
      "     8.840362 ]\n",
      " [-374.5674     105.58146      0.6683379 ...   18.679613    24.596912\n",
      "    66.66915  ]\n",
      " ...\n",
      " [-236.46799     43.007263    -3.6039703 ...   18.133627   -14.654611\n",
      "     8.836792 ]\n",
      " [-240.23975     41.290257   -52.208305  ...    3.0631526    4.8792267\n",
      "    29.43051  ]\n",
      " [-314.09525     38.27533    -50.740383  ...    3.5583792  -35.56745\n",
      "   -40.88866  ]]\n",
      "[[31.466291   11.154725    0.         ... 35.939972    0.\n",
      "   0.        ]\n",
      " [41.705284    0.          0.         ...  0.         44.25718\n",
      "  34.889084  ]\n",
      " [ 0.          0.          0.         ... 92.24999    22.162407\n",
      "  21.241     ]\n",
      " ...\n",
      " [12.287675   18.75502     0.         ... 15.54476    55.489014\n",
      "  21.571573  ]\n",
      " [14.505278   27.549797    0.         ...  3.5592616   0.\n",
      "  26.330444  ]\n",
      " [ 0.65212256 31.231289    0.         ...  0.         14.375819\n",
      "  14.927368  ]]\n",
      "sz torch.Size([5880, 10103])\n",
      "top n 1608 0.5516875386238098\n",
      "ensemble nr 0\n",
      "cost tensor(0.9857, device='cuda:0')\n",
      "top n 3183 0.6139754056930542\n",
      "ensemble nr 1\n",
      "cost tensor(0.9786, device='cuda:0')\n",
      "top n 6415 0.533966064453125\n",
      "ensemble nr 2\n",
      "cost tensor(0.9746, device='cuda:0')\n",
      "top n 3100 0.58597731590271\n",
      "ensemble nr 3\n",
      "cost tensor(0.9719, device='cuda:0')\n",
      "top n 1076 0.5770801901817322\n",
      "ensemble nr 4\n",
      "cost tensor(0.9685, device='cuda:0')\n",
      "top n 2545 0.5335924625396729\n",
      "ensemble nr 5\n",
      "cost tensor(0.9654, device='cuda:0')\n",
      "top n 2657 0.579582691192627\n",
      "top n 2854 0.5654461979866028\n",
      "ensemble nr 6\n",
      "cost tensor(0.9628, device='cuda:0')\n",
      "top n 984 0.5813974738121033\n",
      "ensemble nr 7\n",
      "cost tensor(0.9609, device='cuda:0')\n",
      "top n 3057 0.5366870760917664\n",
      "ensemble nr 8\n",
      "cost tensor(0.9579, device='cuda:0')\n",
      "top n 4978 0.5288177132606506\n",
      "ensemble nr 9\n",
      "cost tensor(0.9561, device='cuda:0')\n",
      "top n 2619 0.5164979100227356\n",
      "top n 3643 0.5059649348258972\n",
      "top n 9414 0.509863555431366\n",
      "top n 5168 0.529632031917572\n",
      "ensemble nr 10\n",
      "cost tensor(0.9549, device='cuda:0')\n",
      "top n 529 0.5143316388130188\n",
      "ensemble nr 11\n",
      "cost tensor(0.9534, device='cuda:0')\n",
      "top n 3570 0.5297749042510986\n",
      "top n 1605 0.5398930907249451\n",
      "ensemble nr 12\n",
      "cost tensor(0.9505, device='cuda:0')\n",
      "top n 2601 0.5573979020118713\n",
      "ensemble nr 13\n",
      "cost tensor(0.9478, device='cuda:0')\n",
      "top n 83 0.5028554201126099\n",
      "ensemble nr 14\n",
      "cost tensor(0.9467, device='cuda:0')\n",
      "top n 1925 0.6209478378295898\n",
      "top n 3065 0.5095184445381165\n",
      "ensemble nr 15\n",
      "cost tensor(0.9450, device='cuda:0')\n",
      "top n 2831 0.5979411005973816\n",
      "ensemble nr 16\n",
      "cost tensor(0.9415, device='cuda:0')\n",
      "top n 3100 0.5145306587219238\n",
      "ensemble nr 17\n",
      "cost tensor(0.9410, device='cuda:0')\n",
      "top n 1041 0.49389228224754333\n",
      "ensemble nr 18\n",
      "cost tensor(0.9402, device='cuda:0')\n",
      "top n 2398 0.5220036506652832\n",
      "ensemble nr 19\n",
      "cost tensor(0.9392, device='cuda:0')\n",
      "top n 4484 0.5070250034332275\n",
      "ensemble nr 20\n",
      "cost tensor(0.9380, device='cuda:0')\n",
      "top n 4863 0.49891939759254456\n",
      "top n 5209 0.5006213188171387\n",
      "ensemble nr 21\n",
      "cost tensor(0.9368, device='cuda:0')\n",
      "top n 2342 0.5271469354629517\n",
      "ensemble nr 22\n",
      "cost tensor(0.9350, device='cuda:0')\n",
      "top n 2470 0.506994903087616\n",
      "top n 7439 0.5000128149986267\n",
      "top n 742 0.488187700510025\n",
      "ensemble nr 23\n",
      "cost tensor(0.9327, device='cuda:0')\n",
      "top n 10054 0.5145530104637146\n",
      "top n 1797 0.4860629737377167\n",
      "ensemble nr 24\n",
      "cost tensor(0.9322, device='cuda:0')\n",
      "top n 574 0.5235909223556519\n",
      "ensemble nr 25\n",
      "cost tensor(0.9316, device='cuda:0')\n",
      "top n 2460 0.486847847700119\n",
      "ensemble nr 26\n",
      "cost tensor(0.9294, device='cuda:0')\n",
      "top n 7045 0.4881802201271057\n",
      "ensemble nr 27\n",
      "cost tensor(0.9283, device='cuda:0')\n",
      "top n 6169 0.5125089287757874\n",
      "ensemble nr 28\n",
      "cost tensor(0.9262, device='cuda:0')\n",
      "top n 9414 0.5072700381278992\n",
      "top n 833 0.5234646201133728\n",
      "top n 2422 0.5073174834251404\n",
      "ensemble nr 29\n",
      "cost tensor(0.9253, device='cuda:0')\n",
      "top n 7234 0.47834691405296326\n",
      "ensemble nr 30\n",
      "cost tensor(0.9240, device='cuda:0')\n",
      "top n 3452 0.47719651460647583\n",
      "ensemble nr 31\n",
      "cost tensor(0.9230, device='cuda:0')\n",
      "top n 2918 0.49917060136795044\n",
      "ensemble nr 32\n",
      "cost tensor(0.9216, device='cuda:0')\n",
      "top n 1568 0.48265501856803894\n",
      "top n 6415 0.5002524852752686\n",
      "ensemble nr 33\n",
      "cost tensor(0.9207, device='cuda:0')\n",
      "top n 2774 0.6467388272285461\n",
      "top n 3232 0.47831830382347107\n",
      "top n 1481 0.4936695098876953\n",
      "top n 1850 0.4770011603832245\n",
      "top n 2940 0.48128294944763184\n",
      "top n 112 0.4760112762451172\n",
      "ensemble nr 34\n",
      "cost tensor(0.9196, device='cuda:0')\n",
      "top n 2233 0.5244389772415161\n",
      "top n 6954 0.47016260027885437\n",
      "top n 202 0.509991466999054\n",
      "ensemble nr 35\n",
      "cost tensor(0.9190, device='cuda:0')\n",
      "top n 3971 0.4697016775608063\n",
      "top n 149 0.5051280856132507\n",
      "top n 196 0.48432183265686035\n",
      "top n 196 0.48432183265686035\n",
      "top n 3571 0.49544140696525574\n",
      "top n 1568 0.4826725125312805\n",
      "top n 6248 0.4969049096107483\n",
      "ensemble nr 36\n",
      "cost tensor(0.9178, device='cuda:0')\n",
      "top n 7890 0.48404842615127563\n",
      "ensemble nr 37\n",
      "cost tensor(0.9169, device='cuda:0')\n",
      "top n 7766 0.4987247586250305\n",
      "ensemble nr 38\n",
      "cost tensor(0.9160, device='cuda:0')\n",
      "top n 2687 0.4852084815502167\n",
      "top n 2205 0.487901896238327\n",
      "top n 1679 0.48437801003456116\n",
      "ensemble nr 39\n",
      "cost tensor(0.9148, device='cuda:0')\n",
      "top n 3696 0.4874878525733948\n",
      "top n 4346 0.4688936173915863\n",
      "ensemble nr 40\n",
      "cost tensor(0.9133, device='cuda:0')\n",
      "top n 341 0.5076045989990234\n",
      "top n 3606 0.550878643989563\n",
      "top n 923 0.46742120385169983\n",
      "top n 2854 0.4814891517162323\n",
      "ensemble nr 41\n",
      "cost tensor(0.9128, device='cuda:0')\n",
      "top n 4097 0.5235548615455627\n",
      "ensemble nr 42\n",
      "cost tensor(0.9122, device='cuda:0')\n",
      "top n 3606 0.5508432388305664\n",
      "top n 2657 0.5756129026412964\n",
      "top n 2331 0.49362993240356445\n",
      "top n 4863 0.4927169978618622\n",
      "top n 3156 0.48851338028907776\n",
      "top n 341 0.5074357390403748\n",
      "top n 3522 0.4956079423427582\n",
      "top n 803 0.47840818762779236\n",
      "top n 4562 0.4935931861400604\n",
      "top n 1605 0.46827879548072815\n",
      "ensemble nr 43\n",
      "cost tensor(0.9115, device='cuda:0')\n",
      "top n 3643 0.504946231842041\n",
      "top n 10054 0.5148890614509583\n",
      "top n 2205 0.48805561661720276\n",
      "top n 4022 0.4689400792121887\n",
      "ensemble nr 44\n",
      "cost tensor(0.9111, device='cuda:0')\n",
      "top n 3103 0.47192269563674927\n",
      "ensemble nr 45\n",
      "cost tensor(0.9101, device='cuda:0')\n",
      "top n 3643 0.50499027967453\n",
      "top n 2030 0.4655035138130188\n",
      "top n 2774 0.6447576880455017\n",
      "top n 3571 0.49237847328186035\n",
      "top n 984 0.5140866637229919\n",
      "top n 347 0.5537106990814209\n",
      "top n 9910 0.4711599349975586\n",
      "ensemble nr 46\n",
      "cost tensor(0.9092, device='cuda:0')\n",
      "top n 984 0.5141162276268005\n",
      "top n 1408 0.4841112792491913\n",
      "top n 97 0.4764401614665985\n",
      "top n 2233 0.5273131728172302\n",
      "top n 4610 0.5013635754585266\n",
      "ensemble nr 47\n",
      "cost tensor(0.9087, device='cuda:0')\n",
      "top n 1408 0.4840852916240692\n",
      "top n 10054 0.5140427947044373\n",
      "top n 3570 0.5257924199104309\n",
      "top n 299 0.4665012061595917\n",
      "top n 2057 0.47419601678848267\n",
      "top n 2331 0.49356818199157715\n",
      "top n 3971 0.4683937132358551\n",
      "top n 3905 0.4676724076271057\n",
      "top n 7914 0.4616132378578186\n",
      "ensemble nr 48\n",
      "cost tensor(0.9077, device='cuda:0')\n",
      "top n 3698 0.5143119692802429\n",
      "ensemble nr 49\n",
      "cost tensor(0.9070, device='cuda:0')\n",
      "top n 9414 0.5059489011764526\n",
      "top n 8665 0.4916497766971588\n",
      "top n 2218 0.4623798429965973\n",
      "top n 6150 0.491976797580719\n",
      "top n 10054 0.514010488986969\n",
      "top n 386 0.46725407242774963\n",
      "top n 299 0.46571192145347595\n",
      "top n 4822 0.4672307074069977\n",
      "top n 4066 0.4654709994792938\n",
      "ensemble nr 50\n",
      "cost tensor(0.9061, device='cuda:0')\n",
      "top n 699 0.5228675007820129\n",
      "top n 4562 0.4940509796142578\n",
      "top n 299 0.46578866243362427\n",
      "top n 3866 0.6592192053794861\n",
      "top n 3866 0.6592192053794861\n",
      "top n 2069 0.4952830374240875\n",
      "top n 6422 0.4805024266242981\n",
      "top n 699 0.5228675007820129\n",
      "top n 833 0.5099948644638062\n",
      "top n 6422 0.4805024266242981\n",
      "top n 9440 0.4649675786495209\n",
      "top n 8637 0.4618149697780609\n",
      "top n 3905 0.4678712785243988\n",
      "top n 803 0.4640885889530182\n",
      "top n 803 0.4640885889530182\n",
      "top n 2940 0.4801706373691559\n",
      "top n 2687 0.48519158363342285\n",
      "top n 9440 0.4649675786495209\n",
      "top n 5154 0.4713156819343567\n",
      "top n 1408 0.48412927985191345\n",
      "top n 1290 0.5183945894241333\n",
      "top n 299 0.46578866243362427\n",
      "top n 3156 0.48694831132888794\n",
      "top n 833 0.5099948644638062\n",
      "top n 1290 0.5183945894241333\n",
      "top n 984 0.5115211606025696\n",
      "top n 2774 0.6451156735420227\n",
      "top n 196 0.48373380303382874\n",
      "top n 3522 0.4971294105052948\n",
      "top n 7439 0.4945014417171478\n",
      "top n 4854 0.6436900496482849\n",
      "top n 4821 0.4823123514652252\n",
      "top n 5154 0.4713156819343567\n",
      "top n 6652 0.48653408885002136\n",
      "ensemble nr 51\n",
      "cost tensor(0.9051, device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top n 8101 0.512182891368866\n",
      "top n 3505 0.5197045207023621\n",
      "top n 8637 0.4619941711425781\n",
      "top n 1408 0.4841393530368805\n",
      "top n 1925 0.6182723045349121\n",
      "top n 3606 0.5493463277816772\n",
      "top n 803 0.4612889289855957\n",
      "top n 1076 0.48229333758354187\n",
      "top n 3570 0.5252630710601807\n",
      "top n 2601 0.5131068229675293\n",
      "top n 1283 0.46442660689353943\n",
      "top n 3643 0.5045904517173767\n",
      "top n 735 0.48479071259498596\n",
      "top n 299 0.4660862982273102\n",
      "top n 4562 0.49390822649002075\n",
      "top n 4822 0.46694856882095337\n",
      "top n 735 0.48479071259498596\n",
      "top n 3232 0.4778224527835846\n",
      "top n 2774 0.645138680934906\n",
      "top n 3954 0.5133721828460693\n",
      "top n 2619 0.5162059664726257\n",
      "top n 3917 0.476856529712677\n",
      "top n 1925 0.6182723045349121\n",
      "top n 7437 0.47426196932792664\n",
      "ensemble nr 52\n",
      "cost tensor(0.9040, device='cuda:0')\n",
      "top n 2687 0.4841303527355194\n",
      "top n 1830 0.4750794470310211\n",
      "top n 2205 0.4875558912754059\n",
      "top n 149 0.4931635558605194\n",
      "top n 3570 0.5253100991249084\n",
      "top n 833 0.5109440088272095\n",
      "top n 2907 0.5136898756027222\n",
      "top n 2584 0.46939292550086975\n",
      "top n 2331 0.4924900531768799\n",
      "top n 3156 0.48645010590553284\n",
      "top n 196 0.4836764335632324\n",
      "top n 699 0.5230839848518372\n",
      "top n 1663 0.46092936396598816\n",
      "ensemble nr 53\n",
      "cost tensor(0.9032, device='cuda:0')\n",
      "top n 2703 0.48767325282096863\n",
      "top n 3057 0.4640381336212158\n",
      "top n 6932 0.4621756672859192\n",
      "ensemble nr 54\n",
      "cost tensor(0.9021, device='cuda:0')\n",
      "top n 3866 0.6593899130821228\n",
      "top n 123 0.4569413363933563\n",
      "top n 2687 0.48391610383987427\n",
      "top n 1830 0.475118488073349\n",
      "top n 2406 0.45820656418800354\n",
      "top n 1842 0.49999555945396423\n",
      "top n 1830 0.475118488073349\n",
      "top n 7439 0.49369850754737854\n",
      "top n 386 0.46663257479667664\n",
      "top n 2030 0.46553561091423035\n",
      "top n 1290 0.5185002088546753\n",
      "top n 4562 0.49338921904563904\n",
      "top n 1568 0.4821859300136566\n",
      "top n 2601 0.5128015279769897\n",
      "top n 3643 0.5038761496543884\n",
      "top n 1283 0.4644008278846741\n",
      "top n 984 0.5117988586425781\n",
      "top n 221 0.4643592834472656\n",
      "top n 4821 0.4824136793613434\n",
      "top n 8101 0.5119056105613708\n",
      "top n 386 0.46663257479667664\n",
      "top n 3232 0.47668886184692383\n",
      "top n 3954 0.5135230422019958\n",
      "top n 2687 0.48391610383987427\n",
      "top n 149 0.49399515986442566\n",
      "top n 3121 0.4558955132961273\n",
      "ensemble nr 55\n",
      "cost tensor(0.9011, device='cuda:0')\n",
      "top n 1290 0.518500804901123\n",
      "top n 3156 0.48676544427871704\n",
      "top n 803 0.4598234295845032\n",
      "top n 1076 0.4763358533382416\n",
      "top n 341 0.5077570676803589\n",
      "top n 2218 0.46296077966690063\n",
      "top n 2188 0.46720409393310547\n",
      "top n 1747 0.526505172252655\n",
      "top n 1763 0.49525126814842224\n",
      "top n 3057 0.4639716148376465\n",
      "top n 3232 0.4767162501811981\n",
      "top n 9440 0.46422821283340454\n",
      "top n 1850 0.47586217522621155\n",
      "top n 3606 0.5430830717086792\n",
      "top n 3905 0.4679606854915619\n",
      "top n 3522 0.4971378445625305\n",
      "top n 2470 0.5012280941009521\n",
      "top n 386 0.466683954000473\n",
      "top n 2687 0.4839424192905426\n",
      "top n 37 0.4585132598876953\n",
      "ensemble nr 56\n",
      "cost tensor(0.9000, device='cuda:0')\n",
      "top n 4059 0.4602946937084198\n",
      "top n 386 0.4667867124080658\n",
      "top n 1810 0.516090989112854\n",
      "top n 2331 0.49301275610923767\n",
      "top n 299 0.46591177582740784\n",
      "top n 2460 0.4562053382396698\n",
      "top n 4562 0.4920373857021332\n",
      "top n 9414 0.5067431330680847\n",
      "top n 1830 0.47539597749710083\n",
      "top n 2218 0.4623951017856598\n",
      "top n 2703 0.4877696931362152\n",
      "top n 2460 0.4562053382396698\n",
      "top n 3938 0.49968481063842773\n",
      "top n 2406 0.4583466649055481\n",
      "top n 2650 0.5217360258102417\n",
      "top n 99 0.47485923767089844\n",
      "ensemble nr 57\n",
      "cost tensor(0.8993, device='cuda:0')\n",
      "top n 8101 0.5040554404258728\n",
      "top n 1747 0.5273515582084656\n",
      "top n 2218 0.46249914169311523\n",
      "top n 1408 0.4837842583656311\n",
      "top n 4029 0.461107075214386\n",
      "top n 8107 0.456555038690567\n",
      "top n 803 0.45996323227882385\n",
      "top n 3156 0.4867686331272125\n",
      "top n 196 0.4791923463344574\n",
      "top n 1055 0.5699084997177124\n",
      "top n 2584 0.46959805488586426\n",
      "top n 4854 0.6324136257171631\n",
      "top n 1481 0.46629056334495544\n",
      "top n 1481 0.46629056334495544\n",
      "top n 4029 0.461107075214386\n",
      "top n 3606 0.5430026054382324\n",
      "top n 2030 0.46564874053001404\n",
      "top n 2703 0.4877789616584778\n",
      "top n 2406 0.4582118093967438\n",
      "top n 1763 0.4956086575984955\n",
      "top n 4115 0.45317742228507996\n",
      "ensemble nr 58\n",
      "cost tensor(0.8982, device='cuda:0')\n",
      "top n 9414 0.506751537322998\n",
      "top n 97 0.47538191080093384\n",
      "top n 2233 0.5193742513656616\n",
      "top n 1925 0.616375744342804\n",
      "top n 7439 0.4937317371368408\n",
      "top n 3954 0.5097762942314148\n",
      "top n 3232 0.4787571132183075\n",
      "top n 8101 0.5042223930358887\n",
      "top n 1830 0.4754865765571594\n",
      "top n 9414 0.506751537322998\n",
      "top n 1763 0.49565306305885315\n",
      "top n 2069 0.4955790042877197\n",
      "top n 2959 0.45761093497276306\n",
      "top n 3571 0.4907458424568176\n",
      "top n 123 0.4559960961341858\n",
      "top n 519 0.47378650307655334\n",
      "top n 7439 0.4937317371368408\n",
      "top n 4821 0.48198506236076355\n",
      "top n 5154 0.4711827337741852\n",
      "top n 1408 0.483159601688385\n",
      "top n 1842 0.4938514232635498\n",
      "top n 2460 0.4560525119304657\n",
      "top n 3571 0.4907458424568176\n",
      "top n 3606 0.5430868268013\n",
      "top n 519 0.47378650307655334\n",
      "top n 2069 0.4955790042877197\n",
      "top n 1850 0.47338753938674927\n",
      "top n 2959 0.45761093497276306\n",
      "top n 1490 0.5165708065032959\n",
      "top n 3866 0.6503139734268188\n",
      "top n 1283 0.46424397826194763\n",
      "top n 106 0.4788305461406708\n",
      "top n 4990 0.454996794462204\n",
      "top n 1830 0.4754865765571594\n",
      "top n 519 0.47378650307655334\n",
      "top n 221 0.4584314823150635\n",
      "top n 4822 0.46737852692604065\n",
      "top n 3696 0.4847342073917389\n",
      "top n 8723 0.46377187967300415\n",
      "top n 1850 0.47338753938674927\n",
      "top n 4059 0.4594685733318329\n",
      "top n 2233 0.5193742513656616\n",
      "top n 7439 0.4937317371368408\n",
      "top n 2601 0.512846827507019\n",
      "top n 3917 0.4762607216835022\n",
      "top n 8665 0.49079838395118713\n",
      "top n 3938 0.49967989325523376\n",
      "top n 5154 0.4711827337741852\n",
      "top n 1842 0.4938514232635498\n",
      "top n 3643 0.5032169222831726\n",
      "top n 2687 0.48111677169799805\n",
      "top n 2687 0.48111677169799805\n",
      "top n 1830 0.4754865765571594\n",
      "top n 1747 0.5274214148521423\n",
      "top n 196 0.4775340259075165\n",
      "top n 2959 0.45761093497276306\n",
      "top n 2474 0.4531083106994629\n",
      "ensemble nr 59\n",
      "cost tensor(0.8973, device='cuda:0')\n",
      "top n 2205 0.4876411557197571\n",
      "top n 923 0.4542728364467621\n",
      "top n 2940 0.47982484102249146\n",
      "top n 2460 0.4558071196079254\n",
      "top n 4562 0.49198275804519653\n",
      "top n 196 0.4774744510650635\n",
      "top n 2188 0.4672774374485016\n",
      "top n 3971 0.46888628602027893\n",
      "top n 3447 0.4523487091064453\n",
      "ensemble nr 60\n",
      "cost tensor(0.8967, device='cuda:0')\n",
      "top n 1810 0.5161641240119934\n",
      "top n 1842 0.493575781583786\n",
      "top n 2470 0.49433326721191406\n",
      "top n 4822 0.46746188402175903\n",
      "top n 6954 0.4613039195537567\n",
      "top n 4854 0.6319720149040222\n",
      "top n 2406 0.45810723304748535\n",
      "top n 3866 0.6499520540237427\n",
      "top n 8723 0.46378204226493835\n",
      "top n 9414 0.5068513751029968\n",
      "top n 5890 0.5011615753173828\n",
      "top n 699 0.5182474255561829\n",
      "top n 3866 0.6499520540237427\n",
      "top n 8101 0.5042309761047363\n",
      "top n 3571 0.4907807409763336\n",
      "top n 2460 0.45592352747917175\n",
      "top n 2959 0.4575917422771454\n",
      "top n 123 0.4560992419719696\n",
      "top n 3866 0.6499520540237427\n",
      "top n 149 0.48880645632743835\n",
      "top n 923 0.45430389046669006\n",
      "top n 4059 0.45878705382347107\n",
      "top n 3057 0.46406862139701843\n",
      "top n 2703 0.48752090334892273\n",
      "top n 984 0.5127463340759277\n",
      "top n 8723 0.46378204226493835\n",
      "top n 386 0.4667758643627167\n",
      "top n 10054 0.5085152983665466\n",
      "top n 1925 0.6166495680809021\n",
      "top n 523 0.45204979181289673\n",
      "top n 2460 0.45592352747917175\n",
      "top n 2716 0.49813738465309143\n",
      "top n 3866 0.6499520540237427\n",
      "top n 5154 0.47113704681396484\n",
      "top n 123 0.4560992419719696\n",
      "top n 1076 0.4736042618751526\n",
      "top n 2774 0.6368446350097656\n",
      "top n 8723 0.46378204226493835\n",
      "top n 299 0.46496134996414185\n",
      "top n 97 0.47537723183631897\n",
      "top n 196 0.47775110602378845\n",
      "top n 1850 0.4733240306377411\n",
      "top n 1408 0.48357096314430237\n",
      "top n 4990 0.45472002029418945\n",
      "top n 2069 0.49517080187797546\n",
      "top n 6954 0.4613039195537567\n",
      "top n 2601 0.5129658579826355\n",
      "top n 2619 0.5161373019218445\n",
      "top n 347 0.5533932447433472\n",
      "top n 1290 0.5183199644088745\n",
      "top n 735 0.4826783239841461\n",
      "top n 1076 0.4736042618751526\n",
      "top n 2406 0.45810723304748535\n",
      "top n 5890 0.5011615753173828\n",
      "top n 2650 0.521767795085907\n",
      "top n 1568 0.4822886884212494\n",
      "top n 6422 0.4764494001865387\n",
      "top n 1408 0.48357096314430237\n",
      "top n 2650 0.521767795085907\n",
      "top n 123 0.4560992419719696\n",
      "top n 3057 0.46406862139701843\n",
      "top n 3938 0.4996893107891083\n",
      "top n 9414 0.5068513751029968\n",
      "top n 1850 0.4733240306377411\n",
      "top n 231 0.46604427695274353\n",
      "top n 2703 0.48752090334892273\n",
      "top n 106 0.4788711667060852\n",
      "top n 3954 0.5098409056663513\n",
      "top n 3505 0.5203725695610046\n",
      "top n 2703 0.48752090334892273\n",
      "top n 7439 0.493750661611557\n",
      "top n 2650 0.521767795085907\n",
      "top n 1830 0.47502055764198303\n",
      "top n 5890 0.5011615753173828\n",
      "top n 2218 0.46285101771354675\n",
      "top n 3232 0.4786074757575989\n",
      "top n 6422 0.4764494001865387\n",
      "top n 123 0.4560992419719696\n",
      "top n 10054 0.5085152983665466\n",
      "top n 3905 0.46815118193626404\n",
      "top n 4854 0.6319720149040222\n",
      "top n 4059 0.45878705382347107\n",
      "top n 123 0.4560992419719696\n",
      "top n 2584 0.46765390038490295\n",
      "top n 2584 0.46765390038490295\n",
      "top n 519 0.47380924224853516\n",
      "top n 5154 0.47113704681396484\n",
      "top n 3954 0.5098409056663513\n",
      "top n 2940 0.4799647331237793\n",
      "top n 1568 0.4822886884212494\n",
      "top n 8665 0.4908449351787567\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top n 9440 0.46406036615371704\n",
      "top n 1055 0.5699735879898071\n",
      "top n 2601 0.5129658579826355\n",
      "top n 5890 0.5011615753173828\n",
      "top n 2218 0.46285101771354675\n",
      "top n 8723 0.46378204226493835\n",
      "top n 299 0.46496134996414185\n",
      "top n 196 0.47775110602378845\n",
      "top n 2716 0.49813738465309143\n",
      "top n 2331 0.4925670623779297\n",
      "top n 123 0.4560992419719696\n",
      "top n 7234 0.43229109048843384\n",
      "top n 5262 0.4148004651069641\n",
      "top n 2071 0.40938588976860046\n",
      "top n 2040 0.428671658039093\n",
      "top n 2567 0.4065362513065338\n",
      "top n 352 0.43593311309814453\n",
      "top n 5241 0.4090340733528137\n",
      "top n 196 0.47775110602378845\n",
      "top n 5030 0.41168877482414246\n",
      "top n 9576 0.43189889192581177\n",
      "top n 2188 0.46730348467826843\n",
      "top n 6558 0.42354169487953186\n",
      "top n 2650 0.521767795085907\n",
      "top n 1035 0.4389757215976715\n",
      "top n 1988 0.4504142701625824\n",
      "top n 2651 0.4516483247280121\n",
      "top n 7322 0.4169580042362213\n",
      "ensemble nr 61\n",
      "cost tensor(0.8960, device='cuda:0')\n",
      "top n 5154 0.4709596335887909\n",
      "top n 1672 0.4306182861328125\n",
      "top n 3665 0.4048037528991699\n",
      "ensemble nr 62\n",
      "cost tensor(0.8953, device='cuda:0')\n",
      "top n 4990 0.45501708984375\n",
      "top n 3028 0.42549529671669006\n",
      "top n 7003 0.4261344373226166\n",
      "top n 2205 0.48788079619407654\n",
      "top n 1442 0.4091322124004364\n",
      "ensemble nr 63\n",
      "cost tensor(0.8947, device='cuda:0')\n",
      "top n 9970 0.4395628571510315\n",
      "ensemble nr 64\n",
      "cost tensor(0.8939, device='cuda:0')\n",
      "top n 6742 0.4225175082683563\n",
      "top n 5904 0.41659241914749146\n",
      "ensemble nr 65\n",
      "cost tensor(0.8932, device='cuda:0')\n",
      "top n 3998 0.410554975271225\n",
      "ensemble nr 66\n",
      "cost tensor(0.8925, device='cuda:0')\n",
      "top n 778 0.4105503261089325\n",
      "top n 1153 0.4160030484199524\n",
      "top n 6506 0.4059153199195862\n",
      "top n 1076 0.47221413254737854\n",
      "top n 7423 0.41555625200271606\n",
      "ensemble nr 67\n",
      "cost tensor(0.8916, device='cuda:0')\n",
      "top n 1490 0.5165219902992249\n",
      "top n 4408 0.4218783378601074\n",
      "top n 3612 0.4464547634124756\n",
      "top n 8190 0.40849190950393677\n",
      "top n 6900 0.41491708159446716\n",
      "top n 9789 0.428591787815094\n",
      "top n 8973 0.41252127289772034\n",
      "top n 2529 0.4337196350097656\n",
      "top n 9215 0.4303834140300751\n",
      "top n 2651 0.4519062638282776\n",
      "top n 8975 0.4215518534183502\n",
      "ensemble nr 68\n",
      "cost tensor(0.8908, device='cuda:0')\n",
      "top n 3696 0.4846988618373871\n",
      "top n 3489 0.40094971656799316\n",
      "ensemble nr 69\n",
      "cost tensor(0.8903, device='cuda:0')\n",
      "top n 6959 0.4054131507873535\n",
      "top n 7855 0.4282453656196594\n",
      "ensemble nr 70\n",
      "cost tensor(0.8895, device='cuda:0')\n",
      "top n 2657 0.5746975541114807\n",
      "top n 4005 0.4156045913696289\n",
      "top n 2534 0.4096124768257141\n",
      "top n 6763 0.41387924551963806\n",
      "top n 1593 0.40289685130119324\n",
      "top n 1391 0.40362605452537537\n",
      "top n 9440 0.4624667763710022\n",
      "top n 7687 0.4116377830505371\n",
      "ensemble nr 71\n",
      "cost tensor(0.8883, device='cuda:0')\n",
      "top n 1808 0.44437289237976074\n",
      "top n 3522 0.4987734854221344\n",
      "top n 4029 0.4602798521518707\n",
      "top n 97 0.4752921760082245\n",
      "top n 1770 0.3996046781539917\n",
      "top n 1020 0.4335428774356842\n",
      "top n 8121 0.4016946256160736\n",
      "top n 523 0.45174309611320496\n",
      "top n 3674 0.4010111391544342\n",
      "top n 8736 0.4185614585876465\n",
      "top n 1660 0.4219454228878021\n",
      "top n 1747 0.5279805660247803\n",
      "top n 6558 0.4229077398777008\n",
      "top n 1552 0.44735246896743774\n",
      "top n 9293 0.4174179136753082\n",
      "top n 8261 0.4164843261241913\n",
      "top n 1290 0.517170250415802\n",
      "top n 5530 0.4124494194984436\n",
      "top n 4822 0.4669606685638428\n",
      "top n 9633 0.40281739830970764\n",
      "top n 2115 0.4420727789402008\n",
      "top n 1418 0.41922855377197266\n",
      "top n 2027 0.40410980582237244\n",
      "top n 2352 0.4102211594581604\n",
      "ensemble nr 72\n",
      "cost tensor(0.8873, device='cuda:0')\n",
      "top n 9296 0.41581591963768005\n",
      "top n 4284 0.40356263518333435\n",
      "top n 3004 0.4140739142894745\n",
      "top n 4353 0.41213545203208923\n",
      "top n 5369 0.4093964695930481\n",
      "ensemble nr 73\n",
      "cost tensor(0.8866, device='cuda:0')\n",
      "top n 3232 0.47240954637527466\n",
      "top n 306 0.43658143281936646\n",
      "top n 4854 0.6306073069572449\n",
      "top n 7003 0.4247363209724426\n",
      "top n 1076 0.4720938205718994\n",
      "top n 2277 0.4387665390968323\n",
      "top n 3028 0.4242861866950989\n",
      "top n 1770 0.39946141839027405\n",
      "top n 86 0.40177661180496216\n",
      "top n 9110 0.42247602343559265\n",
      "top n 2329 0.4264337718486786\n",
      "top n 5453 0.40932416915893555\n",
      "top n 307 0.4078965187072754\n",
      "top n 20 0.4398806691169739\n",
      "top n 3433 0.4006679952144623\n",
      "top n 776 0.4429134428501129\n",
      "top n 2546 0.41713324189186096\n",
      "top n 2774 0.6361508369445801\n",
      "top n 833 0.49547824263572693\n",
      "top n 2521 0.4282646179199219\n",
      "top n 6724 0.4101128578186035\n",
      "top n 7598 0.3992350101470947\n",
      "top n 3190 0.4018230438232422\n",
      "top n 2188 0.46726194024086\n",
      "top n 282 0.40376725792884827\n",
      "top n 5607 0.40067169070243835\n",
      "top n 7694 0.4005875587463379\n",
      "top n 949 0.40167370438575745\n",
      "ensemble nr 74\n",
      "cost tensor(0.8859, device='cuda:0')\n",
      "top n 5241 0.4100055396556854\n",
      "top n 6558 0.42324209213256836\n",
      "top n 3289 0.40137216448783875\n",
      "ensemble nr 75\n",
      "cost tensor(0.8852, device='cuda:0')\n",
      "top n 948 0.39833077788352966\n",
      "top n 3028 0.4242810308933258\n",
      "top n 2503 0.4544740617275238\n",
      "top n 4863 0.49087563157081604\n",
      "top n 7727 0.4219512641429901\n",
      "top n 523 0.451937198638916\n",
      "top n 9440 0.4625318646430969\n",
      "top n 1290 0.5171498656272888\n",
      "top n 9642 0.4414059817790985\n",
      "top n 7439 0.4948616921901703\n",
      "top n 9576 0.4294449985027313\n",
      "top n 5336 0.421419620513916\n",
      "ensemble nr 76\n",
      "cost tensor(0.8847, device='cuda:0')\n",
      "top n 6558 0.42317986488342285\n",
      "top n 2506 0.4274270534515381\n",
      "top n 9574 0.43145737051963806\n",
      "top n 678 0.44310298562049866\n",
      "top n 4516 0.40025076270103455\n",
      "top n 7814 0.4184342920780182\n",
      "top n 2218 0.43171802163124084\n",
      "top n 3152 0.4162440001964569\n",
      "top n 2911 0.4038889408111572\n",
      "top n 221 0.4565132260322571\n",
      "top n 819 0.44782957434654236\n",
      "top n 7613 0.3977600634098053\n",
      "top n 7093 0.4126202166080475\n",
      "top n 2325 0.3994770050048828\n",
      "top n 7814 0.4184342920780182\n",
      "top n 7361 0.4168862998485565\n",
      "top n 8165 0.43915557861328125\n",
      "top n 209 0.4277587831020355\n",
      "top n 8084 0.40741148591041565\n",
      "ensemble nr 77\n",
      "cost tensor(0.8842, device='cuda:0')\n",
      "top n 9129 0.41150209307670593\n",
      "ensemble nr 78\n",
      "cost tensor(0.8836, device='cuda:0')\n",
      "top n 2703 0.4869977533817291\n",
      "top n 3514 0.4238147735595703\n",
      "top n 330 0.4438256323337555\n",
      "top n 3190 0.40209323167800903\n",
      "top n 1616 0.42475056648254395\n",
      "top n 9 0.4489525258541107\n",
      "top n 3962 0.44571882486343384\n",
      "top n 8983 0.40626558661460876\n",
      "top n 2632 0.41717299818992615\n",
      "top n 5385 0.39825376868247986\n",
      "ensemble nr 79\n",
      "cost tensor(0.8828, device='cuda:0')\n",
      "top n 9068 0.4229576587677002\n",
      "top n 1925 0.6163872480392456\n",
      "top n 56 0.4380117356777191\n",
      "top n 1286 0.4470961093902588\n",
      "top n 1763 0.49281778931617737\n",
      "top n 699 0.5161134600639343\n",
      "top n 2329 0.4243590533733368\n",
      "top n 3612 0.44366654753685\n",
      "top n 8612 0.4048660397529602\n",
      "top n 6422 0.47418567538261414\n",
      "top n 1896 0.44016599655151367\n",
      "top n 5857 0.40253883600234985\n",
      "ensemble nr 80\n",
      "cost tensor(0.8822, device='cuda:0')\n",
      "top n 6456 0.42460471391677856\n",
      "top n 1967 0.4107522964477539\n",
      "top n 4035 0.42620497941970825\n",
      "top n 9110 0.42180749773979187\n",
      "top n 4353 0.4120757281780243\n",
      "top n 7648 0.42512941360473633\n",
      "ensemble nr 81\n",
      "cost tensor(0.8815, device='cuda:0')\n",
      "top n 4393 0.4306500554084778\n",
      "top n 8165 0.43940025568008423\n",
      "top n 3726 0.42179250717163086\n",
      "top n 1409 0.39959436655044556\n",
      "top n 1283 0.4649396538734436\n",
      "top n 90 0.3968859612941742\n",
      "top n 3954 0.508135974407196\n",
      "top n 4562 0.4903241693973541\n",
      "top n 7037 0.4004308879375458\n",
      "top n 8786 0.446847528219223\n",
      "top n 4193 0.40524694323539734\n",
      "top n 873 0.4289029538631439\n",
      "ensemble nr 82\n",
      "cost tensor(0.8807, device='cuda:0')\n",
      "top n 9064 0.407125324010849\n",
      "top n 4464 0.4085221290588379\n",
      "ensemble nr 83\n",
      "cost tensor(0.8803, device='cuda:0')\n",
      "top n 9576 0.4296582341194153\n",
      "top n 830 0.40062499046325684\n",
      "top n 6150 0.48827943205833435\n",
      "top n 2999 0.4074013829231262\n",
      "top n 8853 0.40725284814834595\n",
      "top n 7613 0.3989274501800537\n",
      "top n 2277 0.44002681970596313\n",
      "top n 9576 0.4296582341194153\n",
      "top n 9628 0.39635926485061646\n",
      "top n 9127 0.40924522280693054\n",
      "top n 4562 0.49049264192581177\n",
      "top n 9574 0.43162795901298523\n",
      "top n 6423 0.4119146466255188\n",
      "ensemble nr 84\n",
      "cost tensor(0.8797, device='cuda:0')\n",
      "top n 8761 0.4033999443054199\n",
      "top n 2329 0.4243294298648834\n",
      "top n 1967 0.41034528613090515\n",
      "top n 7550 0.3963838517665863\n",
      "top n 695 0.43876710534095764\n",
      "top n 8249 0.42671164870262146\n",
      "top n 8973 0.4077520966529846\n",
      "top n 6796 0.40717387199401855\n",
      "top n 2156 0.39570435881614685\n",
      "top n 304 0.3961212635040283\n",
      "top n 8505 0.39745649695396423\n",
      "ensemble nr 85\n",
      "cost tensor(0.8789, device='cuda:0')\n",
      "top n 2149 0.4437837600708008\n",
      "top n 8387 0.4020426273345947\n",
      "top n 3958 0.42696768045425415\n",
      "top n 2325 0.40113162994384766\n",
      "top n 2071 0.4087057113647461\n",
      "top n 1956 0.4481382966041565\n",
      "top n 5086 0.3990480601787567\n",
      "top n 9020 0.4063287675380707\n",
      "top n 1403 0.44082164764404297\n",
      "top n 2628 0.4495926797389984\n",
      "top n 2601 0.512971818447113\n",
      "top n 2115 0.44147855043411255\n",
      "top n 6954 0.4599331021308899\n",
      "top n 4780 0.3998580276966095\n",
      "top n 1782 0.4015669524669647\n",
      "top n 123 0.448007196187973\n",
      "top n 1357 0.39532628655433655\n",
      "top n 1076 0.4706484377384186\n",
      "top n 9642 0.44199338555336\n",
      "top n 7037 0.4003661572933197\n",
      "top n 1481 0.4656519889831543\n",
      "top n 3962 0.4436342716217041\n",
      "top n 6462 0.40261363983154297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top n 3244 0.42271706461906433\n",
      "top n 8028 0.4455108642578125\n",
      "top n 4854 0.6307509541511536\n",
      "top n 3237 0.3951142132282257\n",
      "top n 7037 0.4003661572933197\n",
      "top n 1809 0.39694902300834656\n",
      "top n 2504 0.43173590302467346\n",
      "top n 9147 0.43085652589797974\n",
      "top n 1967 0.41009321808815\n",
      "top n 5404 0.41989627480506897\n",
      "top n 2479 0.4018211364746094\n",
      "top n 1013 0.4063023030757904\n",
      "top n 8944 0.40601396560668945\n",
      "top n 8853 0.40674033761024475\n",
      "top n 2833 0.4093763828277588\n",
      "top n 3571 0.4904288947582245\n",
      "top n 2907 0.5072556138038635\n",
      "top n 1031 0.40854620933532715\n",
      "top n 2328 0.4485839307308197\n",
      "top n 2144 0.4342212378978729\n",
      "top n 6161 0.40174150466918945\n",
      "top n 3004 0.41480857133865356\n",
      "top n 2144 0.4342212378978729\n",
      "top n 648 0.4163142144680023\n",
      "top n 699 0.5164030194282532\n",
      "top n 742 0.3975934684276581\n",
      "top n 3521 0.396388441324234\n",
      "top n 2546 0.4176672101020813\n",
      "top n 3813 0.395155668258667\n",
      "top n 9296 0.40821585059165955\n",
      "top n 8920 0.4041464924812317\n",
      "top n 2093 0.41878482699394226\n",
      "top n 149 0.4792105257511139\n",
      "top n 1452 0.40119242668151855\n",
      "top n 7868 0.40073996782302856\n",
      "top n 6268 0.4010036885738373\n",
      "top n 1483 0.4493105113506317\n",
      "top n 532 0.39759859442710876\n",
      "top n 8587 0.40984439849853516\n",
      "top n 7357 0.3950720727443695\n",
      "top n 1031 0.40854620933532715\n",
      "top n 1077 0.4203053414821625\n",
      "top n 6993 0.40098926424980164\n",
      "top n 1283 0.46521568298339844\n",
      "top n 2619 0.5151289701461792\n",
      "top n 4151 0.43762069940567017\n",
      "top n 6246 0.3973289430141449\n",
      "top n 3057 0.4638502299785614\n",
      "top n 2703 0.4873715341091156\n",
      "top n 3726 0.4216561019420624\n",
      "top n 8723 0.4585421085357666\n",
      "top n 8619 0.4156462848186493\n",
      "top n 7456 0.39505231380462646\n",
      "top n 7310 0.4036226272583008\n",
      "top n 9113 0.4023595452308655\n",
      "top n 648 0.4163142144680023\n",
      "top n 7003 0.42487818002700806\n",
      "top n 7598 0.3985995352268219\n",
      "top n 9897 0.4078120291233063\n",
      "top n 7379 0.44405195116996765\n",
      "top n 8107 0.45250675082206726\n",
      "top n 6287 0.4141791760921478\n",
      "top n 2197 0.4081277847290039\n",
      "top n 2355 0.39504995942115784\n",
      "top n 4080 0.4178009033203125\n",
      "top n 6952 0.39946332573890686\n",
      "top n 5890 0.49778205156326294\n",
      "top n 1441 0.40683069825172424\n",
      "top n 1483 0.4493105113506317\n",
      "top n 2684 0.4067822992801666\n",
      "top n 2710 0.41290637850761414\n",
      "top n 5723 0.39655789732933044\n",
      "top n 7379 0.44405195116996765\n",
      "top n 2031 0.413872629404068\n",
      "top n 1716 0.40269970893859863\n",
      "top n 123 0.448007196187973\n",
      "top n 2503 0.4537660777568817\n",
      "top n 145 0.42288169264793396\n",
      "top n 2316 0.39497512578964233\n",
      "top n 231 0.4635035991668701\n",
      "top n 1037 0.39918261766433716\n",
      "top n 9296 0.40821585059165955\n",
      "top n 3586 0.419013112783432\n",
      "top n 9917 0.40103989839553833\n",
      "top n 4355 0.3953720033168793\n",
      "top n 2460 0.45333942770957947\n",
      "top n 6287 0.4141791760921478\n",
      "top n 2657 0.5734918117523193\n",
      "top n 3028 0.4236353933811188\n",
      "top n 1408 0.48363399505615234\n",
      "top n 7456 0.39505231380462646\n",
      "top n 81 0.44074031710624695\n",
      "top n 4118 0.42391952872276306\n",
      "top n 465 0.4120924472808838\n",
      "top n 4059 0.4571455419063568\n",
      "top n 3237 0.3951142132282257\n",
      "top n 4393 0.4306766986846924\n",
      "top n 3156 0.4863603115081787\n",
      "top n 9 0.44869089126586914\n",
      "top n 7748 0.39490872621536255\n",
      "top n 9968 0.4086093008518219\n",
      "top n 9632 0.43938493728637695\n",
      "top n 3954 0.5082542300224304\n",
      "top n 2031 0.413872629404068\n",
      "top n 5380 0.41539421677589417\n",
      "ensemble nr 86\n",
      "cost tensor(0.8782, device='cuda:0')\n",
      "top n 948 0.39738041162490845\n",
      "top n 1483 0.4493105113506317\n",
      "top n 3954 0.5082542300224304\n",
      "top n 9164 0.4059358537197113\n",
      "ensemble nr 87\n",
      "cost tensor(0.8775, device='cuda:0')\n",
      "top n 1076 0.4705825746059418\n",
      "top n 8375 0.4062952995300293\n",
      "top n 2303 0.39549675583839417\n",
      "top n 4266 0.44205281138420105\n",
      "top n 90 0.39668041467666626\n",
      "top n 56 0.4388130307197571\n",
      "top n 1967 0.40971383452415466\n",
      "top n 5453 0.408416748046875\n",
      "top n 341 0.504463255405426\n",
      "top n 2329 0.4239558279514313\n",
      "top n 28 0.42408785223960876\n",
      "top n 2684 0.4067983329296112\n",
      "top n 2546 0.4177437424659729\n",
      "top n 2504 0.4308253228664398\n",
      "top n 9465 0.40065836906433105\n",
      "top n 4821 0.4820026457309723\n",
      "top n 6197 0.4009368121623993\n",
      "top n 4005 0.4152209758758545\n",
      "top n 4194 0.41419798135757446\n",
      "top n 5723 0.39679154753685\n",
      "top n 5026 0.3952873647212982\n",
      "ensemble nr 88\n",
      "cost tensor(0.8769, device='cuda:0')\n",
      "top n 532 0.39785799384117126\n",
      "top n 3674 0.4021275043487549\n",
      "top n 4151 0.4370534121990204\n",
      "top n 1967 0.40971383452415466\n",
      "top n 9139 0.42510849237442017\n",
      "top n 7456 0.3960552215576172\n",
      "top n 7598 0.3989380896091461\n",
      "top n 7238 0.40305614471435547\n",
      "ensemble nr 89\n",
      "cost tensor(0.8763, device='cuda:0')\n",
      "top n 923 0.4511469304561615\n",
      "top n 2657 0.5726313591003418\n",
      "top n 3232 0.4690261781215668\n",
      "top n 8788 0.4142858684062958\n",
      "top n 2940 0.4783484935760498\n",
      "top n 4393 0.430856853723526\n",
      "top n 3570 0.5255453586578369\n",
      "top n 2359 0.3980100750923157\n",
      "top n 2710 0.41212350130081177\n",
      "top n 2657 0.5726313591003418\n",
      "top n 742 0.39763107895851135\n",
      "top n 9306 0.39405378699302673\n",
      "top n 9064 0.40758219361305237\n",
      "top n 3942 0.40282580256462097\n",
      "top n 4284 0.4031059741973877\n",
      "top n 9310 0.40651702880859375\n",
      "top n 2959 0.45617151260375977\n",
      "top n 7580 0.3955102860927582\n",
      "top n 9414 0.5015537142753601\n",
      "top n 466 0.4225217401981354\n",
      "top n 1402 0.39464089274406433\n",
      "top n 6558 0.4238448143005371\n",
      "top n 2027 0.40270790457725525\n",
      "top n 5409 0.40584203600883484\n",
      "top n 1076 0.4706082344055176\n",
      "top n 4253 0.4029978811740875\n",
      "ensemble nr 90\n",
      "cost tensor(0.8756, device='cuda:0')\n",
      "top n 6954 0.45682191848754883\n",
      "top n 97 0.4737188518047333\n",
      "top n 2144 0.4340360164642334\n",
      "top n 3962 0.44353175163269043\n",
      "top n 9353 0.4336889386177063\n",
      "top n 5956 0.39539027214050293\n",
      "top n 8121 0.4053124487400055\n",
      "top n 702 0.40725865960121155\n",
      "top n 5195 0.4011407792568207\n",
      "top n 4080 0.41686511039733887\n",
      "top n 9147 0.43084603548049927\n",
      "top n 6150 0.48876118659973145\n",
      "top n 3022 0.4046284854412079\n",
      "top n 3521 0.3967224657535553\n",
      "top n 3369 0.39792966842651367\n",
      "top n 8637 0.4156935214996338\n",
      "top n 3071 0.3958558738231659\n",
      "top n 8162 0.39904019236564636\n",
      "top n 7003 0.42470836639404297\n",
      "top n 9310 0.4065200984477997\n",
      "top n 56 0.43873023986816406\n",
      "top n 6420 0.398771733045578\n",
      "top n 508 0.4135294556617737\n",
      "top n 1646 0.3953375220298767\n",
      "top n 2503 0.45299839973449707\n",
      "top n 4029 0.4593840539455414\n",
      "top n 139 0.39525166153907776\n",
      "top n 2205 0.48897823691368103\n",
      "top n 2619 0.5159072279930115\n",
      "top n 3979 0.4094521105289459\n",
      "top n 1568 0.48236361145973206\n",
      "top n 8165 0.43963152170181274\n",
      "top n 528 0.41338130831718445\n",
      "top n 3586 0.4191441535949707\n",
      "top n 1441 0.4070280194282532\n",
      "top n 2911 0.4032967686653137\n",
      "top n 4154 0.4056890904903412\n",
      "ensemble nr 91\n",
      "cost tensor(0.8750, device='cuda:0')\n",
      "top n 3300 0.4018755853176117\n",
      "top n 2503 0.45299839973449707\n",
      "top n 2032 0.3974618911743164\n",
      "top n 7565 0.40400728583335876\n",
      "top n 2069 0.49237170815467834\n",
      "top n 2668 0.3977341651916504\n",
      "top n 1408 0.483724981546402\n",
      "top n 3028 0.4234898090362549\n",
      "top n 282 0.4040988087654114\n",
      "top n 1458 0.4278794229030609\n",
      "top n 2521 0.4269047677516937\n",
      "top n 5631 0.393758624792099\n",
      "top n 8219 0.40554147958755493\n",
      "ensemble nr 92\n",
      "cost tensor(0.8745, device='cuda:0')\n",
      "top n 2665 0.42262744903564453\n",
      "top n 81 0.44098931550979614\n",
      "top n 7418 0.4364408552646637\n",
      "top n 4990 0.45455700159072876\n",
      "top n 1286 0.44716760516166687\n",
      "top n 8261 0.4118834435939789\n",
      "top n 1153 0.4160486161708832\n",
      "top n 516 0.4073130786418915\n",
      "top n 9310 0.40650200843811035\n",
      "top n 4863 0.490898996591568\n",
      "top n 1366 0.43089351058006287\n",
      "top n 8761 0.3980253338813782\n",
      "top n 9293 0.4178825318813324\n",
      "ensemble nr 93\n",
      "cost tensor(0.8738, device='cuda:0')\n",
      "top n 925 0.4038441777229309\n",
      "top n 27 0.3972782790660858\n",
      "top n 5409 0.40565988421440125\n",
      "top n 6246 0.39618349075317383\n",
      "top n 6451 0.4152343273162842\n",
      "top n 6422 0.47217994928359985\n",
      "top n 984 0.5113000273704529\n",
      "top n 4854 0.6294183135032654\n",
      "top n 6952 0.3958720862865448\n",
      "top n 3958 0.4262908101081848\n",
      "top n 519 0.47217902541160583\n",
      "top n 8041 0.4420900344848633\n",
      "ensemble nr 94\n",
      "cost tensor(0.8733, device='cuda:0')\n",
      "top n 2032 0.39741620421409607\n",
      "top n 2994 0.39352747797966003\n",
      "top n 3768 0.4013330042362213\n",
      "top n 8665 0.4915339946746826\n",
      "top n 9110 0.4216708242893219\n",
      "top n 3992 0.40518879890441895\n",
      "top n 304 0.395801305770874\n",
      "top n 1646 0.3953927457332611\n",
      "top n 2940 0.4774799048900604\n",
      "top n 7141 0.41680994629859924\n",
      "top n 1302 0.3999747037887573\n",
      "top n 4355 0.3949976861476898\n",
      "top n 3810 0.39591309428215027\n",
      "top n 1252 0.3940119445323944\n",
      "top n 28 0.42397165298461914\n",
      "top n 803 0.44550514221191406\n",
      "top n 145 0.4221467971801758\n",
      "top n 1591 0.4017167091369629\n",
      "top n 516 0.4074588418006897\n",
      "top n 139 0.39355918765068054\n",
      "top n 7598 0.39733555912971497\n",
      "top n 8587 0.40892115235328674\n",
      "top n 2555 0.4084046483039856\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top n 5195 0.39900219440460205\n",
      "top n 3866 0.6467955112457275\n",
      "top n 1763 0.49246254563331604\n",
      "top n 1290 0.5147244334220886\n",
      "top n 341 0.503736674785614\n",
      "top n 2115 0.44236811995506287\n",
      "top n 2774 0.6353499293327332\n",
      "top n 8853 0.40573978424072266\n",
      "ensemble nr 95\n",
      "cost tensor(0.8726, device='cuda:0')\n",
      "top n 1129 0.4055176377296448\n",
      "top n 3280 0.4197065532207489\n",
      "top n 7369 0.4060388505458832\n",
      "top n 1013 0.40689951181411743\n",
      "top n 6422 0.47230467200279236\n",
      "top n 2716 0.49717235565185547\n",
      "top n 304 0.39587125182151794\n",
      "top n 3954 0.5088362097740173\n",
      "top n 1481 0.4615996479988098\n",
      "top n 9608 0.39810463786125183\n",
      "top n 7310 0.4019692838191986\n",
      "top n 2650 0.5214962959289551\n",
      "top n 9353 0.43338248133659363\n",
      "top n 6422 0.47230467200279236\n",
      "top n 1076 0.4646783471107483\n",
      "top n 3612 0.44218212366104126\n",
      "top n 4194 0.413920134305954\n",
      "top n 2349 0.39541977643966675\n",
      "top n 899 0.39362239837646484\n",
      "top n 3962 0.4437997043132782\n",
      "top n 4863 0.4908246695995331\n",
      "top n 5471 0.39314910769462585\n",
      "top n 7099 0.41985589265823364\n",
      "top n 2069 0.4926159083843231\n",
      "top n 2665 0.42240437865257263\n",
      "top n 3726 0.4211159348487854\n",
      "top n 7361 0.41441330313682556\n",
      "top n 3674 0.4007335305213928\n",
      "top n 3982 0.4441242218017578\n",
      "top n 465 0.410326212644577\n",
      "top n 5548 0.3955020308494568\n",
      "top n 9574 0.4315696358680725\n",
      "top n 1646 0.3948422372341156\n",
      "top n 2911 0.403672456741333\n",
      "top n 6763 0.41228705644607544\n",
      "top n 2601 0.5131314396858215\n",
      "top n 984 0.5113333463668823\n",
      "top n 6197 0.4004543721675873\n",
      "top n 1591 0.4017830789089203\n",
      "top n 296 0.4008153975009918\n",
      "top n 1031 0.40919771790504456\n",
      "top n 1041 0.40002551674842834\n",
      "top n 3962 0.4437997043132782\n",
      "top n 3536 0.4010806083679199\n",
      "top n 9459 0.419086217880249\n",
      "top n 1506 0.3936712443828583\n",
      "top n 145 0.4221816658973694\n",
      "top n 32 0.41694074869155884\n",
      "top n 2040 0.42784467339515686\n",
      "top n 9020 0.405253142118454\n",
      "top n 2684 0.4067264497280121\n",
      "top n 3917 0.47445201873779297\n",
      "top n 9608 0.39810463786125183\n",
      "top n 2316 0.3941628336906433\n",
      "top n 2999 0.40695449709892273\n",
      "top n 8787 0.41267552971839905\n",
      "top n 2124 0.42154961824417114\n",
      "top n 380 0.40464526414871216\n",
      "top n 3550 0.3945290148258209\n",
      "top n 2650 0.5214962959289551\n",
      "top n 735 0.48066940903663635\n",
      "top n 7369 0.4060388505458832\n",
      "top n 4194 0.413920134305954\n",
      "top n 1252 0.39376944303512573\n",
      "top n 3422 0.3935277462005615\n",
      "top n 5262 0.40830525755882263\n",
      "top n 699 0.5155653357505798\n",
      "top n 6763 0.41228705644607544\n",
      "top n 5609 0.4116859436035156\n",
      "ensemble nr 96\n",
      "cost tensor(0.8721, device='cuda:0')\n",
      "top n 2703 0.4872365891933441\n",
      "top n 1673 0.39344459772109985\n",
      "top n 923 0.4483207166194916\n",
      "top n 8723 0.4563714563846588\n",
      "top n 8723 0.4563714563846588\n",
      "top n 2567 0.40417003631591797\n",
      "top n 1616 0.422884464263916\n",
      "top n 9459 0.4183679521083832\n",
      "top n 695 0.43920764327049255\n",
      "top n 642 0.40989041328430176\n",
      "top n 3086 0.4603993892669678\n",
      "top n 2806 0.39317843317985535\n",
      "top n 1013 0.4068862497806549\n",
      "top n 3276 0.40608206391334534\n",
      "top n 2628 0.45004501938819885\n",
      "top n 2329 0.42233043909072876\n",
      "top n 2634 0.3925165832042694\n",
      "top n 1076 0.46372029185295105\n",
      "top n 2555 0.4081619679927826\n",
      "top n 2774 0.6342344284057617\n",
      "top n 4193 0.4051889479160309\n",
      "top n 3214 0.40833282470703125\n",
      "top n 354 0.3927861452102661\n",
      "top n 1441 0.4072602689266205\n",
      "top n 2450 0.40482020378112793\n",
      "top n 296 0.4008499085903168\n",
      "top n 9254 0.4021224081516266\n",
      "top n 1452 0.40073761343955994\n",
      "top n 1418 0.4166176915168762\n",
      "top n 1403 0.43998199701309204\n",
      "top n 142 0.4187985956668854\n",
      "ensemble nr 97\n",
      "cost tensor(0.8714, device='cuda:0')\n",
      "top n 1488 0.39430317282676697\n",
      "top n 3156 0.48607608675956726\n",
      "top n 519 0.4721359312534332\n",
      "top n 5956 0.3952145576477051\n",
      "top n 341 0.5038260221481323\n",
      "top n 7027 0.39985811710357666\n",
      "top n 9310 0.40584850311279297\n",
      "top n 1413 0.40464267134666443\n",
      "top n 2460 0.4483049809932709\n",
      "top n 833 0.49658021330833435\n",
      "top n 3034 0.3942511975765228\n",
      "top n 3081 0.3928902745246887\n",
      "top n 3586 0.4191291928291321\n",
      "top n 1366 0.4308947026729584\n",
      "top n 8637 0.41361719369888306\n",
      "top n 5607 0.4012887179851532\n",
      "top n 1776 0.40853404998779297\n",
      "top n 6763 0.4123995304107666\n",
      "top n 296 0.4003583490848541\n",
      "top n 10014 0.4344727694988251\n",
      "top n 7418 0.43616825342178345\n",
      "top n 7379 0.44368115067481995\n",
      "top n 2115 0.44207271933555603\n",
      "top n 788 0.42048379778862\n",
      "top n 7708 0.4058113098144531\n",
      "top n 3212 0.3931080996990204\n",
      "top n 1031 0.40897518396377563\n",
      "top n 803 0.4437321126461029\n",
      "top n 8375 0.4057588577270508\n",
      "top n 9684 0.40275058150291443\n",
      "top n 3905 0.4556836783885956\n",
      "top n 899 0.3932780623435974\n",
      "top n 2470 0.48013049364089966\n",
      "top n 1956 0.4483141005039215\n",
      "top n 286 0.39418765902519226\n",
      "top n 2329 0.42233043909072876\n",
      "top n 2277 0.43820199370384216\n",
      "top n 6462 0.4010836184024811\n",
      "top n 1020 0.43390408158302307\n",
      "top n 9215 0.42946720123291016\n",
      "top n 2665 0.42232203483581543\n",
      "top n 2115 0.44207271933555603\n",
      "top n 656 0.40347734093666077\n",
      "top n 1252 0.39382633566856384\n",
      "top n 1890 0.40656834840774536\n",
      "top n 4408 0.4220418930053711\n",
      "top n 254 0.416856586933136\n",
      "top n 299 0.46548041701316833\n",
      "top n 2156 0.3959312438964844\n",
      "top n 4037 0.40410271286964417\n",
      "top n 20 0.44044944643974304\n",
      "top n 2592 0.44438210129737854\n",
      "top n 8189 0.40266498923301697\n",
      "top n 1925 0.6141452193260193\n",
      "top n 3522 0.4962718188762665\n",
      "top n 9628 0.39709290862083435\n",
      "top n 1616 0.4205762445926666\n",
      "top n 9381 0.3982871472835541\n",
      "top n 1441 0.40699681639671326\n",
      "top n 4576 0.409229576587677\n",
      "top n 9414 0.4890047609806061\n",
      "top n 1283 0.4643976390361786\n",
      "top n 5530 0.41173869371414185\n",
      "top n 8387 0.4012727737426758\n",
      "top n 5404 0.4172816276550293\n",
      "top n 6506 0.40220680832862854\n",
      "top n 962 0.42581215500831604\n",
      "top n 3942 0.40299996733665466\n",
      "top n 3962 0.42924752831459045\n",
      "top n 386 0.4676518142223358\n",
      "top n 7099 0.4194502830505371\n",
      "top n 5890 0.49596405029296875\n",
      "top n 6521 0.3933090269565582\n",
      "top n 4080 0.41650256514549255\n",
      "top n 1020 0.43390408158302307\n",
      "top n 4353 0.40637117624282837\n",
      "top n 2355 0.395203173160553\n",
      "top n 3570 0.5255858302116394\n",
      "top n 376 0.3970942497253418\n",
      "top n 1380 0.43843936920166016\n",
      "top n 1120 0.40192556381225586\n",
      "top n 1850 0.4674186706542969\n",
      "top n 3982 0.444130003452301\n",
      "top n 3190 0.39948680996894836\n",
      "top n 5195 0.3987765908241272\n",
      "top n 5404 0.4172816276550293\n",
      "top n 7369 0.40484294295310974\n",
      "top n 6689 0.40849754214286804\n",
      "top n 1842 0.48177480697631836\n",
      "top n 7024 0.4170898497104645\n",
      "top n 2628 0.45005711913108826\n",
      "top n 6150 0.4887982904911041\n",
      "top n 18 0.413417249917984\n",
      "top n 2994 0.3933132588863373\n",
      "top n 699 0.5150539875030518\n",
      "top n 32 0.41529032588005066\n",
      "top n 1153 0.41604286432266235\n",
      "top n 9310 0.40584850311279297\n",
      "top n 8637 0.41361719369888306\n",
      "top n 9215 0.42946720123291016\n",
      "top n 7037 0.40039101243019104\n",
      "top n 254 0.416856586933136\n",
      "top n 7234 0.41321679949760437\n",
      "top n 3156 0.48607608675956726\n",
      "top n 2156 0.3959312438964844\n",
      "top n 2651 0.45279359817504883\n",
      "top n 8637 0.41361719369888306\n",
      "top n 7310 0.4016922414302826\n",
      "top n 9632 0.43427810072898865\n",
      "top n 9310 0.40584850311279297\n",
      "top n 4284 0.40345868468284607\n",
      "top n 1077 0.420818954706192\n",
      "top n 6420 0.3990839123725891\n",
      "top n 7439 0.49427172541618347\n",
      "top n 1809 0.3968609571456909\n",
      "top n 1029 0.42095422744750977\n",
      "top n 1850 0.4674186706542969\n",
      "top n 519 0.4721359312534332\n",
      "top n 3917 0.47454890608787537\n",
      "top n 3768 0.4014603793621063\n",
      "top n 1452 0.40076056122779846\n",
      "top n 2668 0.39689871668815613\n",
      "top n 106 0.47871747612953186\n",
      "top n 6287 0.4007105529308319\n",
      "top n 2450 0.40482041239738464\n",
      "top n 7003 0.42002812027931213\n",
      "top n 1483 0.4496645927429199\n",
      "top n 2460 0.4483049809932709\n",
      "top n 354 0.3927284777164459\n",
      "top n 3514 0.4185144603252411\n",
      "top n 2233 0.5101048350334167\n",
      "top n 735 0.48052605986595154\n",
      "top n 3696 0.4843376576900482\n",
      "top n 2619 0.5153021216392517\n",
      "top n 4151 0.4301774501800537\n",
      "top n 3958 0.4268549382686615\n",
      "top n 1488 0.39430317282676697\n",
      "top n 3982 0.444130003452301\n",
      "top n 9215 0.42946720123291016\n",
      "top n 962 0.42581215500831604\n",
      "top n 7099 0.4194502830505371\n",
      "top n 2897 0.39279797673225403\n",
      "top n 7767 0.39393410086631775\n",
      "top n 5154 0.4558420777320862\n",
      "top n 6038 0.39303097128868103\n",
      "ensemble nr 98\n",
      "cost tensor(0.8709, device='cuda:0')\n",
      "top n 8665 0.49151039123535156\n",
      "top n 1951 0.40514737367630005\n",
      "top n 1076 0.4637499451637268\n",
      "top n 2994 0.39331790804862976\n",
      "top n 833 0.4966690242290497\n",
      "top n 7037 0.40035176277160645\n",
      "top n 5607 0.4012726843357086\n",
      "top n 1646 0.39477941393852234\n",
      "top n 7141 0.4161507189273834\n",
      "top n 1956 0.44834932684898376\n",
      "top n 1809 0.39682453870773315\n",
      "top n 7234 0.4132879376411438\n",
      "top n 9576 0.42911529541015625\n",
      "top n 299 0.46548041701316833\n",
      "top n 1380 0.43840113282203674\n",
      "top n 466 0.4192529618740082\n",
      "top n 1776 0.4085775315761566\n",
      "top n 3519 0.3966996669769287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top n 1830 0.4751862585544586\n",
      "top n 3979 0.4075947701931\n",
      "top n 695 0.43932732939720154\n",
      "top n 90 0.3967815935611725\n",
      "top n 5479 0.4084383547306061\n",
      "ensemble nr 99\n",
      "cost tensor(0.8703, device='cuda:0')\n",
      "torch.Size([5880, 10103])\n",
      "torch.Size([10103, 100])\n",
      "torch.Size([100, 5880])\n",
      "281.89358472824097\n",
      "[473, 265, 163, 78, 128, 96, 103, 49, 89, 55, 30, 33, 103, 90, 26, 40, 134, 8, 12, 19, 26, 19, 54, 78, 9, 8, 58, 26, 63, 14, 33, 20, 35, 17, 30, 10, 24, 14, 17, 26, 37, 8, 8, 8, 11, 25, 21, 8, 25, 10, 20, 26, 19, 10, 21, 17, 25, 8, 23, 20, 8, 14, 10, 11, 9, 13, 15, 18, 11, 9, 13, 21, 26, 12, 11, 10, 9, 8, 11, 11, 11, 9, 10, 8, 9, 15, 12, 9, 9, 10, 9, 8, 8, 12, 8, 8, 8, 10, 8, 8]\n",
      "[0.9857428669929504, 0.978646993637085, 0.9745738506317139, 0.9719213247299194, 0.9684534668922424, 0.965385377407074, 0.9627528786659241, 0.9608548879623413, 0.9578728079795837, 0.9560969471931458, 0.9549017548561096, 0.9534193277359009, 0.9505071640014648, 0.9477530717849731, 0.9467118382453918, 0.9450116157531738, 0.9415032863616943, 0.9409996867179871, 0.9401624202728271, 0.9391782879829407, 0.9379523992538452, 0.9367620944976807, 0.934995174407959, 0.9327318072319031, 0.9321743845939636, 0.931597888469696, 0.9294282793998718, 0.9283339381217957, 0.9261508584022522, 0.9253084659576416, 0.9240396022796631, 0.9229794144630432, 0.9215549826622009, 0.9207496047019958, 0.9195835590362549, 0.9189938306808472, 0.917816698551178, 0.9169425368309021, 0.9160243272781372, 0.9147878885269165, 0.9133309721946716, 0.9128293991088867, 0.9122161865234375, 0.9115422964096069, 0.9110590815544128, 0.9100545644760132, 0.9092018604278564, 0.9087182879447937, 0.9076619744300842, 0.9069958329200745, 0.9060894250869751, 0.9050716161727905, 0.9039868116378784, 0.903232216835022, 0.9020748734474182, 0.9010857939720154, 0.9000024795532227, 0.8992999792098999, 0.8982065320014954, 0.8972629308700562, 0.8966678380966187, 0.8959728479385376, 0.8953423500061035, 0.8947065472602844, 0.8939281702041626, 0.8932049870491028, 0.8924697041511536, 0.8916211128234863, 0.8908314108848572, 0.8902859687805176, 0.8894515633583069, 0.8883357644081116, 0.8872695565223694, 0.8865863680839539, 0.885906457901001, 0.8852450847625732, 0.8847165107727051, 0.8842079043388367, 0.8836055994033813, 0.8827582001686096, 0.8821964859962463, 0.8815445899963379, 0.8807399868965149, 0.8802539706230164, 0.8797073364257812, 0.8789282441139221, 0.8781588077545166, 0.877467930316925, 0.8768934011459351, 0.876267671585083, 0.8755630254745483, 0.8750218152999878, 0.8745033740997314, 0.8737896084785461, 0.8732542991638184, 0.8725625276565552, 0.8721036911010742, 0.871448814868927, 0.8709383010864258, 0.8702533841133118]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "np.random.seed(7)\n",
    "ep=EnsemblePursuitPyTorch()\n",
    "s=time.time()\n",
    "u = PCA(n_components=32).fit_transform(spont.T) # u is neurons by components\n",
    "print(u)\n",
    "print(X)\n",
    "resp = X - (X @ u) @ u.T\n",
    "neuron_init_dict={'method':'top_k_corr','parameters':{'T':10,'n_of_neurons':100,'min_assembly_size':8}}\n",
    "U_V,nr_of_neurons,U,V, cost_lst,seed_neurons=ep.fit_transform(X,0.05,100,neuron_init_dict)\n",
    "e=time.time()\n",
    "print(e-s)\n",
    "print(nr_of_neurons)\n",
    "print(cost_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Histogram of assembly sizes, lambda 0.05, 100 assemblies')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(nr_of_neurons)\n",
    "plt.title('Histogram of assembly sizes, lambda 0.05, 100 assemblies')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2800, 10103)\n"
     ]
    }
   ],
   "source": [
    "def test_train_split(data,stim):\n",
    "    unique, counts = np.unique(stim.flatten(), return_counts=True)\n",
    "    count_dict=dict(zip(unique, counts))\n",
    "\n",
    "    keys_with_enough_data=[]\n",
    "    for key in count_dict.keys():\n",
    "        if count_dict[key]==2:\n",
    "            keys_with_enough_data.append(key)\n",
    "\n",
    "    filtered_stims=np.isin(stim.flatten(),keys_with_enough_data)\n",
    "\n",
    "    #Arrange data so that responses with the same stimulus are adjacent\n",
    "    z=stim.flatten()[np.where(filtered_stims)[0]]\n",
    "    sortd=np.argsort(z)\n",
    "    istim=np.sort(z)\n",
    "    X=data[filtered_stims,:]\n",
    "    out=X[sortd,:].copy()\n",
    "\n",
    "    x_train=out[::2,:]\n",
    "    y_train=istim[::2]\n",
    "    x_test=out[1::2,:]\n",
    "    y_test=istim[1::2]\n",
    "    \n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "\n",
    "def corrcoef(x,y):\n",
    "        '''\n",
    "        Torch implementation of the full correlation matrix.\n",
    "        '''\n",
    "        # calculate covariance matrix of columns\n",
    "        mean_x = torch.mean(x,0)\n",
    "        xm = torch.sub(x,mean_x)\n",
    "        mean_y=torch.mean(y,0)\n",
    "        ym=torch.sub(y,mean_y)\n",
    "        c = torch.matmul(x.t(),y)\n",
    "        c = c / (x.size(0))\n",
    "\n",
    "        # normalize covariance matrix\n",
    "        std_x=torch.std(x,0)\n",
    "        std_y=torch.std(y,0)\n",
    "        std=torch.matmul(std_x.view(std_x.size()[0],1),std_y.view(1,std_y.size()[0]))\n",
    "        c = c.div(std)\n",
    "        return c\n",
    "    \n",
    "def evaluate_model(x_train,x_test):\n",
    "    corr_mat=np.zeros((x_train.shape[0],x_train.shape[0]))\n",
    "    for j in range(0,x_train.shape[0]):\n",
    "        for i in range(0,x_test.shape[0]):\n",
    "            corr_mat[j,i]=np.corrcoef(x_train[j,:],x_test[i,:])[0,1]\n",
    "    print(np.mean(np.argmax(corr_mat, axis=0) == np.arange(0,x_train.shape[0],1,int)))\n",
    "    \n",
    "def evaluate_model_torch(x_train,x_test):\n",
    "    x_train=torch.cuda.FloatTensor(x_train).t()\n",
    "    x_test=torch.cuda.FloatTensor(x_test).t()\n",
    "    corr_mat=np.array(corrcoef(x_train,x_test).cpu())\n",
    "    #print(corr_mat.size())\n",
    "\n",
    "    print(np.mean(np.argmax(corr_mat, axis=0) == np.arange(0,x_train.size()[1],1,int)))\n",
    "    \n",
    "stim=sio.loadmat('/home/maria/Documents/EnsemblePursuit/data/natimg2800_M170717_MP034_2017-09-11.mat')['stim']['istim'][0][0]\n",
    "x_train, x_test, y_train, y_test=test_train_split(np.array(X),stim)\n",
    "print(x_train.shape)\n",
    "#evaluate_model_torch(x_train,x_test)\n",
    "#evaluate_model(x_train,x_test)\n",
    "#x_train, x_test, y_train, y_test=test_train_split(np.array(V.t()),stim)\n",
    "#evaluate_model_torch(x_train,x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spont=sio.loadmat('/home/maria/Documents/EnsemblePursuit/data/natimg2800_M170717_MP034_2017-09-11.mat')['stim']['spont']\n",
    "print(spont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(range(0,100),cost_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons_100=np.load('/home/maria/Documents/EnsemblePursuit/data/natimg2800_M170717_MP034_2017-09-11_100_neuron_distributions.npy')\n",
    "print(neurons_100.shape)\n",
    "topics_100=np.load('/home/maria/Documents/EnsemblePursuit/data/natimg2800_M170717_MP034_2017-09-11_100_topic_distributions.npy')\n",
    "print(topics_100.shape)\n",
    "\n",
    "total_100=topics_100@neurons_100\n",
    "print(total_100.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test=test_train_split(topics_100,stim)\n",
    "evaluate_model_torch(x_train,x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5880, 100)\n",
      "0.3271428571428571\n"
     ]
    }
   ],
   "source": [
    "pcs=PCA(n_components=100).fit_transform(X)\n",
    "print(pcs.shape)\n",
    "x_train, x_test, y_train, y_test=test_train_split(pcs,stim)\n",
    "evaluate_model_torch(x_train,x_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
